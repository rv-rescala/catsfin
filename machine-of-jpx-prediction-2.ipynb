{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T23:38:44.941483Z","iopub.execute_input":"2022-04-21T23:38:44.941948Z","iopub.status.idle":"2022-04-21T23:38:44.951581Z","shell.execute_reply.started":"2022-04-21T23:38:44.941897Z","shell.execute_reply":"2022-04-21T23:38:44.950753Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# I/O Func\nBASE_PATH = Path(f'/kaggle/working')\n\ndef adjusting_price(price, key: str):\n    \"\"\"[Adjusting Close Price]\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n\n    def generate_adjusted(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, f\"CumulativeAdjustmentFactor{key}\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = (\n            df[f\"CumulativeAdjustmentFactor{key}\"] * df[key]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[f\"Adjusted{key}\"] == 0, f\"Adjusted{key}\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = df.loc[:, f\"Adjusted{key}\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted).reset_index(drop=True)\n\n    # price.set_index(\"Date\", inplace=True)\n    return price\n\ndef adjusting_volume(price, key = \"Volume\"):\n    \"\"\"[Adjusting Close Price]\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n\n    def generate_adjusted(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, f\"CumulativeAdjustmentFactor{key}\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = (\n            df[key] / df[f\"CumulativeAdjustmentFactor{key}\"]  \n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[f\"Adjusted{key}\"] == 0, f\"Adjusted{key}\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = df.loc[:, f\"Adjusted{key}\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted).reset_index(drop=True)\n\n    # price.set_index(\"Date\", inplace=True)\n    return price\n\ndef read_prices(dir_name: str, securities_code: int = None):\n    \"\"\"[Important: the dateset of 2020/10/1 is lost because of system failer in JPX, see: https://www.jpx.co.jp/corporate/news/news-releases/0060/20201019-01.html]\n    \n    \"\"\"\n    base_path = Path(f'../input/jpx-tokyo-stock-exchange-prediction/{dir_name}')\n    df = pd.read_csv(base_path / 'stock_prices.csv')\n    df.loc[: ,\"Date\"] = pd.to_datetime(df.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n    df = df[df['Open'].notna()]\n    if securities_code:\n        df = df[df[\"SecuritiesCode\"] == securities_code]\n    return df\n\ndef read_stock_list(securities_code: int = None, only_universe: bool = True):\n    df = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv')\n    df.loc[: ,\"EffectiveDate\"] = pd.to_datetime(df.loc[: ,\"EffectiveDate\"], format=\"%Y%m%d\")\n    if only_universe:\n        df = df[df['Universe0']]\n    if securities_code:\n        df = df[df[\"SecuritiesCode\"] == securities_code]\n    return df\n\ndef read_train_data_by_price(securities_code: int = None, with_supplemental: bool = True):\n    \"\"\"[The train base is price dataset, the other data are joined to prices DF by left join]\n    \n    \"\"\"\n    def merge_data(prices, stock_list):\n        base_df = prices.copy()\n        _stock_list = stock_list.copy()\n        _stock_list.rename(columns={'Close': 'Close_x'}, inplace=True)\n        base_df = base_df.merge(_stock_list, on='SecuritiesCode', how=\"left\")\n        return base_df\n    \n    # origin\n    df = merge_data(prices=read_prices(dir_name=\"train_files\", securities_code=securities_code), stock_list=read_stock_list(securities_code=securities_code))\n    \n    # supplyment\n    if with_supplemental:\n        supplemental_df = merge_data(prices=read_prices(dir_name=\"supplemental_files\", securities_code=securities_code), stock_list=read_stock_list(securities_code=securities_code))\n        df = pd.concat([df, supplemental_df]).reset_index(drop=True)\n        \n    df = adjusting_price(df, \"Close\")\n    df = adjusting_price(df, \"Open\")\n    df = adjusting_price(df, \"High\")\n    df = adjusting_price(df, \"Low\")\n    df = adjusting_volume(df)\n    return df\n\ndef write_df(df, filename):\n    df.to_csv(BASE_PATH / f'{filename}.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:38:44.954554Z","iopub.execute_input":"2022-04-21T23:38:44.954965Z","iopub.status.idle":"2022-04-21T23:38:44.983801Z","shell.execute_reply.started":"2022-04-21T23:38:44.954934Z","shell.execute_reply":"2022-04-21T23:38:44.982918Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df = read_train_data_by_price()\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:38:44.985109Z","iopub.execute_input":"2022-04-21T23:38:44.985784Z","iopub.status.idle":"2022-04-21T23:40:54.884324Z","shell.execute_reply.started":"2022-04-21T23:38:44.985732Z","shell.execute_reply":"2022-04-21T23:40:54.883349Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"num_leaves, val_score: 0.024645:  90%|######### | 18/20 [1:01:27<06:49, 204.87s/it]\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                 RowId       Date  SecuritiesCode    Open    High     Low  \\\n0        20170104_1301 2017-01-04            1301  2734.0  2755.0  2730.0   \n1        20170105_1301 2017-01-05            1301  2743.0  2747.0  2735.0   \n2        20170106_1301 2017-01-06            1301  2734.0  2744.0  2720.0   \n3        20170110_1301 2017-01-10            1301  2745.0  2754.0  2735.0   \n4        20170111_1301 2017-01-11            1301  2748.0  2752.0  2737.0   \n...                ...        ...             ...     ...     ...     ...   \n2436634  20220221_9997 2022-02-21            9997   725.0   729.0   719.0   \n2436635  20220222_9997 2022-02-22            9997   719.0   723.0   711.0   \n2436636  20220224_9997 2022-02-24            9997   709.0   725.0   708.0   \n2436637  20220225_9997 2022-02-25            9997   725.0   738.0   724.0   \n2436638  20220228_9997 2022-02-28            9997   731.0   737.0   726.0   \n\n          Close  Volume  AdjustmentFactor  ExpectedDividend  ...  \\\n0        2742.0   31400               1.0               NaN  ...   \n1        2738.0   17900               1.0               NaN  ...   \n2        2740.0   19900               1.0               NaN  ...   \n3        2748.0   24200               1.0               NaN  ...   \n4        2745.0    9300               1.0               NaN  ...   \n...         ...     ...               ...               ...  ...   \n2436634   727.0  116400               1.0               NaN  ...   \n2436635   721.0  225500               1.0               NaN  ...   \n2436636   719.0  195600               1.0               NaN  ...   \n2436637   733.0  170500               1.0               NaN  ...   \n2436638   734.0  288100               1.0               NaN  ...   \n\n         CumulativeAdjustmentFactorClose  AdjustedClose  \\\n0                                    1.0         2742.0   \n1                                    1.0         2738.0   \n2                                    1.0         2740.0   \n3                                    1.0         2748.0   \n4                                    1.0         2745.0   \n...                                  ...            ...   \n2436634                              1.0          727.0   \n2436635                              1.0          721.0   \n2436636                              1.0          719.0   \n2436637                              1.0          733.0   \n2436638                              1.0          734.0   \n\n        CumulativeAdjustmentFactorOpen AdjustedOpen  \\\n0                                  1.0       2734.0   \n1                                  1.0       2743.0   \n2                                  1.0       2734.0   \n3                                  1.0       2745.0   \n4                                  1.0       2748.0   \n...                                ...          ...   \n2436634                            1.0        725.0   \n2436635                            1.0        719.0   \n2436636                            1.0        709.0   \n2436637                            1.0        725.0   \n2436638                            1.0        731.0   \n\n        CumulativeAdjustmentFactorHigh AdjustedHigh  \\\n0                                  1.0       2755.0   \n1                                  1.0       2747.0   \n2                                  1.0       2744.0   \n3                                  1.0       2754.0   \n4                                  1.0       2752.0   \n...                                ...          ...   \n2436634                            1.0        729.0   \n2436635                            1.0        723.0   \n2436636                            1.0        725.0   \n2436637                            1.0        738.0   \n2436638                            1.0        737.0   \n\n        CumulativeAdjustmentFactorLow AdjustedLow  \\\n0                                 1.0      2730.0   \n1                                 1.0      2735.0   \n2                                 1.0      2720.0   \n3                                 1.0      2735.0   \n4                                 1.0      2737.0   \n...                               ...         ...   \n2436634                           1.0       719.0   \n2436635                           1.0       711.0   \n2436636                           1.0       708.0   \n2436637                           1.0       724.0   \n2436638                           1.0       726.0   \n\n        CumulativeAdjustmentFactorVolume AdjustedVolume  \n0                                    1.0        31400.0  \n1                                    1.0        17900.0  \n2                                    1.0        19900.0  \n3                                    1.0        24200.0  \n4                                    1.0         9300.0  \n...                                  ...            ...  \n2436634                              1.0       116400.0  \n2436635                              1.0       225500.0  \n2436636                              1.0       195600.0  \n2436637                              1.0       170500.0  \n2436638                              1.0       288100.0  \n\n[2436639 rows x 37 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowId</th>\n      <th>Date</th>\n      <th>SecuritiesCode</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>AdjustmentFactor</th>\n      <th>ExpectedDividend</th>\n      <th>...</th>\n      <th>CumulativeAdjustmentFactorClose</th>\n      <th>AdjustedClose</th>\n      <th>CumulativeAdjustmentFactorOpen</th>\n      <th>AdjustedOpen</th>\n      <th>CumulativeAdjustmentFactorHigh</th>\n      <th>AdjustedHigh</th>\n      <th>CumulativeAdjustmentFactorLow</th>\n      <th>AdjustedLow</th>\n      <th>CumulativeAdjustmentFactorVolume</th>\n      <th>AdjustedVolume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20170104_1301</td>\n      <td>2017-01-04</td>\n      <td>1301</td>\n      <td>2734.0</td>\n      <td>2755.0</td>\n      <td>2730.0</td>\n      <td>2742.0</td>\n      <td>31400</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2742.0</td>\n      <td>1.0</td>\n      <td>2734.0</td>\n      <td>1.0</td>\n      <td>2755.0</td>\n      <td>1.0</td>\n      <td>2730.0</td>\n      <td>1.0</td>\n      <td>31400.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20170105_1301</td>\n      <td>2017-01-05</td>\n      <td>1301</td>\n      <td>2743.0</td>\n      <td>2747.0</td>\n      <td>2735.0</td>\n      <td>2738.0</td>\n      <td>17900</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2738.0</td>\n      <td>1.0</td>\n      <td>2743.0</td>\n      <td>1.0</td>\n      <td>2747.0</td>\n      <td>1.0</td>\n      <td>2735.0</td>\n      <td>1.0</td>\n      <td>17900.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20170106_1301</td>\n      <td>2017-01-06</td>\n      <td>1301</td>\n      <td>2734.0</td>\n      <td>2744.0</td>\n      <td>2720.0</td>\n      <td>2740.0</td>\n      <td>19900</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2740.0</td>\n      <td>1.0</td>\n      <td>2734.0</td>\n      <td>1.0</td>\n      <td>2744.0</td>\n      <td>1.0</td>\n      <td>2720.0</td>\n      <td>1.0</td>\n      <td>19900.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20170110_1301</td>\n      <td>2017-01-10</td>\n      <td>1301</td>\n      <td>2745.0</td>\n      <td>2754.0</td>\n      <td>2735.0</td>\n      <td>2748.0</td>\n      <td>24200</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2748.0</td>\n      <td>1.0</td>\n      <td>2745.0</td>\n      <td>1.0</td>\n      <td>2754.0</td>\n      <td>1.0</td>\n      <td>2735.0</td>\n      <td>1.0</td>\n      <td>24200.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20170111_1301</td>\n      <td>2017-01-11</td>\n      <td>1301</td>\n      <td>2748.0</td>\n      <td>2752.0</td>\n      <td>2737.0</td>\n      <td>2745.0</td>\n      <td>9300</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2745.0</td>\n      <td>1.0</td>\n      <td>2748.0</td>\n      <td>1.0</td>\n      <td>2752.0</td>\n      <td>1.0</td>\n      <td>2737.0</td>\n      <td>1.0</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2436634</th>\n      <td>20220221_9997</td>\n      <td>2022-02-21</td>\n      <td>9997</td>\n      <td>725.0</td>\n      <td>729.0</td>\n      <td>719.0</td>\n      <td>727.0</td>\n      <td>116400</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>727.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>729.0</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>116400.0</td>\n    </tr>\n    <tr>\n      <th>2436635</th>\n      <td>20220222_9997</td>\n      <td>2022-02-22</td>\n      <td>9997</td>\n      <td>719.0</td>\n      <td>723.0</td>\n      <td>711.0</td>\n      <td>721.0</td>\n      <td>225500</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>721.0</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>723.0</td>\n      <td>1.0</td>\n      <td>711.0</td>\n      <td>1.0</td>\n      <td>225500.0</td>\n    </tr>\n    <tr>\n      <th>2436636</th>\n      <td>20220224_9997</td>\n      <td>2022-02-24</td>\n      <td>9997</td>\n      <td>709.0</td>\n      <td>725.0</td>\n      <td>708.0</td>\n      <td>719.0</td>\n      <td>195600</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>709.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>708.0</td>\n      <td>1.0</td>\n      <td>195600.0</td>\n    </tr>\n    <tr>\n      <th>2436637</th>\n      <td>20220225_9997</td>\n      <td>2022-02-25</td>\n      <td>9997</td>\n      <td>725.0</td>\n      <td>738.0</td>\n      <td>724.0</td>\n      <td>733.0</td>\n      <td>170500</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>733.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>738.0</td>\n      <td>1.0</td>\n      <td>724.0</td>\n      <td>1.0</td>\n      <td>170500.0</td>\n    </tr>\n    <tr>\n      <th>2436638</th>\n      <td>20220228_9997</td>\n      <td>2022-02-28</td>\n      <td>9997</td>\n      <td>731.0</td>\n      <td>737.0</td>\n      <td>726.0</td>\n      <td>734.0</td>\n      <td>288100</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>734.0</td>\n      <td>1.0</td>\n      <td>731.0</td>\n      <td>1.0</td>\n      <td>737.0</td>\n      <td>1.0</td>\n      <td>726.0</td>\n      <td>1.0</td>\n      <td>288100.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2436639 rows × 37 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Featrue","metadata":{}},{"cell_type":"code","source":"def cal_moving_average(key:str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"MovingAverage{key}{period}\"\n            col_gap = f\"{col}GapPercent\"\n            df[col] = df[key].rolling(period, min_periods=1).mean()\n            df[col_gap] = (df[key] / df[col]) * 100.0\n        return df\n    return func\n\ndef cal_changing_ration(key:str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"ChangingRatio{key}{period}\"\n            df[col] = df[key].pct_change(period) * 100\n        return df\n    return func\n\ndef cal_historical_vix(key: str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"HistoricalVIX{key}{period}\"\n            df[col] = np.log(df[key]).diff().rolling(period).std()\n        return df\n    return func\n\ndef add_columns_per_code(df, functions):\n    def func(df):\n        for f in functions:\n            df = f(df)\n        return df\n    df = df.sort_values([\"SecuritiesCode\", \"Date\"])\n    df = df.groupby(\"SecuritiesCode\").apply(func)\n    df = df.reset_index(drop=True)\n    return df\n\ndef add_columns_per_day(base_df):\n    base_df['diff_rate1'] = (base_df['Close'] - base_df['Open']) / base_df['Close']\n    base_df['diff_rate2'] = (base_df['High'] - base_df['Low']) / base_df['Close']    \n    return base_df\n\ndef generate_features(df):\n    base_df = df.copy()\n    prev_column_names = base_df.columns\n    periods = [5, 25, 75]\n    functions = [\n        cal_moving_average(\"AdjustedClose\", periods),\n        cal_moving_average(\"AdjustedOpen\", periods),\n        cal_moving_average(\"AdjustedHigh\", periods),\n        cal_moving_average(\"AdjustedLow\", periods),\n        cal_moving_average(\"AdjustedVolume\", periods),\n        cal_changing_ration(\"AdjustedClose\", periods),\n        cal_changing_ration(\"AdjustedOpen\", periods),\n        cal_changing_ration(\"AdjustedHigh\", periods),\n        cal_changing_ration(\"AdjustedLow\", periods),\n        cal_changing_ration(\"AdjustedVolume\", periods),\n        cal_historical_vix(\"AdjustedClose\", periods),\n        cal_historical_vix(\"AdjustedOpen\", periods),\n        cal_historical_vix(\"AdjustedHigh\", periods),\n        cal_historical_vix(\"AdjustedLow\", periods),\n        cal_historical_vix(\"AdjustedVolume\", periods)\n    ]\n    \n    base_df = add_columns_per_code(base_df, functions)\n    base_df = add_columns_per_day(base_df)\n    \n    add_column_names = list(set(base_df.columns) - set(prev_column_names))\n    #feats = feats[feats[\"HistoricalVIXAdjustedClose75\"] != 0]\n    return base_df, add_column_names\n\ndef select_features(feature_df, add_column_names, is_train):\n    base_cols = ['RowId', 'Date', 'SecuritiesCode']\n    numerical_cols = sorted(add_column_names)\n    categorical_cols = ['NewMarketSegment', '33SectorCode', '17SectorCode']\n    label_col = ['Target']\n    feat_cols = numerical_cols + categorical_cols\n    feature_df = feature_df[base_cols + feat_cols + label_col]\n    feature_df[categorical_cols] = feature_df[categorical_cols].astype('category')\n    if is_train:\n        feature_df.dropna(inplace=True)\n    else:\n        feature_df[numerical_cols] = feature_df[numerical_cols].fillna(0)\n        feature_df[numerical_cols] = feature_df[numerical_cols].replace([np.inf, -np.inf], 0)\n    return feature_df, feat_cols, label_col\n\ndef preprocessor(base_df, is_train=True):\n    feature_df = base_df.copy()\n    \n    ## 特徴量生成\n    feature_df, add_column_names = generate_features(feature_df)\n    \n    ## 特徴量選択\n    feature_df, feat_cols, label_col = select_features(feature_df, add_column_names, is_train)\n\n    return feature_df, feat_cols, label_col\n\nfeature_df, feat_cols, label_col = preprocessor(train_df)\n\n# modelの結果をもとにfeat_colsを上書き\nfeat_cols = ['33SectorCode', 'ChangingRatioAdjustedVolume25', 'diff_rate2', 'MovingAverageAdjustedHigh5GapPercent', 'MovingAverageAdjustedOpen5GapPercent', 'HistoricalVIXAdjustedLow5', 'MovingAverageAdjustedClose5GapPercent', 'HistoricalVIXAdjustedOpen5', 'MovingAverageAdjustedLow25GapPercent', 'ChangingRatioAdjustedVolume5', 'HistoricalVIXAdjustedOpen75', 'HistoricalVIXAdjustedVolume5', 'MovingAverageAdjustedVolume25GapPercent', 'diff_rate1', 'ChangingRatioAdjustedHigh5', 'ChangingRatioAdjustedOpen25', 'HistoricalVIXAdjustedOpen25', 'MovingAverageAdjustedClose25GapPercent', 'MovingAverageAdjustedVolume75GapPercent', 'ChangingRatioAdjustedLow25', 'ChangingRatioAdjustedLow5', 'HistoricalVIXAdjustedHigh75', 'MovingAverageAdjustedLow5GapPercent', 'ChangingRatioAdjustedClose75', 'MovingAverageAdjustedClose75', 'MovingAverageAdjustedClose75GapPercent', 'HistoricalVIXAdjustedVolume75']\nfeat_cols","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:40:54.886830Z","iopub.execute_input":"2022-04-21T23:40:54.887156Z","iopub.status.idle":"2022-04-21T23:43:02.822361Z","shell.execute_reply.started":"2022-04-21T23:40:54.887115Z","shell.execute_reply":"2022-04-21T23:43:02.821528Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['33SectorCode',\n 'ChangingRatioAdjustedVolume25',\n 'diff_rate2',\n 'MovingAverageAdjustedHigh5GapPercent',\n 'MovingAverageAdjustedOpen5GapPercent',\n 'HistoricalVIXAdjustedLow5',\n 'MovingAverageAdjustedClose5GapPercent',\n 'HistoricalVIXAdjustedOpen5',\n 'MovingAverageAdjustedLow25GapPercent',\n 'ChangingRatioAdjustedVolume5',\n 'HistoricalVIXAdjustedOpen75',\n 'HistoricalVIXAdjustedVolume5',\n 'MovingAverageAdjustedVolume25GapPercent',\n 'MovingAverageAdjustedVolume5',\n 'diff_rate1',\n 'ChangingRatioAdjustedHigh5',\n 'ChangingRatioAdjustedOpen25',\n 'HistoricalVIXAdjustedOpen25',\n 'MovingAverageAdjustedClose25GapPercent',\n 'MovingAverageAdjustedVolume75GapPercent',\n 'ChangingRatioAdjustedLow25',\n 'ChangingRatioAdjustedLow5',\n 'HistoricalVIXAdjustedHigh75',\n 'MovingAverageAdjustedLow5GapPercent',\n 'ChangingRatioAdjustedClose75',\n 'MovingAverageAdjustedClose5',\n 'MovingAverageAdjustedClose75',\n 'MovingAverageAdjustedClose75GapPercent',\n 'HistoricalVIXAdjustedVolume75']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Learning","metadata":{}},{"cell_type":"code","source":"# 予測値を降順に並べて順位番号を振る関数\n# 言い換えると、目的変数から提出用項目を導出する関数\ndef add_rank(df, col_name=\"pred\"):\n    df[\"Rank\"] = df.groupby(\"Date\")[col_name].rank(ascending=False, method=\"first\") - 1 \n    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n    return df\n\ndef calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio\n\n# 予測用のデータフレームと、予測結果をもとに、スコアを計算する関数\ndef evaluator(df, pred):\n    df[\"pred\"] = pred\n    df = add_rank(df)\n    score = calc_spread_return_sharpe(df)\n    return score\n\nimport lightgbm as lgb\nimport optuna.integration.lightgbm as lgb\n\n# 学習を実行する関数\ndef trainer(feature_df, feat_cols, label_col, fold_params, seed=2022):\n    scores = []\n    models = []\n    params = []\n    i = 0\n    for param in fold_params:\n        ################################\n        # データ準備\n        ################################\n        train = feature_df[(param[0] <= feature_df['Date']) & (feature_df['Date'] < param[1])]\n        valid = feature_df[(param[1] <= feature_df['Date']) & (feature_df['Date'] < param[2])]\n\n        X_train = train[feat_cols]\n        y_train = train[label_col]\n        X_valid = valid[feat_cols]\n        y_valid = valid[label_col]\n        \n        lgb_train = lgb.Dataset(X_train, y_train)\n        lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n\n        ################################\n        # 学習\n        ################################\n        params = {\n            'task': 'train',                   # 学習\n            'boosting_type': 'gbdt',           # GBDT\n            'objective': 'regression',         # 回帰\n            'metric': 'rmse',                  # 損失（誤差）\n            'learning_rate': 0.01,             # 学習率\n            'lambda_l1': 0.5,                  # L1正則化項の係数\n            'lambda_l2': 0.5,                  # L2正則化項の係数\n            'num_leaves': 10,                  # 最大葉枚数\n            'feature_fraction': 0.5,           # ランダムに抽出される列の割合\n            'bagging_fraction': 0.5,           # ランダムに抽出される標本の割合\n            'bagging_freq': 5,                 # バギング実施頻度\n            'min_child_samples': 10,           # 葉に含まれる最小データ数\n            'seed': seed                       # シード値\n        } \n \n        lgb_results = {}                       \n        model = lgb.train( \n            params,                            # ハイパーパラメータ\n            lgb_train,                         # 訓練データ\n            valid_sets=[lgb_train, lgb_valid], # 検証データ\n            valid_names=['Train', 'Valid'],    # データセット名前\n            num_boost_round=2000,              # 計算回数\n            early_stopping_rounds=100,         # 計算打ち切り設定\n            evals_result=lgb_results,          # 学習の履歴\n            verbose_eval=100,                  # 学習過程の表示サイクル\n        )  \n\n        ################################\n        # 結果描画\n        ################################\n        fig = plt.figure(figsize=(10, 4))\n\n        # loss\n        plt.subplot(1,2,1)\n        loss_train = lgb_results['Train']['rmse']\n        loss_test = lgb_results['Valid']['rmse']   \n        plt.xlabel('Iteration')\n        plt.ylabel('logloss')\n        plt.plot(loss_train, label='train loss')\n        plt.plot(loss_test, label='valid loss')\n        plt.legend()\n\n        # feature importance\n        plt.subplot(1,2,2)\n        importance = pd.DataFrame({'feature':feat_cols, 'importance':model.feature_importance()})\n        write_df(importance, f\"importance_{i}\")\n        sns.barplot(x = 'importance', y = 'feature', data = importance.sort_values('importance', ascending=False))\n\n        plt.tight_layout()\n        plt.show()\n\n        ################################\n        # 評価\n        ################################\n        # 推論\n        pred =  model.predict(X_valid, num_iteration=model.best_iteration)\n        # 評価\n        score = evaluator(valid, pred)\n\n        scores.append(score)\n        models.append(model)\n        # save model\n        model.save_model(f'{BASE_PATH} / model_{i}.txt')\n        i = i + 1\n        # model = lightgbm.Booster(model_file='lgbr_base.txt')\n\n    print(\"CV_SCORES:\", scores)\n    print(\"CV_SCORE:\", np.mean(scores))\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:43:02.823965Z","iopub.execute_input":"2022-04-21T23:43:02.824208Z","iopub.status.idle":"2022-04-21T23:43:02.853678Z","shell.execute_reply.started":"2022-04-21T23:43:02.824178Z","shell.execute_reply":"2022-04-21T23:43:02.853002Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# 2020-12-23よりも前のデータは証券コードが2000個すべて揃っていないため、これ以降のデータのみを使う。\n# (学習用データの開始日、学習用データの終了日＝検証用データの開始日、検証用データの終了日)\nfold_params = [\n    ('2020-12-23', '2021-11-01', '2021-12-01'),\n    ('2021-01-23', '2021-12-01', '2022-01-01'),\n    ('2021-02-23', '2022-01-01', '2022-02-01'),\n]\nmodels = trainer(feature_df, feat_cols, label_col, fold_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:43:02.854769Z","iopub.execute_input":"2022-04-21T23:43:02.855655Z","iopub.status.idle":"2022-04-21T23:49:42.441149Z","shell.execute_reply.started":"2022-04-21T23:43:02.855612Z","shell.execute_reply":"2022-04-21T23:49:42.440082Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-04-21 23:43:03,065]\u001b[0m A new study created in memory with name: no-name-e48f430e-7f26-408a-b9b1-f351012c30be\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081719 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  14%|#4        | 1/7 [00:04<00:25,  4.20s/it]\u001b[32m[I 2022-04-21 23:43:07,275]\u001b[0m Trial 0 finished with value: 0.024644677040188058 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.024644677040188058.\u001b[0m\nfeature_fraction, val_score: 0.024645:  14%|#4        | 1/7 [00:04<00:25,  4.20s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021421\tValid's rmse: 0.024666\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  29%|##8       | 2/7 [00:08<00:20,  4.04s/it]\u001b[32m[I 2022-04-21 23:43:11,195]\u001b[0m Trial 1 finished with value: 0.02464463239883677 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.02464463239883677.\u001b[0m\nfeature_fraction, val_score: 0.024645:  29%|##8       | 2/7 [00:08<00:20,  4.04s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021422\tValid's rmse: 0.0246653\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  43%|####2     | 3/7 [00:11<00:15,  3.79s/it]\u001b[32m[I 2022-04-21 23:43:14,700]\u001b[0m Trial 2 finished with value: 0.024644820662975717 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.02464463239883677.\u001b[0m\nfeature_fraction, val_score: 0.024645:  43%|####2     | 3/7 [00:11<00:15,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214265\tValid's rmse: 0.0246637\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070649 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  57%|#####7    | 4/7 [00:15<00:11,  3.74s/it]\u001b[32m[I 2022-04-21 23:43:18,368]\u001b[0m Trial 3 finished with value: 0.02464486665625294 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.02464463239883677.\u001b[0m\nfeature_fraction, val_score: 0.024645:  57%|#####7    | 4/7 [00:15<00:11,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214247\tValid's rmse: 0.0246661\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.247806 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  71%|#######1  | 5/7 [00:19<00:07,  3.94s/it]\u001b[32m[I 2022-04-21 23:43:22,652]\u001b[0m Trial 4 finished with value: 0.024644682109811286 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.02464463239883677.\u001b[0m\nfeature_fraction, val_score: 0.024645:  71%|#######1  | 5/7 [00:19<00:07,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214234\tValid's rmse: 0.0246646\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074138 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  86%|########5 | 6/7 [00:23<00:03,  3.88s/it]\u001b[32m[I 2022-04-21 23:43:26,410]\u001b[0m Trial 5 finished with value: 0.02464463239883677 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.02464463239883677.\u001b[0m\nfeature_fraction, val_score: 0.024645:  86%|########5 | 6/7 [00:23<00:03,  3.88s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214215\tValid's rmse: 0.0246646\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087765 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645: 100%|##########| 7/7 [00:27<00:00,  3.89s/it]\u001b[32m[I 2022-04-21 23:43:30,326]\u001b[0m Trial 6 finished with value: 0.024644802843216466 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.02464463239883677.\u001b[0m\nfeature_fraction, val_score: 0.024645: 100%|##########| 7/7 [00:27<00:00,  3.89s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214213\tValid's rmse: 0.0246646\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246448\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070866 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:   5%|5         | 1/20 [00:05<01:48,  5.70s/it]\u001b[32m[I 2022-04-21 23:43:36,045]\u001b[0m Trial 7 finished with value: 0.02464463297691151 and parameters: {'num_leaves': 52}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:   5%|5         | 1/20 [00:05<01:48,  5.70s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021365\tValid's rmse: 0.0246663\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070210 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  10%|#         | 2/20 [00:09<01:23,  4.64s/it]\u001b[32m[I 2022-04-21 23:43:39,944]\u001b[0m Trial 8 finished with value: 0.024644731662152246 and parameters: {'num_leaves': 14}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  10%|#         | 2/20 [00:09<01:23,  4.64s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214137\tValid's rmse: 0.0246661\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069877 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  15%|#5        | 3/20 [00:18<01:51,  6.53s/it]\u001b[32m[I 2022-04-21 23:43:48,728]\u001b[0m Trial 9 finished with value: 0.02464491022093292 and parameters: {'num_leaves': 216}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  15%|#5        | 3/20 [00:18<01:51,  6.53s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212581\tValid's rmse: 0.0246741\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214567\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070463 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  20%|##        | 4/20 [00:24<01:41,  6.35s/it]\u001b[32m[I 2022-04-21 23:43:54,783]\u001b[0m Trial 10 finished with value: 0.024644776140161813 and parameters: {'num_leaves': 33}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  20%|##        | 4/20 [00:24<01:41,  6.35s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213859\tValid's rmse: 0.0246666\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214581\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  25%|##5       | 5/20 [00:33<01:51,  7.42s/it]\u001b[32m[I 2022-04-21 23:44:04,119]\u001b[0m Trial 11 finished with value: 0.024644920931748006 and parameters: {'num_leaves': 252}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  25%|##5       | 5/20 [00:33<01:51,  7.42s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021241\tValid's rmse: 0.0246723\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214565\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  30%|###       | 6/20 [00:40<01:38,  7.03s/it]\u001b[32m[I 2022-04-21 23:44:10,375]\u001b[0m Trial 12 finished with value: 0.024644772164874977 and parameters: {'num_leaves': 72}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  30%|###       | 6/20 [00:40<01:38,  7.03s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213476\tValid's rmse: 0.0246692\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214577\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072693 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  35%|###5      | 7/20 [00:47<01:34,  7.27s/it]\u001b[32m[I 2022-04-21 23:44:18,155]\u001b[0m Trial 13 finished with value: 0.024644942937314302 and parameters: {'num_leaves': 158}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  35%|###5      | 7/20 [00:47<01:34,  7.27s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212888\tValid's rmse: 0.0246706\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214571\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  40%|####      | 8/20 [00:56<01:33,  7.79s/it]\u001b[32m[I 2022-04-21 23:44:27,061]\u001b[0m Trial 14 finished with value: 0.02464496113945811 and parameters: {'num_leaves': 178}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  40%|####      | 8/20 [00:56<01:33,  7.79s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212776\tValid's rmse: 0.0246717\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214569\tValid's rmse: 0.024645\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070959 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  45%|####5     | 9/20 [01:05<01:28,  8.00s/it]\u001b[32m[I 2022-04-21 23:44:35,523]\u001b[0m Trial 15 finished with value: 0.02464489130528576 and parameters: {'num_leaves': 209}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  45%|####5     | 9/20 [01:05<01:28,  8.00s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212618\tValid's rmse: 0.0246729\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071463 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  50%|#####     | 10/20 [01:11<01:15,  7.58s/it]\u001b[32m[I 2022-04-21 23:44:42,161]\u001b[0m Trial 16 finished with value: 0.024644907905653397 and parameters: {'num_leaves': 86}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  50%|#####     | 10/20 [01:11<01:15,  7.58s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213359\tValid's rmse: 0.0246695\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214576\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070393 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  55%|#####5    | 11/20 [01:18<01:06,  7.39s/it]\u001b[32m[I 2022-04-21 23:44:49,106]\u001b[0m Trial 17 finished with value: 0.024644911037759593 and parameters: {'num_leaves': 111}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  55%|#####5    | 11/20 [01:18<01:06,  7.39s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213178\tValid's rmse: 0.0246708\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214574\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070681 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  60%|######    | 12/20 [01:21<00:48,  6.04s/it]\u001b[32m[I 2022-04-21 23:44:52,075]\u001b[0m Trial 18 finished with value: 0.024644800193109825 and parameters: {'num_leaves': 4}. Best is trial 7 with value: 0.02464463297691151.\u001b[0m\nnum_leaves, val_score: 0.024645:  60%|######    | 12/20 [01:21<00:48,  6.04s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.02144\tValid's rmse: 0.0246639\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070823 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  65%|######5   | 13/20 [01:28<00:43,  6.19s/it]\u001b[32m[I 2022-04-21 23:44:58,604]\u001b[0m Trial 19 finished with value: 0.024644629521468158 and parameters: {'num_leaves': 51}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645:  65%|######5   | 13/20 [01:28<00:43,  6.19s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213657\tValid's rmse: 0.0246671\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075039 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  70%|#######   | 14/20 [01:34<00:36,  6.15s/it]\u001b[32m[I 2022-04-21 23:45:04,670]\u001b[0m Trial 20 finished with value: 0.024644725900790983 and parameters: {'num_leaves': 63}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645:  70%|#######   | 14/20 [01:34<00:36,  6.15s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213552\tValid's rmse: 0.0246688\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  75%|#######5  | 15/20 [01:39<00:29,  5.94s/it]\u001b[32m[I 2022-04-21 23:45:10,129]\u001b[0m Trial 21 finished with value: 0.024644699244363452 and parameters: {'num_leaves': 47}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645:  75%|#######5  | 15/20 [01:39<00:29,  5.94s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213696\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021458\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072880 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  80%|########  | 16/20 [01:46<00:25,  6.26s/it]\u001b[32m[I 2022-04-21 23:45:17,116]\u001b[0m Trial 22 finished with value: 0.024644911037759593 and parameters: {'num_leaves': 111}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645:  80%|########  | 16/20 [01:46<00:25,  6.26s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213178\tValid's rmse: 0.0246708\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214574\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  85%|########5 | 17/20 [01:54<00:20,  6.70s/it]\u001b[32m[I 2022-04-21 23:45:24,830]\u001b[0m Trial 23 finished with value: 0.024644866756193994 and parameters: {'num_leaves': 136}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645:  85%|########5 | 17/20 [01:54<00:20,  6.70s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021302\tValid's rmse: 0.0246718\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214572\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082247 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  90%|######### | 18/20 [02:02<00:14,  7.01s/it]\u001b[32m[I 2022-04-21 23:45:32,567]\u001b[0m Trial 24 finished with value: 0.02464492668840094 and parameters: {'num_leaves': 85}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645:  90%|######### | 18/20 [02:02<00:14,  7.01s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213368\tValid's rmse: 0.0246694\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214576\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  95%|#########5| 19/20 [02:07<00:06,  6.45s/it]\u001b[32m[I 2022-04-21 23:45:37,730]\u001b[0m Trial 25 finished with value: 0.024644755505824092 and parameters: {'num_leaves': 35}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645:  95%|#########5| 19/20 [02:07<00:06,  6.45s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213833\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214581\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069786 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645: 100%|##########| 20/20 [02:14<00:00,  6.65s/it]\u001b[32m[I 2022-04-21 23:45:44,820]\u001b[0m Trial 26 finished with value: 0.02464488904273963 and parameters: {'num_leaves': 110}. Best is trial 19 with value: 0.024644629521468158.\u001b[0m\nnum_leaves, val_score: 0.024645: 100%|##########| 20/20 [02:14<00:00,  6.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213193\tValid's rmse: 0.0246699\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214574\tValid's rmse: 0.0246449\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070764 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  10%|#         | 1/10 [00:05<00:49,  5.53s/it]\u001b[32m[I 2022-04-21 23:45:50,362]\u001b[0m Trial 27 finished with value: 0.024644807555239314 and parameters: {'bagging_fraction': 0.48914590092306587, 'bagging_freq': 5}. Best is trial 27 with value: 0.024644807555239314.\u001b[0m\nbagging, val_score: 0.024645:  10%|#         | 1/10 [00:05<00:49,  5.53s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213668\tValid's rmse: 0.0246699\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  20%|##        | 2/10 [00:11<00:46,  5.85s/it]\u001b[32m[I 2022-04-21 23:45:56,436]\u001b[0m Trial 28 finished with value: 0.024644817662724895 and parameters: {'bagging_fraction': 0.6279378191554122, 'bagging_freq': 5}. Best is trial 27 with value: 0.024644807555239314.\u001b[0m\nbagging, val_score: 0.024645:  20%|##        | 2/10 [00:11<00:46,  5.85s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213629\tValid's rmse: 0.0246714\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  30%|###       | 3/10 [00:17<00:42,  6.06s/it]\u001b[32m[I 2022-04-21 23:46:02,744]\u001b[0m Trial 29 finished with value: 0.02464488283063972 and parameters: {'bagging_fraction': 0.40199602665725837, 'bagging_freq': 7}. Best is trial 27 with value: 0.024644807555239314.\u001b[0m\nbagging, val_score: 0.024645:  30%|###       | 3/10 [00:17<00:42,  6.06s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213707\tValid's rmse: 0.0246696\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214581\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069866 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  40%|####      | 4/10 [00:23<00:35,  5.91s/it]\u001b[32m[I 2022-04-21 23:46:08,430]\u001b[0m Trial 30 finished with value: 0.024644805815926332 and parameters: {'bagging_fraction': 0.6024293075188769, 'bagging_freq': 1}. Best is trial 30 with value: 0.024644805815926332.\u001b[0m\nbagging, val_score: 0.024645:  40%|####      | 4/10 [00:23<00:35,  5.91s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213636\tValid's rmse: 0.0246704\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  50%|#####     | 5/10 [00:29<00:28,  5.80s/it]\u001b[32m[I 2022-04-21 23:46:14,030]\u001b[0m Trial 31 finished with value: 0.024644923008452172 and parameters: {'bagging_fraction': 0.6428929965781156, 'bagging_freq': 1}. Best is trial 30 with value: 0.024644805815926332.\u001b[0m\nbagging, val_score: 0.024645:  50%|#####     | 5/10 [00:29<00:28,  5.80s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213624\tValid's rmse: 0.0246705\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079183 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  60%|######    | 6/10 [00:35<00:23,  5.93s/it]\u001b[32m[I 2022-04-21 23:46:20,212]\u001b[0m Trial 32 finished with value: 0.024644872524367516 and parameters: {'bagging_fraction': 0.6267450867319098, 'bagging_freq': 2}. Best is trial 30 with value: 0.024644805815926332.\u001b[0m\nbagging, val_score: 0.024645:  60%|######    | 6/10 [00:35<00:23,  5.93s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213632\tValid's rmse: 0.0246712\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083801 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  70%|#######   | 7/10 [00:41<00:17,  5.94s/it]\u001b[32m[I 2022-04-21 23:46:26,183]\u001b[0m Trial 33 finished with value: 0.024644758100453933 and parameters: {'bagging_fraction': 0.595105900122819, 'bagging_freq': 2}. Best is trial 33 with value: 0.024644758100453933.\u001b[0m\nbagging, val_score: 0.024645:  70%|#######   | 7/10 [00:41<00:17,  5.94s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213636\tValid's rmse: 0.0246704\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071208 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  80%|########  | 8/10 [00:48<00:12,  6.26s/it]\u001b[32m[I 2022-04-21 23:46:33,113]\u001b[0m Trial 34 finished with value: 0.024644806901809903 and parameters: {'bagging_fraction': 0.6267000484492793, 'bagging_freq': 6}. Best is trial 33 with value: 0.024644758100453933.\u001b[0m\nbagging, val_score: 0.024645:  80%|########  | 8/10 [00:48<00:12,  6.26s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213638\tValid's rmse: 0.0246715\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070642 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  90%|######### | 9/10 [00:54<00:06,  6.16s/it]\u001b[32m[I 2022-04-21 23:46:39,054]\u001b[0m Trial 35 finished with value: 0.024644696066911186 and parameters: {'bagging_fraction': 0.9169500428563397, 'bagging_freq': 1}. Best is trial 35 with value: 0.024644696066911186.\u001b[0m\nbagging, val_score: 0.024645:  90%|######### | 9/10 [00:54<00:06,  6.16s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213575\tValid's rmse: 0.0246709\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645: 100%|##########| 10/10 [01:00<00:00,  6.08s/it]\u001b[32m[I 2022-04-21 23:46:44,967]\u001b[0m Trial 36 finished with value: 0.02464469658183113 and parameters: {'bagging_fraction': 0.5872152066467553, 'bagging_freq': 4}. Best is trial 35 with value: 0.024644696066911186.\u001b[0m\nbagging, val_score: 0.024645: 100%|##########| 10/10 [01:00<00:00,  6.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021364\tValid's rmse: 0.024669\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021458\tValid's rmse: 0.0246447\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:   0%|          | 0/6 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  17%|#6        | 1/6 [00:05<00:28,  5.70s/it]\u001b[32m[I 2022-04-21 23:46:50,676]\u001b[0m Trial 37 finished with value: 0.02464461925340685 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.02464461925340685.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  17%|#6        | 1/6 [00:05<00:28,  5.70s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213678\tValid's rmse: 0.0246676\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021458\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070673 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  33%|###3      | 2/6 [00:11<00:22,  5.56s/it]\u001b[32m[I 2022-04-21 23:46:56,131]\u001b[0m Trial 38 finished with value: 0.024644612766477104 and parameters: {'feature_fraction': 0.62}. Best is trial 38 with value: 0.024644612766477104.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  33%|###3      | 2/6 [00:11<00:22,  5.56s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213692\tValid's rmse: 0.024668\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021458\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070419 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  50%|#####     | 3/6 [00:16<00:17,  5.67s/it]\u001b[32m[I 2022-04-21 23:47:01,940]\u001b[0m Trial 39 finished with value: 0.024644629521468158 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 38 with value: 0.024644612766477104.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  50%|#####     | 3/6 [00:16<00:17,  5.67s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213657\tValid's rmse: 0.0246671\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  67%|######6   | 4/6 [00:23<00:12,  6.04s/it]\u001b[32m[I 2022-04-21 23:47:08,549]\u001b[0m Trial 40 finished with value: 0.024644618185915106 and parameters: {'feature_fraction': 0.716}. Best is trial 38 with value: 0.024644612766477104.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  67%|######6   | 4/6 [00:23<00:12,  6.04s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213651\tValid's rmse: 0.0246672\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  83%|########3 | 5/6 [00:29<00:05,  5.98s/it]\u001b[32m[I 2022-04-21 23:47:14,423]\u001b[0m Trial 41 finished with value: 0.024644799646009283 and parameters: {'feature_fraction': 0.748}. Best is trial 38 with value: 0.024644612766477104.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  83%|########3 | 5/6 [00:29<00:05,  5.98s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213644\tValid's rmse: 0.0246676\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075731 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645: 100%|##########| 6/6 [00:35<00:00,  5.94s/it]\u001b[32m[I 2022-04-21 23:47:20,292]\u001b[0m Trial 42 finished with value: 0.024644869230878587 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 38 with value: 0.024644612766477104.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645: 100%|##########| 6/6 [00:35<00:00,  5.89s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213635\tValid's rmse: 0.0246694\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246449\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071197 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:   5%|5         | 1/20 [00:04<01:33,  4.94s/it]\u001b[32m[I 2022-04-21 23:47:25,237]\u001b[0m Trial 43 finished with value: 0.024645067585200443 and parameters: {'lambda_l1': 5.549228981285507e-08, 'lambda_l2': 6.215110674703827e-05}. Best is trial 43 with value: 0.024645067585200443.\u001b[0m\nregularization_factors, val_score: 0.024645:   5%|5         | 1/20 [00:04<01:33,  4.94s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213422\tValid's rmse: 0.0246687\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246451\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073355 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  10%|#         | 2/20 [00:09<01:26,  4.83s/it]\u001b[32m[I 2022-04-21 23:47:29,988]\u001b[0m Trial 44 finished with value: 0.024645045945884004 and parameters: {'lambda_l1': 0.001556542745304732, 'lambda_l2': 0.02683473829165736}. Best is trial 44 with value: 0.024645045945884004.\u001b[0m\nregularization_factors, val_score: 0.024645:  10%|#         | 2/20 [00:09<01:26,  4.83s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213424\tValid's rmse: 0.0246685\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.024645\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071602 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  15%|#5        | 3/20 [00:16<01:38,  5.78s/it]\u001b[32m[I 2022-04-21 23:47:36,902]\u001b[0m Trial 45 finished with value: 0.024644779944254437 and parameters: {'lambda_l1': 2.2886724788690094, 'lambda_l2': 4.410685836849339e-06}. Best is trial 45 with value: 0.024644779944254437.\u001b[0m\nregularization_factors, val_score: 0.024645:  15%|#5        | 3/20 [00:16<01:38,  5.78s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214012\tValid's rmse: 0.0246621\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214583\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070307 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  20%|##        | 4/20 [00:21<01:25,  5.37s/it]\u001b[32m[I 2022-04-21 23:47:41,631]\u001b[0m Trial 46 finished with value: 0.024645067536182008 and parameters: {'lambda_l1': 2.2387806755113034e-07, 'lambda_l2': 0.0015728883427290454}. Best is trial 45 with value: 0.024644779944254437.\u001b[0m\nregularization_factors, val_score: 0.024645:  20%|##        | 4/20 [00:21<01:25,  5.37s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213423\tValid's rmse: 0.0246687\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246451\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  25%|##5       | 5/20 [00:27<01:24,  5.65s/it]\u001b[32m[I 2022-04-21 23:47:47,780]\u001b[0m Trial 47 finished with value: 0.02464501973840326 and parameters: {'lambda_l1': 1.6569346643565446, 'lambda_l2': 0.039373546924161354}. Best is trial 45 with value: 0.024644779944254437.\u001b[0m\nregularization_factors, val_score: 0.024645:  25%|##5       | 5/20 [00:27<01:24,  5.65s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213949\tValid's rmse: 0.0246645\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214582\tValid's rmse: 0.024645\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074506 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  30%|###       | 6/20 [00:32<01:14,  5.35s/it]\u001b[32m[I 2022-04-21 23:47:52,551]\u001b[0m Trial 48 finished with value: 0.02464504979153123 and parameters: {'lambda_l1': 0.006586496072331098, 'lambda_l2': 0.14504344530670962}. Best is trial 45 with value: 0.024644779944254437.\u001b[0m\nregularization_factors, val_score: 0.024645:  30%|###       | 6/20 [00:32<01:14,  5.35s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213436\tValid's rmse: 0.0246682\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.024645\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069991 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  35%|###5      | 7/20 [00:37<01:07,  5.21s/it]\u001b[32m[I 2022-04-21 23:47:57,472]\u001b[0m Trial 49 finished with value: 0.024645067587221778 and parameters: {'lambda_l1': 2.853932106534794e-08, 'lambda_l2': 3.519050107495924e-07}. Best is trial 45 with value: 0.024644779944254437.\u001b[0m\nregularization_factors, val_score: 0.024645:  35%|###5      | 7/20 [00:37<01:07,  5.21s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213422\tValid's rmse: 0.0246687\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246451\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071537 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  40%|####      | 8/20 [00:41<01:00,  5.04s/it]\u001b[32m[I 2022-04-21 23:48:02,160]\u001b[0m Trial 50 finished with value: 0.024645067018514922 and parameters: {'lambda_l1': 1.965455210280713e-08, 'lambda_l2': 0.01760246867126065}. Best is trial 45 with value: 0.024644779944254437.\u001b[0m\nregularization_factors, val_score: 0.024645:  40%|####      | 8/20 [00:41<01:00,  5.04s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213423\tValid's rmse: 0.0246692\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246451\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070383 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  45%|####5     | 9/20 [00:46<00:54,  4.98s/it]\u001b[32m[I 2022-04-21 23:48:07,015]\u001b[0m Trial 51 finished with value: 0.024644760767164316 and parameters: {'lambda_l1': 0.051292551659189875, 'lambda_l2': 3.059249862231149e-08}. Best is trial 51 with value: 0.024644760767164316.\u001b[0m\nregularization_factors, val_score: 0.024645:  45%|####5     | 9/20 [00:46<00:54,  4.98s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213448\tValid's rmse: 0.0246707\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214577\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.152213 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  50%|#####     | 10/20 [00:51<00:50,  5.06s/it]\u001b[32m[I 2022-04-21 23:48:12,254]\u001b[0m Trial 52 finished with value: 0.0246450143590217 and parameters: {'lambda_l1': 5.619486078901678e-08, 'lambda_l2': 1.6368942479772284}. Best is trial 51 with value: 0.024644760767164316.\u001b[0m\nregularization_factors, val_score: 0.024645:  50%|#####     | 10/20 [00:51<00:50,  5.06s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021347\tValid's rmse: 0.0246671\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.024645\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070467 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  55%|#####5    | 11/20 [00:56<00:44,  4.98s/it]\u001b[32m[I 2022-04-21 23:48:17,047]\u001b[0m Trial 53 finished with value: 0.024645067540373704 and parameters: {'lambda_l1': 5.93500280573986e-05, 'lambda_l2': 1.9163169324546555e-08}. Best is trial 51 with value: 0.024644760767164316.\u001b[0m\nregularization_factors, val_score: 0.024645:  55%|#####5    | 11/20 [00:56<00:44,  4.98s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213423\tValid's rmse: 0.0246684\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246451\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069510 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  60%|######    | 12/20 [01:02<00:42,  5.36s/it]\u001b[32m[I 2022-04-21 23:48:23,264]\u001b[0m Trial 54 finished with value: 0.02464449638013395 and parameters: {'lambda_l1': 6.099752897348163, 'lambda_l2': 4.1451547451876815e-06}. Best is trial 54 with value: 0.02464449638013395.\u001b[0m\nregularization_factors, val_score: 0.024644:  60%|######    | 12/20 [01:02<00:42,  5.36s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214196\tValid's rmse: 0.0246596\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072850 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  65%|######5   | 13/20 [01:08<00:37,  5.37s/it]\u001b[32m[I 2022-04-21 23:48:28,667]\u001b[0m Trial 55 finished with value: 0.024644699172529417 and parameters: {'lambda_l1': 0.2768542830539499, 'lambda_l2': 1.3925167687126659e-08}. Best is trial 54 with value: 0.02464449638013395.\u001b[0m\nregularization_factors, val_score: 0.024644:  65%|######5   | 13/20 [01:08<00:37,  5.37s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213583\tValid's rmse: 0.024669\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084079 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  70%|#######   | 14/20 [01:14<00:34,  5.68s/it]\u001b[32m[I 2022-04-21 23:48:35,065]\u001b[0m Trial 56 finished with value: 0.02464450292133951 and parameters: {'lambda_l1': 9.211526426437048, 'lambda_l2': 2.5936283753534136e-06}. Best is trial 54 with value: 0.02464449638013395.\u001b[0m\nregularization_factors, val_score: 0.024644:  70%|#######   | 14/20 [01:14<00:34,  5.68s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214276\tValid's rmse: 0.0246584\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  75%|#######5  | 15/20 [01:21<00:30,  6.14s/it]\u001b[32m[I 2022-04-21 23:48:42,280]\u001b[0m Trial 57 finished with value: 0.024644504366941208 and parameters: {'lambda_l1': 7.293522501713165, 'lambda_l2': 1.3252666467184694e-05}. Best is trial 54 with value: 0.02464449638013395.\u001b[0m\nregularization_factors, val_score: 0.024644:  75%|#######5  | 15/20 [01:21<00:30,  6.14s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tTrain's rmse: 0.0214232\tValid's rmse: 0.0246586\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069836 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  80%|########  | 16/20 [01:26<00:22,  5.72s/it]\u001b[32m[I 2022-04-21 23:48:47,009]\u001b[0m Trial 58 finished with value: 0.024645067572789333 and parameters: {'lambda_l1': 1.825084098088943e-05, 'lambda_l2': 1.5365765223885232e-06}. Best is trial 54 with value: 0.02464449638013395.\u001b[0m\nregularization_factors, val_score: 0.024644:  80%|########  | 16/20 [01:26<00:22,  5.72s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213422\tValid's rmse: 0.0246687\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246451\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  85%|########5 | 17/20 [01:31<00:16,  5.51s/it]\u001b[32m[I 2022-04-21 23:48:52,053]\u001b[0m Trial 59 finished with value: 0.024644981353679284 and parameters: {'lambda_l1': 0.04946395836596592, 'lambda_l2': 0.00038214561203750284}. Best is trial 54 with value: 0.02464449638013395.\u001b[0m\nregularization_factors, val_score: 0.024644:  85%|########5 | 17/20 [01:31<00:16,  5.51s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213444\tValid's rmse: 0.0246716\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.024645\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069163 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  90%|######### | 18/20 [01:37<00:10,  5.44s/it]\u001b[32m[I 2022-04-21 23:48:57,326]\u001b[0m Trial 60 finished with value: 0.024644678974126654 and parameters: {'lambda_l1': 0.24007236806986643, 'lambda_l2': 2.1928969908659395e-07}. Best is trial 54 with value: 0.02464449638013395.\u001b[0m\nregularization_factors, val_score: 0.024644:  90%|######### | 18/20 [01:37<00:10,  5.44s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213554\tValid's rmse: 0.0246711\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069836 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644:  95%|#########5| 19/20 [01:43<00:05,  5.77s/it]\u001b[32m[I 2022-04-21 23:49:03,861]\u001b[0m Trial 61 finished with value: 0.024644475188824976 and parameters: {'lambda_l1': 9.530473438090175, 'lambda_l2': 3.943750829395814e-05}. Best is trial 61 with value: 0.024644475188824976.\u001b[0m\nregularization_factors, val_score: 0.024644:  95%|#########5| 19/20 [01:43<00:05,  5.77s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214284\tValid's rmse: 0.0246581\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070166 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024644: 100%|##########| 20/20 [01:48<00:00,  5.46s/it]\u001b[32m[I 2022-04-21 23:49:08,606]\u001b[0m Trial 62 finished with value: 0.024645067583283345 and parameters: {'lambda_l1': 1.6769440440474564e-06, 'lambda_l2': 8.181239944524647e-05}. Best is trial 61 with value: 0.024644475188824976.\u001b[0m\nregularization_factors, val_score: 0.024644: 100%|##########| 20/20 [01:48<00:00,  5.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213422\tValid's rmse: 0.0246687\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246451\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024644:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069911 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024644:  20%|##        | 1/5 [00:07<00:29,  7.38s/it]\u001b[32m[I 2022-04-21 23:49:15,993]\u001b[0m Trial 63 finished with value: 0.024644475188824976 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.024644475188824976.\u001b[0m\nmin_data_in_leaf, val_score: 0.024644:  20%|##        | 1/5 [00:07<00:29,  7.38s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214284\tValid's rmse: 0.0246581\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024644:  40%|####      | 2/5 [00:13<00:20,  6.79s/it]\u001b[32m[I 2022-04-21 23:49:22,371]\u001b[0m Trial 64 finished with value: 0.024644475188824976 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.024644475188824976.\u001b[0m\nmin_data_in_leaf, val_score: 0.024644:  40%|####      | 2/5 [00:13<00:20,  6.79s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214284\tValid's rmse: 0.0246581\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070270 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024644:  60%|######    | 3/5 [00:20<00:13,  6.62s/it]\u001b[32m[I 2022-04-21 23:49:28,798]\u001b[0m Trial 65 finished with value: 0.024644475188824976 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.024644475188824976.\u001b[0m\nmin_data_in_leaf, val_score: 0.024644:  60%|######    | 3/5 [00:20<00:13,  6.62s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214284\tValid's rmse: 0.0246581\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071990 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024644:  80%|########  | 4/5 [00:26<00:06,  6.50s/it]\u001b[32m[I 2022-04-21 23:49:35,105]\u001b[0m Trial 66 finished with value: 0.024644475188824976 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.024644475188824976.\u001b[0m\nmin_data_in_leaf, val_score: 0.024644:  80%|########  | 4/5 [00:26<00:06,  6.50s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214284\tValid's rmse: 0.0246581\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070794 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7173\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 29\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024644: 100%|##########| 5/5 [00:32<00:00,  6.45s/it]\u001b[32m[I 2022-04-21 23:49:41,458]\u001b[0m Trial 67 finished with value: 0.024644475188824976 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.024644475188824976.\u001b[0m\nmin_data_in_leaf, val_score: 0.024644: 100%|##########| 5/5 [00:32<00:00,  6.57s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214284\tValid's rmse: 0.0246581\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246445\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stderr","text":"[LightGBM] [Fatal] Model file /kaggle/working / model_0.txt is not available for writes\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3574298542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'2021-02-23'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2022-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2022-02-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/1199449174.py\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(feature_df, feat_cols, label_col, fold_params, seed)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{BASE_PATH} / model_{i}.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# model = lightgbm.Booster(model_file='lgbr_base.txt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, filename, num_iteration, start_iteration, importance_type)\u001b[0m\n\u001b[1;32m   3303\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3304\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_type_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3305\u001b[0;31m             c_str(str(filename))))\n\u001b[0m\u001b[1;32m   3306\u001b[0m         \u001b[0m_dump_pandas_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLightGBMError\u001b[0m: Model file /kaggle/working / model_0.txt is not available for writes"],"ename":"LightGBMError","evalue":"Model file /kaggle/working / model_0.txt is not available for writes","output_type":"error"}]}]}