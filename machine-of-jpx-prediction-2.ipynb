{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T23:56:22.598179Z","iopub.execute_input":"2022-04-21T23:56:22.599378Z","iopub.status.idle":"2022-04-21T23:56:22.607029Z","shell.execute_reply.started":"2022-04-21T23:56:22.599314Z","shell.execute_reply":"2022-04-21T23:56:22.605831Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# I/O Func\nBASE_PATH = Path(f'/kaggle/working')\n\ndef adjusting_price(price, key: str):\n    \"\"\"[Adjusting Close Price]\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n\n    def generate_adjusted(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, f\"CumulativeAdjustmentFactor{key}\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = (\n            df[f\"CumulativeAdjustmentFactor{key}\"] * df[key]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[f\"Adjusted{key}\"] == 0, f\"Adjusted{key}\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = df.loc[:, f\"Adjusted{key}\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted).reset_index(drop=True)\n\n    # price.set_index(\"Date\", inplace=True)\n    return price\n\ndef adjusting_volume(price, key = \"Volume\"):\n    \"\"\"[Adjusting Close Price]\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n\n    def generate_adjusted(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, f\"CumulativeAdjustmentFactor{key}\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = (\n            df[key] / df[f\"CumulativeAdjustmentFactor{key}\"]  \n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[f\"Adjusted{key}\"] == 0, f\"Adjusted{key}\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = df.loc[:, f\"Adjusted{key}\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted).reset_index(drop=True)\n\n    # price.set_index(\"Date\", inplace=True)\n    return price\n\ndef read_prices(dir_name: str, securities_code: int = None):\n    \"\"\"[Important: the dateset of 2020/10/1 is lost because of system failer in JPX, see: https://www.jpx.co.jp/corporate/news/news-releases/0060/20201019-01.html]\n    \n    \"\"\"\n    base_path = Path(f'../input/jpx-tokyo-stock-exchange-prediction/{dir_name}')\n    df = pd.read_csv(base_path / 'stock_prices.csv')\n    df.loc[: ,\"Date\"] = pd.to_datetime(df.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n    df = df[df['Open'].notna()]\n    if securities_code:\n        df = df[df[\"SecuritiesCode\"] == securities_code]\n    return df\n\ndef read_stock_list(securities_code: int = None, only_universe: bool = True):\n    df = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv')\n    df.loc[: ,\"EffectiveDate\"] = pd.to_datetime(df.loc[: ,\"EffectiveDate\"], format=\"%Y%m%d\")\n    if only_universe:\n        df = df[df['Universe0']]\n    if securities_code:\n        df = df[df[\"SecuritiesCode\"] == securities_code]\n    return df\n\ndef merge_data(prices, stock_list):\n    # stock_prices がベース\n    base_df = prices.copy()\n    \n    # stock_listと結合\n    _stock_list = stock_list.copy()\n    _stock_list.rename(columns={'Close': 'Close_x'}, inplace=True)\n    base_df = base_df.merge(_stock_list, on='SecuritiesCode', how=\"left\")\n    \n    return base_df\n\ndef read_train_data_by_price(securities_code: int = None, with_supplemental: bool = True):\n    \"\"\"[The train base is price dataset, the other data are joined to prices DF by left join]\n    \n    \"\"\"\n    # origin\n    df = merge_data(prices=read_prices(dir_name=\"train_files\", securities_code=securities_code), stock_list=read_stock_list(securities_code=securities_code))\n    \n    # supplyment\n    if with_supplemental:\n        supplemental_df = merge_data(prices=read_prices(dir_name=\"supplemental_files\", securities_code=securities_code), stock_list=read_stock_list(securities_code=securities_code))\n        df = pd.concat([df, supplemental_df]).reset_index(drop=True)\n        \n    df = adjusting_price(df, \"Close\")\n    df = adjusting_price(df, \"Open\")\n    df = adjusting_price(df, \"High\")\n    df = adjusting_price(df, \"Low\")\n    df = adjusting_volume(df)\n    return df\n\ndef collector(prices, options, financials, trades, secondary_prices, stock_list):\n    # 読み込んだデータを統合して一つのファイルに纏める\n    df = merge_data(prices, stock_list)\n    # AdjustedClose項目の生成\n    df = adjusting_price(df, \"Close\")\n    df = adjusting_price(df, \"Open\")\n    df = adjusting_price(df, \"High\")\n    df = adjusting_price(df, \"Low\")\n    df = adjusting_volume(df)\n    return df\n\ndef write_df(df, filename):\n    df.to_csv(BASE_PATH / f'{filename}.csv',index = False)\n    \nimport joblib\ndef write_model(model, name):\n    # save model\n    joblib.dump(model, f'{BASE_PATH}/{name}.pkl')\n\n\n# load model\ndef read_model(name):\n    return joblib.load(f'{BASE_PATH}/{name}.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:59:32.984598Z","iopub.execute_input":"2022-04-22T01:59:32.984920Z","iopub.status.idle":"2022-04-22T01:59:33.019542Z","shell.execute_reply.started":"2022-04-22T01:59:32.984890Z","shell.execute_reply":"2022-04-22T01:59:33.018838Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_df = read_train_data_by_price()\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:56:22.649187Z","iopub.execute_input":"2022-04-21T23:56:22.649425Z","iopub.status.idle":"2022-04-21T23:58:38.515942Z","shell.execute_reply.started":"2022-04-21T23:56:22.649399Z","shell.execute_reply":"2022-04-21T23:58:38.514765Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                 RowId       Date  SecuritiesCode    Open    High     Low  \\\n0        20170104_1301 2017-01-04            1301  2734.0  2755.0  2730.0   \n1        20170105_1301 2017-01-05            1301  2743.0  2747.0  2735.0   \n2        20170106_1301 2017-01-06            1301  2734.0  2744.0  2720.0   \n3        20170110_1301 2017-01-10            1301  2745.0  2754.0  2735.0   \n4        20170111_1301 2017-01-11            1301  2748.0  2752.0  2737.0   \n...                ...        ...             ...     ...     ...     ...   \n2436634  20220221_9997 2022-02-21            9997   725.0   729.0   719.0   \n2436635  20220222_9997 2022-02-22            9997   719.0   723.0   711.0   \n2436636  20220224_9997 2022-02-24            9997   709.0   725.0   708.0   \n2436637  20220225_9997 2022-02-25            9997   725.0   738.0   724.0   \n2436638  20220228_9997 2022-02-28            9997   731.0   737.0   726.0   \n\n          Close  Volume  AdjustmentFactor  ExpectedDividend  ...  \\\n0        2742.0   31400               1.0               NaN  ...   \n1        2738.0   17900               1.0               NaN  ...   \n2        2740.0   19900               1.0               NaN  ...   \n3        2748.0   24200               1.0               NaN  ...   \n4        2745.0    9300               1.0               NaN  ...   \n...         ...     ...               ...               ...  ...   \n2436634   727.0  116400               1.0               NaN  ...   \n2436635   721.0  225500               1.0               NaN  ...   \n2436636   719.0  195600               1.0               NaN  ...   \n2436637   733.0  170500               1.0               NaN  ...   \n2436638   734.0  288100               1.0               NaN  ...   \n\n         CumulativeAdjustmentFactorClose  AdjustedClose  \\\n0                                    1.0         2742.0   \n1                                    1.0         2738.0   \n2                                    1.0         2740.0   \n3                                    1.0         2748.0   \n4                                    1.0         2745.0   \n...                                  ...            ...   \n2436634                              1.0          727.0   \n2436635                              1.0          721.0   \n2436636                              1.0          719.0   \n2436637                              1.0          733.0   \n2436638                              1.0          734.0   \n\n        CumulativeAdjustmentFactorOpen AdjustedOpen  \\\n0                                  1.0       2734.0   \n1                                  1.0       2743.0   \n2                                  1.0       2734.0   \n3                                  1.0       2745.0   \n4                                  1.0       2748.0   \n...                                ...          ...   \n2436634                            1.0        725.0   \n2436635                            1.0        719.0   \n2436636                            1.0        709.0   \n2436637                            1.0        725.0   \n2436638                            1.0        731.0   \n\n        CumulativeAdjustmentFactorHigh AdjustedHigh  \\\n0                                  1.0       2755.0   \n1                                  1.0       2747.0   \n2                                  1.0       2744.0   \n3                                  1.0       2754.0   \n4                                  1.0       2752.0   \n...                                ...          ...   \n2436634                            1.0        729.0   \n2436635                            1.0        723.0   \n2436636                            1.0        725.0   \n2436637                            1.0        738.0   \n2436638                            1.0        737.0   \n\n        CumulativeAdjustmentFactorLow AdjustedLow  \\\n0                                 1.0      2730.0   \n1                                 1.0      2735.0   \n2                                 1.0      2720.0   \n3                                 1.0      2735.0   \n4                                 1.0      2737.0   \n...                               ...         ...   \n2436634                           1.0       719.0   \n2436635                           1.0       711.0   \n2436636                           1.0       708.0   \n2436637                           1.0       724.0   \n2436638                           1.0       726.0   \n\n        CumulativeAdjustmentFactorVolume AdjustedVolume  \n0                                    1.0        31400.0  \n1                                    1.0        17900.0  \n2                                    1.0        19900.0  \n3                                    1.0        24200.0  \n4                                    1.0         9300.0  \n...                                  ...            ...  \n2436634                              1.0       116400.0  \n2436635                              1.0       225500.0  \n2436636                              1.0       195600.0  \n2436637                              1.0       170500.0  \n2436638                              1.0       288100.0  \n\n[2436639 rows x 37 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowId</th>\n      <th>Date</th>\n      <th>SecuritiesCode</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>AdjustmentFactor</th>\n      <th>ExpectedDividend</th>\n      <th>...</th>\n      <th>CumulativeAdjustmentFactorClose</th>\n      <th>AdjustedClose</th>\n      <th>CumulativeAdjustmentFactorOpen</th>\n      <th>AdjustedOpen</th>\n      <th>CumulativeAdjustmentFactorHigh</th>\n      <th>AdjustedHigh</th>\n      <th>CumulativeAdjustmentFactorLow</th>\n      <th>AdjustedLow</th>\n      <th>CumulativeAdjustmentFactorVolume</th>\n      <th>AdjustedVolume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20170104_1301</td>\n      <td>2017-01-04</td>\n      <td>1301</td>\n      <td>2734.0</td>\n      <td>2755.0</td>\n      <td>2730.0</td>\n      <td>2742.0</td>\n      <td>31400</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2742.0</td>\n      <td>1.0</td>\n      <td>2734.0</td>\n      <td>1.0</td>\n      <td>2755.0</td>\n      <td>1.0</td>\n      <td>2730.0</td>\n      <td>1.0</td>\n      <td>31400.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20170105_1301</td>\n      <td>2017-01-05</td>\n      <td>1301</td>\n      <td>2743.0</td>\n      <td>2747.0</td>\n      <td>2735.0</td>\n      <td>2738.0</td>\n      <td>17900</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2738.0</td>\n      <td>1.0</td>\n      <td>2743.0</td>\n      <td>1.0</td>\n      <td>2747.0</td>\n      <td>1.0</td>\n      <td>2735.0</td>\n      <td>1.0</td>\n      <td>17900.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20170106_1301</td>\n      <td>2017-01-06</td>\n      <td>1301</td>\n      <td>2734.0</td>\n      <td>2744.0</td>\n      <td>2720.0</td>\n      <td>2740.0</td>\n      <td>19900</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2740.0</td>\n      <td>1.0</td>\n      <td>2734.0</td>\n      <td>1.0</td>\n      <td>2744.0</td>\n      <td>1.0</td>\n      <td>2720.0</td>\n      <td>1.0</td>\n      <td>19900.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20170110_1301</td>\n      <td>2017-01-10</td>\n      <td>1301</td>\n      <td>2745.0</td>\n      <td>2754.0</td>\n      <td>2735.0</td>\n      <td>2748.0</td>\n      <td>24200</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2748.0</td>\n      <td>1.0</td>\n      <td>2745.0</td>\n      <td>1.0</td>\n      <td>2754.0</td>\n      <td>1.0</td>\n      <td>2735.0</td>\n      <td>1.0</td>\n      <td>24200.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20170111_1301</td>\n      <td>2017-01-11</td>\n      <td>1301</td>\n      <td>2748.0</td>\n      <td>2752.0</td>\n      <td>2737.0</td>\n      <td>2745.0</td>\n      <td>9300</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2745.0</td>\n      <td>1.0</td>\n      <td>2748.0</td>\n      <td>1.0</td>\n      <td>2752.0</td>\n      <td>1.0</td>\n      <td>2737.0</td>\n      <td>1.0</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2436634</th>\n      <td>20220221_9997</td>\n      <td>2022-02-21</td>\n      <td>9997</td>\n      <td>725.0</td>\n      <td>729.0</td>\n      <td>719.0</td>\n      <td>727.0</td>\n      <td>116400</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>727.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>729.0</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>116400.0</td>\n    </tr>\n    <tr>\n      <th>2436635</th>\n      <td>20220222_9997</td>\n      <td>2022-02-22</td>\n      <td>9997</td>\n      <td>719.0</td>\n      <td>723.0</td>\n      <td>711.0</td>\n      <td>721.0</td>\n      <td>225500</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>721.0</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>723.0</td>\n      <td>1.0</td>\n      <td>711.0</td>\n      <td>1.0</td>\n      <td>225500.0</td>\n    </tr>\n    <tr>\n      <th>2436636</th>\n      <td>20220224_9997</td>\n      <td>2022-02-24</td>\n      <td>9997</td>\n      <td>709.0</td>\n      <td>725.0</td>\n      <td>708.0</td>\n      <td>719.0</td>\n      <td>195600</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>709.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>708.0</td>\n      <td>1.0</td>\n      <td>195600.0</td>\n    </tr>\n    <tr>\n      <th>2436637</th>\n      <td>20220225_9997</td>\n      <td>2022-02-25</td>\n      <td>9997</td>\n      <td>725.0</td>\n      <td>738.0</td>\n      <td>724.0</td>\n      <td>733.0</td>\n      <td>170500</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>733.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>738.0</td>\n      <td>1.0</td>\n      <td>724.0</td>\n      <td>1.0</td>\n      <td>170500.0</td>\n    </tr>\n    <tr>\n      <th>2436638</th>\n      <td>20220228_9997</td>\n      <td>2022-02-28</td>\n      <td>9997</td>\n      <td>731.0</td>\n      <td>737.0</td>\n      <td>726.0</td>\n      <td>734.0</td>\n      <td>288100</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>734.0</td>\n      <td>1.0</td>\n      <td>731.0</td>\n      <td>1.0</td>\n      <td>737.0</td>\n      <td>1.0</td>\n      <td>726.0</td>\n      <td>1.0</td>\n      <td>288100.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2436639 rows × 37 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Featrue","metadata":{}},{"cell_type":"code","source":"def cal_moving_average(key:str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"MovingAverage{key}{period}\"\n            col_gap = f\"{col}GapPercent\"\n            df[col] = df[key].rolling(period, min_periods=1).mean()\n            df[col_gap] = (df[key] / df[col]) * 100.0\n        return df\n    return func\n\ndef cal_changing_ration(key:str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"ChangingRatio{key}{period}\"\n            df[col] = df[key].pct_change(period) * 100\n        return df\n    return func\n\ndef cal_historical_vix(key: str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"HistoricalVIX{key}{period}\"\n            df[col] = np.log(df[key]).diff().rolling(period).std()\n        return df\n    return func\n\ndef add_columns_per_code(df, functions):\n    def func(df):\n        for f in functions:\n            df = f(df)\n        return df\n    df = df.sort_values([\"SecuritiesCode\", \"Date\"])\n    df = df.groupby(\"SecuritiesCode\").apply(func)\n    df = df.reset_index(drop=True)\n    return df\n\ndef add_columns_per_day(base_df):\n    base_df['diff_rate1'] = (base_df['Close'] - base_df['Open']) / base_df['Close']\n    base_df['diff_rate2'] = (base_df['High'] - base_df['Low']) / base_df['Close']    \n    return base_df\n\ndef generate_features(df):\n    base_df = df.copy()\n    prev_column_names = base_df.columns\n    periods = [5, 25, 75]\n    functions = [\n        cal_moving_average(\"AdjustedClose\", periods),\n        cal_moving_average(\"AdjustedOpen\", periods),\n        cal_moving_average(\"AdjustedHigh\", periods),\n        cal_moving_average(\"AdjustedLow\", periods),\n        cal_moving_average(\"AdjustedVolume\", periods),\n        cal_changing_ration(\"AdjustedClose\", periods),\n        cal_changing_ration(\"AdjustedOpen\", periods),\n        cal_changing_ration(\"AdjustedHigh\", periods),\n        cal_changing_ration(\"AdjustedLow\", periods),\n        cal_changing_ration(\"AdjustedVolume\", periods),\n        cal_historical_vix(\"AdjustedClose\", periods),\n        cal_historical_vix(\"AdjustedOpen\", periods),\n        cal_historical_vix(\"AdjustedHigh\", periods),\n        cal_historical_vix(\"AdjustedLow\", periods),\n        cal_historical_vix(\"AdjustedVolume\", periods)\n    ]\n    \n    base_df = add_columns_per_code(base_df, functions)\n    base_df = add_columns_per_day(base_df)\n    \n    add_column_names = list(set(base_df.columns) - set(prev_column_names))\n    #feats = feats[feats[\"HistoricalVIXAdjustedClose75\"] != 0]\n    return base_df, add_column_names\n\ndef select_features(feature_df, add_column_names, is_train):\n    base_cols = ['RowId', 'Date', 'SecuritiesCode']\n    numerical_cols = sorted(add_column_names)\n    categorical_cols = ['NewMarketSegment', '33SectorCode', '17SectorCode']\n    label_col = ['Target']\n    feat_cols = numerical_cols + categorical_cols\n    feature_df = feature_df[base_cols + feat_cols + label_col]\n    feature_df[categorical_cols] = feature_df[categorical_cols].astype('category')\n    if is_train:\n        feature_df.dropna(inplace=True)\n    else:\n        feature_df[numerical_cols] = feature_df[numerical_cols].fillna(0)\n        feature_df[numerical_cols] = feature_df[numerical_cols].replace([np.inf, -np.inf], 0)\n    return feature_df, feat_cols, label_col\n\ndef preprocessor(base_df, is_train=True):\n    feature_df = base_df.copy()\n    \n    ## 特徴量生成\n    feature_df, add_column_names = generate_features(feature_df)\n    \n    ## 特徴量選択\n    feature_df, feat_cols, label_col = select_features(feature_df, add_column_names, is_train)\n\n    return feature_df, feat_cols, label_col\n\nfeature_df, feat_cols, label_col = preprocessor(train_df)\n\n# modelの結果をもとにfeat_colsを上書き\nfeat_cols = ['33SectorCode', 'ChangingRatioAdjustedVolume25', 'diff_rate2', 'MovingAverageAdjustedHigh5GapPercent', 'MovingAverageAdjustedOpen5GapPercent', 'HistoricalVIXAdjustedLow5', 'MovingAverageAdjustedClose5GapPercent', 'HistoricalVIXAdjustedOpen5', 'MovingAverageAdjustedLow25GapPercent', 'ChangingRatioAdjustedVolume5', 'HistoricalVIXAdjustedOpen75', 'HistoricalVIXAdjustedVolume5', 'MovingAverageAdjustedVolume25GapPercent', 'diff_rate1', 'ChangingRatioAdjustedHigh5', 'ChangingRatioAdjustedOpen25', 'HistoricalVIXAdjustedOpen25', 'MovingAverageAdjustedClose25GapPercent', 'MovingAverageAdjustedVolume75GapPercent', 'ChangingRatioAdjustedLow25', 'ChangingRatioAdjustedLow5', 'HistoricalVIXAdjustedHigh75', 'MovingAverageAdjustedLow5GapPercent', 'ChangingRatioAdjustedClose75', 'MovingAverageAdjustedClose75', 'MovingAverageAdjustedClose75GapPercent', 'HistoricalVIXAdjustedVolume75']\nfeat_cols","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:58:38.518553Z","iopub.execute_input":"2022-04-21T23:58:38.519070Z","iopub.status.idle":"2022-04-22T00:00:44.509012Z","shell.execute_reply.started":"2022-04-21T23:58:38.519016Z","shell.execute_reply":"2022-04-22T00:00:44.508064Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['33SectorCode',\n 'ChangingRatioAdjustedVolume25',\n 'diff_rate2',\n 'MovingAverageAdjustedHigh5GapPercent',\n 'MovingAverageAdjustedOpen5GapPercent',\n 'HistoricalVIXAdjustedLow5',\n 'MovingAverageAdjustedClose5GapPercent',\n 'HistoricalVIXAdjustedOpen5',\n 'MovingAverageAdjustedLow25GapPercent',\n 'ChangingRatioAdjustedVolume5',\n 'HistoricalVIXAdjustedOpen75',\n 'HistoricalVIXAdjustedVolume5',\n 'MovingAverageAdjustedVolume25GapPercent',\n 'diff_rate1',\n 'ChangingRatioAdjustedHigh5',\n 'ChangingRatioAdjustedOpen25',\n 'HistoricalVIXAdjustedOpen25',\n 'MovingAverageAdjustedClose25GapPercent',\n 'MovingAverageAdjustedVolume75GapPercent',\n 'ChangingRatioAdjustedLow25',\n 'ChangingRatioAdjustedLow5',\n 'HistoricalVIXAdjustedHigh75',\n 'MovingAverageAdjustedLow5GapPercent',\n 'ChangingRatioAdjustedClose75',\n 'MovingAverageAdjustedClose75',\n 'MovingAverageAdjustedClose75GapPercent',\n 'HistoricalVIXAdjustedVolume75']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Learning","metadata":{}},{"cell_type":"code","source":"# 予測値を降順に並べて順位番号を振る関数\n# 言い換えると、目的変数から提出用項目を導出する関数\ndef add_rank(df, col_name=\"pred\"):\n    df[\"Rank\"] = df.groupby(\"Date\")[col_name].rank(ascending=False, method=\"first\") - 1 \n    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n    return df\n\ndef calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio\n\n# 予測用のデータフレームと、予測結果をもとに、スコアを計算する関数\ndef evaluator(df, pred):\n    df[\"pred\"] = pred\n    df = add_rank(df)\n    score = calc_spread_return_sharpe(df)\n    return score\n\nimport lightgbm as lgb\nimport optuna.integration.lightgbm as lgb\n\n# 学習を実行する関数\ndef trainer(feature_df, feat_cols, label_col, fold_params, seed=2022):\n    scores = []\n    models = []\n    params = []\n    i = 0\n    for param in fold_params:\n        ################################\n        # データ準備\n        ################################\n        train = feature_df[(param[0] <= feature_df['Date']) & (feature_df['Date'] < param[1])]\n        valid = feature_df[(param[1] <= feature_df['Date']) & (feature_df['Date'] < param[2])]\n\n        X_train = train[feat_cols]\n        y_train = train[label_col]\n        X_valid = valid[feat_cols]\n        y_valid = valid[label_col]\n        \n        lgb_train = lgb.Dataset(X_train, y_train)\n        lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n\n        ################################\n        # 学習\n        ################################\n        params = {\n            'task': 'train',                   # 学習\n            'boosting_type': 'gbdt',           # GBDT\n            'objective': 'regression',         # 回帰\n            'metric': 'rmse',                  # 損失（誤差）\n            'learning_rate': 0.01,             # 学習率\n            'lambda_l1': 0.5,                  # L1正則化項の係数\n            'lambda_l2': 0.5,                  # L2正則化項の係数\n            'num_leaves': 10,                  # 最大葉枚数\n            'feature_fraction': 0.5,           # ランダムに抽出される列の割合\n            'bagging_fraction': 0.5,           # ランダムに抽出される標本の割合\n            'bagging_freq': 5,                 # バギング実施頻度\n            'min_child_samples': 10,           # 葉に含まれる最小データ数\n            'seed': seed                       # シード値\n        } \n \n        lgb_results = {}                       \n        model = lgb.train( \n            params,                            # ハイパーパラメータ\n            lgb_train,                         # 訓練データ\n            valid_sets=[lgb_train, lgb_valid], # 検証データ\n            valid_names=['Train', 'Valid'],    # データセット名前\n            num_boost_round=2000,              # 計算回数\n            early_stopping_rounds=100,         # 計算打ち切り設定\n            evals_result=lgb_results,          # 学習の履歴\n            verbose_eval=100,                  # 学習過程の表示サイクル\n        )  \n\n        ################################\n        # 結果描画\n        ################################\n        fig = plt.figure(figsize=(10, 4))\n\n        # loss\n        plt.subplot(1,2,1)\n        loss_train = lgb_results['Train']['rmse']\n        loss_test = lgb_results['Valid']['rmse']   \n        plt.xlabel('Iteration')\n        plt.ylabel('logloss')\n        plt.plot(loss_train, label='train loss')\n        plt.plot(loss_test, label='valid loss')\n        plt.legend()\n\n        # feature importance\n        plt.subplot(1,2,2)\n        importance = pd.DataFrame({'feature':feat_cols, 'importance':model.feature_importance()})\n        write_df(importance, f\"importance_{i}\")\n        sns.barplot(x = 'importance', y = 'feature', data = importance.sort_values('importance', ascending=False))\n\n        plt.tight_layout()\n        plt.show()\n\n        ################################\n        # 評価\n        ################################\n        # 推論\n        pred =  model.predict(X_valid, num_iteration=model.best_iteration)\n        # 評価\n        score = evaluator(valid, pred)\n\n        scores.append(score)\n        models.append(model)\n        # save model\n        write_model(model, f'model_{i}.txt')\n        i = i + 1\n        # model = lightgbm.Booster(model_file='lgbr_base.txt')\n\n    print(\"CV_SCORES:\", scores)\n    print(\"CV_SCORE:\", np.mean(scores))\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:00:44.510717Z","iopub.execute_input":"2022-04-22T00:00:44.511042Z","iopub.status.idle":"2022-04-22T00:00:44.540322Z","shell.execute_reply.started":"2022-04-22T00:00:44.511001Z","shell.execute_reply":"2022-04-22T00:00:44.539757Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# 2020-12-23よりも前のデータは証券コードが2000個すべて揃っていないため、これ以降のデータのみを使う。\n# (学習用データの開始日、学習用データの終了日＝検証用データの開始日、検証用データの終了日)\nfold_params = [\n    ('2020-12-23', '2021-11-01', '2021-12-01'),\n    ('2021-01-23', '2021-12-01', '2022-01-01'),\n    ('2021-02-23', '2022-01-01', '2022-02-01'),\n]\nmodels = trainer(feature_df, feat_cols, label_col, fold_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:00:44.541803Z","iopub.execute_input":"2022-04-22T00:00:44.542517Z","iopub.status.idle":"2022-04-22T01:09:24.580470Z","shell.execute_reply.started":"2022-04-22T00:00:44.542454Z","shell.execute_reply":"2022-04-22T01:09:24.579553Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-04-22 00:00:44,724]\u001b[0m A new study created in memory with name: no-name-689f609f-c268-4659-879f-15de8b69f9f0\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061575 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  14%|#4        | 1/7 [00:03<00:21,  3.53s/it]\u001b[32m[I 2022-04-22 00:00:48,262]\u001b[0m Trial 0 finished with value: 0.02464466028893019 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  14%|#4        | 1/7 [00:03<00:21,  3.53s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214241\tValid's rmse: 0.0246651\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061488 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  29%|##8       | 2/7 [00:06<00:17,  3.47s/it]\u001b[32m[I 2022-04-22 00:00:51,687]\u001b[0m Trial 1 finished with value: 0.024644775051576195 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  29%|##8       | 2/7 [00:06<00:17,  3.47s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214249\tValid's rmse: 0.0246652\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214582\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070592 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  43%|####2     | 3/7 [00:11<00:15,  3.86s/it]\u001b[32m[I 2022-04-22 00:00:56,008]\u001b[0m Trial 2 finished with value: 0.024644748291800075 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  43%|####2     | 3/7 [00:11<00:15,  3.86s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214216\tValid's rmse: 0.0246665\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058601 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  57%|#####7    | 4/7 [00:14<00:10,  3.66s/it]\u001b[32m[I 2022-04-22 00:00:59,357]\u001b[0m Trial 3 finished with value: 0.024644844918831402 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  57%|#####7    | 4/7 [00:14<00:10,  3.66s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214272\tValid's rmse: 0.0246639\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214582\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  71%|#######1  | 5/7 [00:18<00:07,  3.70s/it]\u001b[32m[I 2022-04-22 00:01:03,131]\u001b[0m Trial 4 finished with value: 0.02464474349138154 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  71%|#######1  | 5/7 [00:18<00:07,  3.70s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021421\tValid's rmse: 0.0246673\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068215 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  86%|########5 | 6/7 [00:22<00:03,  3.69s/it]\u001b[32m[I 2022-04-22 00:01:06,797]\u001b[0m Trial 5 finished with value: 0.02464466028893019 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  86%|########5 | 6/7 [00:22<00:03,  3.69s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214222\tValid's rmse: 0.0246653\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066527 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645: 100%|##########| 7/7 [00:25<00:00,  3.71s/it]\u001b[32m[I 2022-04-22 00:01:10,549]\u001b[0m Trial 6 finished with value: 0.02464466028893019 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645: 100%|##########| 7/7 [00:25<00:00,  3.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214233\tValid's rmse: 0.0246642\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246447\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:   5%|5         | 1/20 [00:04<01:23,  4.38s/it]\u001b[32m[I 2022-04-22 00:01:14,939]\u001b[0m Trial 7 finished with value: 0.024644750244441238 and parameters: {'num_leaves': 27}. Best is trial 7 with value: 0.024644750244441238.\u001b[0m\nnum_leaves, val_score: 0.024645:   5%|5         | 1/20 [00:04<01:23,  4.38s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213974\tValid's rmse: 0.0246668\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214583\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063769 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  10%|#         | 2/20 [00:08<01:13,  4.06s/it]\u001b[32m[I 2022-04-22 00:01:18,774]\u001b[0m Trial 8 finished with value: 0.024644694870800517 and parameters: {'num_leaves': 14}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  10%|#         | 2/20 [00:08<01:13,  4.06s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214164\tValid's rmse: 0.0246656\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062483 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  15%|#5        | 3/20 [00:15<01:33,  5.49s/it]\u001b[32m[I 2022-04-22 00:01:25,975]\u001b[0m Trial 9 finished with value: 0.02464479234995584 and parameters: {'num_leaves': 88}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  15%|#5        | 3/20 [00:15<01:33,  5.49s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213424\tValid's rmse: 0.0246706\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214576\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062271 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  20%|##        | 4/20 [00:22<01:39,  6.24s/it]\u001b[32m[I 2022-04-22 00:01:33,362]\u001b[0m Trial 10 finished with value: 0.02464485991675705 and parameters: {'num_leaves': 139}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  20%|##        | 4/20 [00:22<01:39,  6.24s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213107\tValid's rmse: 0.0246716\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214572\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  25%|##5       | 5/20 [00:29<01:38,  6.57s/it]\u001b[32m[I 2022-04-22 00:01:40,513]\u001b[0m Trial 11 finished with value: 0.02464486583124385 and parameters: {'num_leaves': 144}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  25%|##5       | 5/20 [00:29<01:38,  6.57s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213083\tValid's rmse: 0.024672\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214572\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081970 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  30%|###       | 6/20 [00:34<01:23,  5.99s/it]\u001b[32m[I 2022-04-22 00:01:45,379]\u001b[0m Trial 12 finished with value: 0.02464478452210894 and parameters: {'num_leaves': 37}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  30%|###       | 6/20 [00:34<01:23,  5.99s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213861\tValid's rmse: 0.0246683\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214582\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061986 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  35%|###5      | 7/20 [00:41<01:22,  6.32s/it]\u001b[32m[I 2022-04-22 00:01:52,391]\u001b[0m Trial 13 finished with value: 0.024644876814261148 and parameters: {'num_leaves': 143}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  35%|###5      | 7/20 [00:41<01:22,  6.32s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213089\tValid's rmse: 0.0246718\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214572\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  40%|####      | 8/20 [00:51<01:27,  7.28s/it]\u001b[32m[I 2022-04-22 00:02:01,723]\u001b[0m Trial 14 finished with value: 0.024644772012806432 and parameters: {'num_leaves': 241}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  40%|####      | 8/20 [00:51<01:27,  7.28s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212618\tValid's rmse: 0.0246713\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214567\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061832 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  45%|####5     | 9/20 [00:59<01:24,  7.67s/it]\u001b[32m[I 2022-04-22 00:02:10,260]\u001b[0m Trial 15 finished with value: 0.024644770071387115 and parameters: {'num_leaves': 250}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  45%|####5     | 9/20 [00:59<01:24,  7.67s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212578\tValid's rmse: 0.0246712\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214567\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062069 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  50%|#####     | 10/20 [01:08<01:19,  7.92s/it]\u001b[32m[I 2022-04-22 00:02:18,741]\u001b[0m Trial 16 finished with value: 0.024644765996422426 and parameters: {'num_leaves': 248}. Best is trial 8 with value: 0.024644694870800517.\u001b[0m\nnum_leaves, val_score: 0.024645:  50%|#####     | 10/20 [01:08<01:19,  7.92s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212587\tValid's rmse: 0.0246715\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214567\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062517 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  55%|#####5    | 11/20 [01:11<00:57,  6.40s/it]\u001b[32m[I 2022-04-22 00:02:21,682]\u001b[0m Trial 17 finished with value: 0.02464461324977589 and parameters: {'num_leaves': 5}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  55%|#####5    | 11/20 [01:11<00:57,  6.40s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214369\tValid's rmse: 0.0246646\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061060 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  60%|######    | 12/20 [01:14<00:44,  5.61s/it]\u001b[32m[I 2022-04-22 00:02:25,473]\u001b[0m Trial 18 finished with value: 0.024644694870800517 and parameters: {'num_leaves': 14}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  60%|######    | 12/20 [01:14<00:44,  5.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214164\tValid's rmse: 0.0246656\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062533 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  65%|######5   | 13/20 [01:21<00:41,  5.91s/it]\u001b[32m[I 2022-04-22 00:02:32,068]\u001b[0m Trial 19 finished with value: 0.02464476496727503 and parameters: {'num_leaves': 67}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  65%|######5   | 13/20 [01:21<00:41,  5.91s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213584\tValid's rmse: 0.0246703\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214578\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062105 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  70%|#######   | 14/20 [01:24<00:29,  4.90s/it]\u001b[32m[I 2022-04-22 00:02:34,642]\u001b[0m Trial 20 finished with value: 0.0246448003182596 and parameters: {'num_leaves': 3}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  70%|#######   | 14/20 [01:24<00:29,  4.90s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214441\tValid's rmse: 0.0246634\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214588\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061738 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  75%|#######5  | 15/20 [01:30<00:26,  5.24s/it]\u001b[32m[I 2022-04-22 00:02:40,687]\u001b[0m Trial 21 finished with value: 0.02464476704499358 and parameters: {'num_leaves': 81}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  75%|#######5  | 15/20 [01:30<00:26,  5.24s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213475\tValid's rmse: 0.024671\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214577\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  80%|########  | 16/20 [01:35<00:21,  5.27s/it]\u001b[32m[I 2022-04-22 00:02:46,028]\u001b[0m Trial 22 finished with value: 0.02464483951099428 and parameters: {'num_leaves': 52}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  80%|########  | 16/20 [01:35<00:21,  5.27s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021371\tValid's rmse: 0.0246701\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021458\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066313 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  85%|########5 | 17/20 [01:43<00:17,  5.99s/it]\u001b[32m[I 2022-04-22 00:02:53,701]\u001b[0m Trial 23 finished with value: 0.02464480368129133 and parameters: {'num_leaves': 187}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  85%|########5 | 17/20 [01:43<00:17,  5.99s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212855\tValid's rmse: 0.0246705\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021457\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062642 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  90%|######### | 18/20 [01:49<00:12,  6.20s/it]\u001b[32m[I 2022-04-22 00:03:00,382]\u001b[0m Trial 24 finished with value: 0.02464473457635151 and parameters: {'num_leaves': 102}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  90%|######### | 18/20 [01:49<00:12,  6.20s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213328\tValid's rmse: 0.0246716\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214575\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208456 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  95%|#########5| 19/20 [01:56<00:06,  6.27s/it]\u001b[32m[I 2022-04-22 00:03:06,822]\u001b[0m Trial 25 finished with value: 0.024644781483954638 and parameters: {'num_leaves': 47}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  95%|#########5| 19/20 [01:56<00:06,  6.27s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213761\tValid's rmse: 0.0246696\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021458\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062342 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645: 100%|##########| 20/20 [02:02<00:00,  6.38s/it]\u001b[32m[I 2022-04-22 00:03:13,452]\u001b[0m Trial 26 finished with value: 0.024644729265274407 and parameters: {'num_leaves': 108}. Best is trial 17 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645: 100%|##########| 20/20 [02:02<00:00,  6.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021329\tValid's rmse: 0.024672\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214575\tValid's rmse: 0.0246447\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  10%|#         | 1/10 [00:03<00:28,  3.15s/it]\u001b[32m[I 2022-04-22 00:03:16,614]\u001b[0m Trial 27 finished with value: 0.02464468830759929 and parameters: {'bagging_fraction': 0.6541491880095067, 'bagging_freq': 6}. Best is trial 27 with value: 0.02464468830759929.\u001b[0m\nbagging, val_score: 0.024645:  10%|#         | 1/10 [00:03<00:28,  3.15s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214369\tValid's rmse: 0.0246646\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062572 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  20%|##        | 2/10 [00:06<00:25,  3.23s/it]\u001b[32m[I 2022-04-22 00:03:19,902]\u001b[0m Trial 28 finished with value: 0.02464468792101564 and parameters: {'bagging_fraction': 0.6691934832403849, 'bagging_freq': 6}. Best is trial 28 with value: 0.02464468792101564.\u001b[0m\nbagging, val_score: 0.024645:  20%|##        | 2/10 [00:06<00:25,  3.23s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214371\tValid's rmse: 0.0246649\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063645 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  30%|###       | 3/10 [00:10<00:24,  3.45s/it]\u001b[32m[I 2022-04-22 00:03:23,605]\u001b[0m Trial 29 finished with value: 0.024644734585852656 and parameters: {'bagging_fraction': 0.9512837471063342, 'bagging_freq': 4}. Best is trial 28 with value: 0.02464468792101564.\u001b[0m\nbagging, val_score: 0.024645:  30%|###       | 3/10 [00:10<00:24,  3.45s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246681\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062023 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  40%|####      | 4/10 [00:13<00:19,  3.26s/it]\u001b[32m[I 2022-04-22 00:03:26,585]\u001b[0m Trial 30 finished with value: 0.024644593316397578 and parameters: {'bagging_fraction': 0.459638284322843, 'bagging_freq': 4}. Best is trial 30 with value: 0.024644593316397578.\u001b[0m\nbagging, val_score: 0.024645:  40%|####      | 4/10 [00:13<00:19,  3.26s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246653\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062978 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  50%|#####     | 5/10 [00:16<00:16,  3.24s/it]\u001b[32m[I 2022-04-22 00:03:29,794]\u001b[0m Trial 31 finished with value: 0.024644695117054725 and parameters: {'bagging_fraction': 0.6635193526939398, 'bagging_freq': 6}. Best is trial 30 with value: 0.024644593316397578.\u001b[0m\nbagging, val_score: 0.024645:  50%|#####     | 5/10 [00:16<00:16,  3.24s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214371\tValid's rmse: 0.024665\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066339 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  60%|######    | 6/10 [00:21<00:15,  3.79s/it]\u001b[32m[I 2022-04-22 00:03:34,655]\u001b[0m Trial 32 finished with value: 0.024644735905034215 and parameters: {'bagging_fraction': 0.9724204587512449, 'bagging_freq': 2}. Best is trial 30 with value: 0.024644593316397578.\u001b[0m\nbagging, val_score: 0.024645:  60%|######    | 6/10 [00:21<00:15,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246685\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069043 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  70%|#######   | 7/10 [00:24<00:10,  3.57s/it]\u001b[32m[I 2022-04-22 00:03:37,775]\u001b[0m Trial 33 finished with value: 0.02464466910070667 and parameters: {'bagging_fraction': 0.5705552661880031, 'bagging_freq': 4}. Best is trial 30 with value: 0.024644593316397578.\u001b[0m\nbagging, val_score: 0.024645:  70%|#######   | 7/10 [00:24<00:10,  3.57s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214365\tValid's rmse: 0.0246668\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  80%|########  | 8/10 [00:27<00:07,  3.58s/it]\u001b[32m[I 2022-04-22 00:03:41,358]\u001b[0m Trial 34 finished with value: 0.02464474296564299 and parameters: {'bagging_fraction': 0.981949079874426, 'bagging_freq': 5}. Best is trial 30 with value: 0.024644593316397578.\u001b[0m\nbagging, val_score: 0.024645:  80%|########  | 8/10 [00:27<00:07,  3.58s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246689\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062507 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  90%|######### | 9/10 [00:30<00:03,  3.36s/it]\u001b[32m[I 2022-04-22 00:03:44,244]\u001b[0m Trial 35 finished with value: 0.024644605165860017 and parameters: {'bagging_fraction': 0.4123821557895262, 'bagging_freq': 6}. Best is trial 30 with value: 0.024644593316397578.\u001b[0m\nbagging, val_score: 0.024645:  90%|######### | 9/10 [00:30<00:03,  3.36s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246653\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062156 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645: 100%|##########| 10/10 [00:34<00:00,  3.34s/it]\u001b[32m[I 2022-04-22 00:03:47,542]\u001b[0m Trial 36 finished with value: 0.024644760476870527 and parameters: {'bagging_fraction': 0.7582065719437672, 'bagging_freq': 6}. Best is trial 30 with value: 0.024644593316397578.\u001b[0m\nbagging, val_score: 0.024645: 100%|##########| 10/10 [00:34<00:00,  3.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021437\tValid's rmse: 0.0246684\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246448\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:   0%|          | 0/6 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060978 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  17%|#6        | 1/6 [00:02<00:14,  2.92s/it]\u001b[32m[I 2022-04-22 00:03:50,467]\u001b[0m Trial 37 finished with value: 0.024644843617745882 and parameters: {'feature_fraction': 0.52}. Best is trial 37 with value: 0.024644843617745882.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  17%|#6        | 1/6 [00:02<00:14,  2.92s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214371\tValid's rmse: 0.0246667\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069730 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  33%|###3      | 2/6 [00:06<00:12,  3.04s/it]\u001b[32m[I 2022-04-22 00:03:53,587]\u001b[0m Trial 38 finished with value: 0.024644593316397574 and parameters: {'feature_fraction': 0.616}. Best is trial 38 with value: 0.024644593316397574.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  33%|###3      | 2/6 [00:06<00:12,  3.04s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214366\tValid's rmse: 0.024665\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072202 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  50%|#####     | 3/6 [00:09<00:09,  3.16s/it]\u001b[32m[I 2022-04-22 00:03:56,895]\u001b[0m Trial 39 finished with value: 0.024644843617745882 and parameters: {'feature_fraction': 0.552}. Best is trial 38 with value: 0.024644593316397574.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  50%|#####     | 3/6 [00:09<00:09,  3.16s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246664\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  67%|######6   | 4/6 [00:12<00:06,  3.13s/it]\u001b[32m[I 2022-04-22 00:03:59,973]\u001b[0m Trial 40 finished with value: 0.024644593316397578 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 38 with value: 0.024644593316397574.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  67%|######6   | 4/6 [00:12<00:06,  3.13s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214364\tValid's rmse: 0.0246655\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062111 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  83%|########3 | 5/6 [00:15<00:03,  3.07s/it]\u001b[32m[I 2022-04-22 00:04:02,947]\u001b[0m Trial 41 finished with value: 0.024644593316397578 and parameters: {'feature_fraction': 0.584}. Best is trial 38 with value: 0.024644593316397574.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  83%|########3 | 5/6 [00:15<00:03,  3.07s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246653\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069229 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645: 100%|##########| 6/6 [00:19<00:00,  3.40s/it]\u001b[32m[I 2022-04-22 00:04:06,972]\u001b[0m Trial 42 finished with value: 0.024644593316397574 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 38 with value: 0.024644593316397574.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645: 100%|##########| 6/6 [00:19<00:00,  3.24s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214366\tValid's rmse: 0.024665\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071935 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:   5%|5         | 1/20 [00:02<00:55,  2.93s/it]\u001b[32m[I 2022-04-22 00:04:09,920]\u001b[0m Trial 43 finished with value: 0.024644596016942154 and parameters: {'lambda_l1': 2.3405793402192086e-07, 'lambda_l2': 0.020792833238905194}. Best is trial 43 with value: 0.024644596016942154.\u001b[0m\nregularization_factors, val_score: 0.024645:   5%|5         | 1/20 [00:02<00:55,  2.93s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246635\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067197 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  10%|#         | 2/20 [00:05<00:52,  2.92s/it]\u001b[32m[I 2022-04-22 00:04:12,832]\u001b[0m Trial 44 finished with value: 0.02464459599950769 and parameters: {'lambda_l1': 0.003313528021314365, 'lambda_l2': 8.162941137360433e-07}. Best is trial 44 with value: 0.02464459599950769.\u001b[0m\nregularization_factors, val_score: 0.024645:  10%|#         | 2/20 [00:05<00:52,  2.92s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246634\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067398 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  15%|#5        | 3/20 [00:08<00:50,  2.98s/it]\u001b[32m[I 2022-04-22 00:04:15,877]\u001b[0m Trial 45 finished with value: 0.024644596016731465 and parameters: {'lambda_l1': 5.434349023730233e-05, 'lambda_l2': 0.016658000828166396}. Best is trial 44 with value: 0.02464459599950769.\u001b[0m\nregularization_factors, val_score: 0.024645:  15%|#5        | 3/20 [00:08<00:50,  2.98s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246635\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070343 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  20%|##        | 4/20 [00:11<00:48,  3.00s/it]\u001b[32m[I 2022-04-22 00:04:18,913]\u001b[0m Trial 46 finished with value: 0.024644596001190497 and parameters: {'lambda_l1': 0.0029139263835080646, 'lambda_l2': 0.024043856507256028}. Best is trial 44 with value: 0.02464459599950769.\u001b[0m\nregularization_factors, val_score: 0.024645:  20%|##        | 4/20 [00:11<00:48,  3.00s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246635\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070632 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  25%|##5       | 5/20 [00:14<00:45,  3.01s/it]\u001b[32m[I 2022-04-22 00:04:21,947]\u001b[0m Trial 47 finished with value: 0.024644595623843562 and parameters: {'lambda_l1': 0.0629692751098365, 'lambda_l2': 2.803698283541461}. Best is trial 47 with value: 0.024644595623843562.\u001b[0m\nregularization_factors, val_score: 0.024645:  25%|##5       | 5/20 [00:14<00:45,  3.01s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214358\tValid's rmse: 0.0246628\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067923 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  30%|###       | 6/20 [00:17<00:41,  2.97s/it]\u001b[32m[I 2022-04-22 00:04:24,837]\u001b[0m Trial 48 finished with value: 0.024644596017336536 and parameters: {'lambda_l1': 1.32763019279994e-07, 'lambda_l2': 0.0005987816050862184}. Best is trial 47 with value: 0.024644595623843562.\u001b[0m\nregularization_factors, val_score: 0.024645:  30%|###       | 6/20 [00:17<00:41,  2.97s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246635\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067180 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  35%|###5      | 7/20 [00:20<00:38,  2.98s/it]\u001b[32m[I 2022-04-22 00:04:27,837]\u001b[0m Trial 49 finished with value: 0.02464459601731557 and parameters: {'lambda_l1': 5.795420705009354e-06, 'lambda_l2': 0.0001114361291204436}. Best is trial 47 with value: 0.024644595623843562.\u001b[0m\nregularization_factors, val_score: 0.024645:  35%|###5      | 7/20 [00:20<00:38,  2.98s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246635\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  40%|####      | 8/20 [00:23<00:35,  2.95s/it]\u001b[32m[I 2022-04-22 00:04:30,735]\u001b[0m Trial 50 finished with value: 0.024644596017346525 and parameters: {'lambda_l1': 4.4062147422928953e-07, 'lambda_l2': 4.001878685420978e-08}. Best is trial 47 with value: 0.024644595623843562.\u001b[0m\nregularization_factors, val_score: 0.024645:  40%|####      | 8/20 [00:23<00:35,  2.95s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246635\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070641 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  45%|####5     | 9/20 [00:26<00:32,  2.95s/it]\u001b[32m[I 2022-04-22 00:04:33,669]\u001b[0m Trial 51 finished with value: 0.02464459581407749 and parameters: {'lambda_l1': 0.037751931678784885, 'lambda_l2': 0.000273396384209601}. Best is trial 47 with value: 0.024644595623843562.\u001b[0m\nregularization_factors, val_score: 0.024645:  45%|####5     | 9/20 [00:26<00:32,  2.95s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.024663\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069679 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  50%|#####     | 10/20 [00:29<00:30,  3.00s/it]\u001b[32m[I 2022-04-22 00:04:36,799]\u001b[0m Trial 52 finished with value: 0.02464457240254739 and parameters: {'lambda_l1': 4.3959073865067175, 'lambda_l2': 0.0007964951384402018}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  50%|#####     | 10/20 [00:29<00:30,  3.00s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214393\tValid's rmse: 0.0246647\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065955 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  55%|#####5    | 11/20 [00:33<00:29,  3.32s/it]\u001b[32m[I 2022-04-22 00:04:40,825]\u001b[0m Trial 53 finished with value: 0.02464462242472555 and parameters: {'lambda_l1': 8.687985753312459, 'lambda_l2': 4.119389874647792e-06}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  55%|#####5    | 11/20 [00:33<00:29,  3.32s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214413\tValid's rmse: 0.024662\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214588\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  60%|######    | 12/20 [00:36<00:25,  3.24s/it]\u001b[32m[I 2022-04-22 00:04:43,873]\u001b[0m Trial 54 finished with value: 0.024644587440933542 and parameters: {'lambda_l1': 1.5617847618649192, 'lambda_l2': 9.79935408831778}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  60%|######    | 12/20 [00:36<00:25,  3.24s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214376\tValid's rmse: 0.0246667\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070878 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  65%|######5   | 13/20 [00:39<00:22,  3.18s/it]\u001b[32m[I 2022-04-22 00:04:46,938]\u001b[0m Trial 55 finished with value: 0.024644875793963263 and parameters: {'lambda_l1': 9.006595469216006, 'lambda_l2': 4.434702409034681}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  65%|######5   | 13/20 [00:39<00:22,  3.18s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214415\tValid's rmse: 0.0246619\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214588\tValid's rmse: 0.0246449\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067920 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  70%|#######   | 14/20 [00:43<00:19,  3.17s/it]\u001b[32m[I 2022-04-22 00:04:50,077]\u001b[0m Trial 56 finished with value: 0.024644593002442546 and parameters: {'lambda_l1': 0.5595226799133777, 'lambda_l2': 0.16494202859611257}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  70%|#######   | 14/20 [00:43<00:19,  3.17s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246653\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067166 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  75%|#######5  | 15/20 [00:46<00:15,  3.12s/it]\u001b[32m[I 2022-04-22 00:04:53,080]\u001b[0m Trial 57 finished with value: 0.02464459383984345 and parameters: {'lambda_l1': 0.40449837801216815, 'lambda_l2': 1.727467956766602e-08}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  75%|#######5  | 15/20 [00:46<00:15,  3.12s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214364\tValid's rmse: 0.024665\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  80%|########  | 16/20 [00:49<00:12,  3.09s/it]\u001b[32m[I 2022-04-22 00:04:56,114]\u001b[0m Trial 58 finished with value: 0.024644592378013804 and parameters: {'lambda_l1': 0.6749455563137947, 'lambda_l2': 0.34475121328384245}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  80%|########  | 16/20 [00:49<00:12,  3.09s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214367\tValid's rmse: 0.0246654\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066282 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  85%|########5 | 17/20 [00:52<00:09,  3.05s/it]\u001b[32m[I 2022-04-22 00:04:59,056]\u001b[0m Trial 59 finished with value: 0.02464459601173634 and parameters: {'lambda_l1': 0.001042297412255392, 'lambda_l2': 2.405347604655538e-05}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  85%|########5 | 17/20 [00:52<00:09,  3.05s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214355\tValid's rmse: 0.0246635\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070731 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  90%|######### | 18/20 [00:55<00:06,  3.03s/it]\u001b[32m[I 2022-04-22 00:05:02,037]\u001b[0m Trial 60 finished with value: 0.02464459582929369 and parameters: {'lambda_l1': 0.03491459000570278, 'lambda_l2': 0.0033788833765172888}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  90%|######### | 18/20 [00:55<00:06,  3.03s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214356\tValid's rmse: 0.0246629\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072268 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  95%|#########5| 19/20 [00:57<00:02,  2.99s/it]\u001b[32m[I 2022-04-22 00:05:04,925]\u001b[0m Trial 61 finished with value: 0.02464459600756853 and parameters: {'lambda_l1': 8.780558308519923e-05, 'lambda_l2': 0.477323227724138}. Best is trial 52 with value: 0.02464457240254739.\u001b[0m\nregularization_factors, val_score: 0.024645:  95%|#########5| 19/20 [00:57<00:02,  2.99s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214356\tValid's rmse: 0.0246634\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066169 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645: 100%|##########| 20/20 [01:01<00:00,  3.04s/it]\u001b[32m[I 2022-04-22 00:05:08,086]\u001b[0m Trial 62 finished with value: 0.024644557958237515 and parameters: {'lambda_l1': 2.086470350265008, 'lambda_l2': 6.854114548301938e-07}. Best is trial 62 with value: 0.024644557958237515.\u001b[0m\nregularization_factors, val_score: 0.024645: 100%|##########| 20/20 [01:01<00:00,  3.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021438\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246446\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067126 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  20%|##        | 1/5 [00:04<00:16,  4.12s/it]\u001b[32m[I 2022-04-22 00:05:12,219]\u001b[0m Trial 63 finished with value: 0.024644557958237515 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.024644557958237515.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  20%|##        | 1/5 [00:04<00:16,  4.12s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021438\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  40%|####      | 2/5 [00:07<00:10,  3.54s/it]\u001b[32m[I 2022-04-22 00:05:15,349]\u001b[0m Trial 64 finished with value: 0.024644557958237515 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.024644557958237515.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  40%|####      | 2/5 [00:07<00:10,  3.54s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021438\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067918 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  60%|######    | 3/5 [00:10<00:06,  3.36s/it]\u001b[32m[I 2022-04-22 00:05:18,496]\u001b[0m Trial 65 finished with value: 0.024644557958237515 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.024644557958237515.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  60%|######    | 3/5 [00:10<00:06,  3.36s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021438\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  80%|########  | 4/5 [00:13<00:03,  3.36s/it]\u001b[32m[I 2022-04-22 00:05:21,861]\u001b[0m Trial 66 finished with value: 0.024644557958237515 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.024644557958237515.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  80%|########  | 4/5 [00:13<00:03,  3.36s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021438\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645: 100%|##########| 5/5 [00:16<00:00,  3.30s/it]\u001b[32m[I 2022-04-22 00:05:25,038]\u001b[0m Trial 67 finished with value: 0.024644557958237515 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.024644557958237515.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645: 100%|##########| 5/5 [00:16<00:00,  3.39s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021438\tValid's rmse: 0.0246669\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214584\tValid's rmse: 0.0246446\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stderr","text":"\u001b[32m[I 2022-04-22 00:05:26,243]\u001b[0m A new study created in memory with name: no-name-2ba4b263-bd1d-46ec-9cdb-2a63c8d6e812\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217852\tValid's rmse: 0.0222319\n[200]\tTrain's rmse: 0.0217624\tValid's rmse: 0.0222186\n[300]\tTrain's rmse: 0.0217442\tValid's rmse: 0.022214\n[400]\tTrain's rmse: 0.0217283\tValid's rmse: 0.0222098\n[500]\tTrain's rmse: 0.0217154\tValid's rmse: 0.0222068\n[600]\tTrain's rmse: 0.0217015\tValid's rmse: 0.0222059\n[700]\tTrain's rmse: 0.0216902\tValid's rmse: 0.0222074\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022205:  14%|#4        | 1/7 [00:14<01:29, 14.92s/it]\u001b[32m[I 2022-04-22 00:05:41,167]\u001b[0m Trial 0 finished with value: 0.022204817766049826 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.022204817766049826.\u001b[0m\nfeature_fraction, val_score: 0.022205:  14%|#4        | 1/7 [00:14<01:29, 14.92s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[615]\tTrain's rmse: 0.0216997\tValid's rmse: 0.0222048\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197039 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217825\tValid's rmse: 0.0222296\n[200]\tTrain's rmse: 0.0217581\tValid's rmse: 0.0222158\n[300]\tTrain's rmse: 0.0217389\tValid's rmse: 0.0222136\n[400]\tTrain's rmse: 0.0217219\tValid's rmse: 0.0222084\n[500]\tTrain's rmse: 0.0217072\tValid's rmse: 0.0222055\n[600]\tTrain's rmse: 0.0216931\tValid's rmse: 0.0222052\n[700]\tTrain's rmse: 0.0216812\tValid's rmse: 0.0222042\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022204:  29%|##8       | 2/7 [00:32<01:21, 16.38s/it]\u001b[32m[I 2022-04-22 00:05:58,574]\u001b[0m Trial 1 finished with value: 0.022203791174335248 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.022203791174335248.\u001b[0m\nfeature_fraction, val_score: 0.022204:  29%|##8       | 2/7 [00:32<01:21, 16.38s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[627]\tTrain's rmse: 0.0216896\tValid's rmse: 0.0222038\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066153 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217827\tValid's rmse: 0.0222294\n[200]\tTrain's rmse: 0.0217587\tValid's rmse: 0.0222156\n[300]\tTrain's rmse: 0.0217397\tValid's rmse: 0.0222131\n[400]\tTrain's rmse: 0.0217231\tValid's rmse: 0.0222082\n[500]\tTrain's rmse: 0.0217091\tValid's rmse: 0.0222043\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022204:  43%|####2     | 3/7 [00:45<01:00, 15.09s/it]\u001b[32m[I 2022-04-22 00:06:12,136]\u001b[0m Trial 2 finished with value: 0.022203944261661425 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.022203791174335248.\u001b[0m\nfeature_fraction, val_score: 0.022204:  43%|####2     | 3/7 [00:45<01:00, 15.09s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0217147\tValid's rmse: 0.0222039\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007395 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217884\tValid's rmse: 0.0222347\n[200]\tTrain's rmse: 0.0217667\tValid's rmse: 0.0222209\n[300]\tTrain's rmse: 0.0217496\tValid's rmse: 0.0222173\n[400]\tTrain's rmse: 0.0217346\tValid's rmse: 0.0222124\n[500]\tTrain's rmse: 0.0217221\tValid's rmse: 0.0222094\n[600]\tTrain's rmse: 0.0217098\tValid's rmse: 0.0222082\n[700]\tTrain's rmse: 0.021699\tValid's rmse: 0.0222082\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022204:  57%|#####7    | 4/7 [01:03<00:48, 16.18s/it]\u001b[32m[I 2022-04-22 00:06:29,978]\u001b[0m Trial 3 finished with value: 0.022206435416118445 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.022203791174335248.\u001b[0m\nfeature_fraction, val_score: 0.022204:  57%|#####7    | 4/7 [01:03<00:48, 16.18s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[640]\tTrain's rmse: 0.0217051\tValid's rmse: 0.0222064\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217865\tValid's rmse: 0.0222314\n[200]\tTrain's rmse: 0.021764\tValid's rmse: 0.0222184\n[300]\tTrain's rmse: 0.0217463\tValid's rmse: 0.0222158\n[400]\tTrain's rmse: 0.0217306\tValid's rmse: 0.0222103\n[500]\tTrain's rmse: 0.0217182\tValid's rmse: 0.0222076\n[600]\tTrain's rmse: 0.0217051\tValid's rmse: 0.0222077\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022204:  71%|#######1  | 5/7 [01:18<00:31, 15.71s/it]\u001b[32m[I 2022-04-22 00:06:44,868]\u001b[0m Trial 4 finished with value: 0.02220665002658414 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.022203791174335248.\u001b[0m\nfeature_fraction, val_score: 0.022204:  71%|#######1  | 5/7 [01:18<00:31, 15.71s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[592]\tTrain's rmse: 0.021706\tValid's rmse: 0.0222067\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217822\tValid's rmse: 0.0222299\n[200]\tTrain's rmse: 0.0217586\tValid's rmse: 0.0222166\n[300]\tTrain's rmse: 0.0217392\tValid's rmse: 0.0222129\n[400]\tTrain's rmse: 0.0217219\tValid's rmse: 0.022208\n[500]\tTrain's rmse: 0.0217069\tValid's rmse: 0.0222033\n[600]\tTrain's rmse: 0.0216923\tValid's rmse: 0.0222049\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022201:  86%|########5 | 6/7 [01:34<00:15, 15.89s/it]\u001b[32m[I 2022-04-22 00:07:01,101]\u001b[0m Trial 5 finished with value: 0.02220132591417371 and parameters: {'feature_fraction': 1.0}. Best is trial 5 with value: 0.02220132591417371.\u001b[0m\nfeature_fraction, val_score: 0.022201:  86%|########5 | 6/7 [01:34<00:15, 15.89s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[525]\tTrain's rmse: 0.0217033\tValid's rmse: 0.0222013\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217841\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217603\tValid's rmse: 0.022215\n[300]\tTrain's rmse: 0.0217418\tValid's rmse: 0.0222126\n[400]\tTrain's rmse: 0.0217253\tValid's rmse: 0.022207\n[500]\tTrain's rmse: 0.0217113\tValid's rmse: 0.0222046\n[600]\tTrain's rmse: 0.0216971\tValid's rmse: 0.0222042\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022201: 100%|##########| 7/7 [01:49<00:00, 15.37s/it]\u001b[32m[I 2022-04-22 00:07:15,406]\u001b[0m Trial 6 finished with value: 0.022203108817092025 and parameters: {'feature_fraction': 0.7}. Best is trial 5 with value: 0.02220132591417371.\u001b[0m\nfeature_fraction, val_score: 0.022201: 100%|##########| 7/7 [01:49<00:00, 15.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[534]\tTrain's rmse: 0.0217066\tValid's rmse: 0.0222031\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069306 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215859\tValid's rmse: 0.0222297\n[200]\tTrain's rmse: 0.0213987\tValid's rmse: 0.0222306\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:   5%|5         | 1/20 [00:20<06:28, 20.45s/it]\u001b[32m[I 2022-04-22 00:07:35,863]\u001b[0m Trial 7 finished with value: 0.02222725025745653 and parameters: {'num_leaves': 244}. Best is trial 7 with value: 0.02222725025745653.\u001b[0m\nnum_leaves, val_score: 0.022201:   5%|5         | 1/20 [00:20<06:28, 20.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[104]\tTrain's rmse: 0.0215776\tValid's rmse: 0.0222273\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070629 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217849\tValid's rmse: 0.02223\n[200]\tTrain's rmse: 0.021763\tValid's rmse: 0.0222175\n[300]\tTrain's rmse: 0.021745\tValid's rmse: 0.022213\n[400]\tTrain's rmse: 0.0217293\tValid's rmse: 0.0222079\n[500]\tTrain's rmse: 0.0217157\tValid's rmse: 0.022204\n[600]\tTrain's rmse: 0.0217021\tValid's rmse: 0.0222052\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  10%|#         | 2/20 [00:36<05:18, 17.68s/it]\u001b[32m[I 2022-04-22 00:07:51,609]\u001b[0m Trial 8 finished with value: 0.022201760611949842 and parameters: {'num_leaves': 9}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  10%|#         | 2/20 [00:36<05:18, 17.68s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[528]\tTrain's rmse: 0.0217118\tValid's rmse: 0.0222018\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067915 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217583\tValid's rmse: 0.0222219\n[200]\tTrain's rmse: 0.0217161\tValid's rmse: 0.0222124\n[300]\tTrain's rmse: 0.0216841\tValid's rmse: 0.0222124\n[400]\tTrain's rmse: 0.0216534\tValid's rmse: 0.0222108\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  15%|#5        | 3/20 [00:51<04:39, 16.44s/it]\u001b[32m[I 2022-04-22 00:08:06,565]\u001b[0m Trial 9 finished with value: 0.022209586767622965 and parameters: {'num_leaves': 22}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  15%|#5        | 3/20 [00:51<04:39, 16.44s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[340]\tTrain's rmse: 0.0216718\tValid's rmse: 0.0222096\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068357 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216269\tValid's rmse: 0.0222302\n[200]\tTrain's rmse: 0.0214753\tValid's rmse: 0.0222282\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  20%|##        | 4/20 [01:11<04:50, 18.17s/it]\u001b[32m[I 2022-04-22 00:08:27,385]\u001b[0m Trial 10 finished with value: 0.022227479281673398 and parameters: {'num_leaves': 169}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  20%|##        | 4/20 [01:11<04:50, 18.17s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[150]\tTrain's rmse: 0.0215478\tValid's rmse: 0.0222275\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216077\tValid's rmse: 0.0222319\n[200]\tTrain's rmse: 0.0214389\tValid's rmse: 0.0222288\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  25%|##5       | 5/20 [01:36<05:09, 20.64s/it]\u001b[32m[I 2022-04-22 00:08:52,403]\u001b[0m Trial 11 finished with value: 0.0222286190407106 and parameters: {'num_leaves': 203}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  25%|##5       | 5/20 [01:36<05:09, 20.64s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[199]\tTrain's rmse: 0.0214404\tValid's rmse: 0.0222286\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068736 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216741\tValid's rmse: 0.0222239\n[200]\tTrain's rmse: 0.0215651\tValid's rmse: 0.0222183\n[300]\tTrain's rmse: 0.0214741\tValid's rmse: 0.0222225\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  30%|###       | 6/20 [01:57<04:47, 20.54s/it]\u001b[32m[I 2022-04-22 00:09:12,742]\u001b[0m Trial 12 finished with value: 0.02221707454520573 and parameters: {'num_leaves': 100}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  30%|###       | 6/20 [01:57<04:47, 20.54s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[205]\tTrain's rmse: 0.0215601\tValid's rmse: 0.0222171\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069739 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216741\tValid's rmse: 0.0222239\n[200]\tTrain's rmse: 0.0215651\tValid's rmse: 0.0222183\n[300]\tTrain's rmse: 0.0214741\tValid's rmse: 0.0222225\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  35%|###5      | 7/20 [02:18<04:28, 20.63s/it]\u001b[32m[I 2022-04-22 00:09:33,568]\u001b[0m Trial 13 finished with value: 0.022217074545205728 and parameters: {'num_leaves': 100}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  35%|###5      | 7/20 [02:18<04:28, 20.63s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[205]\tTrain's rmse: 0.0215601\tValid's rmse: 0.0222171\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073121 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216465\tValid's rmse: 0.0222262\n[200]\tTrain's rmse: 0.0215124\tValid's rmse: 0.0222211\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  40%|####      | 8/20 [02:36<03:59, 19.98s/it]\u001b[32m[I 2022-04-22 00:09:52,139]\u001b[0m Trial 14 finished with value: 0.022220513552269918 and parameters: {'num_leaves': 138}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  40%|####      | 8/20 [02:36<03:59, 19.98s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[155]\tTrain's rmse: 0.02157\tValid's rmse: 0.0222205\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068966 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217017\tValid's rmse: 0.0222238\n[200]\tTrain's rmse: 0.0216155\tValid's rmse: 0.0222157\n[300]\tTrain's rmse: 0.0215448\tValid's rmse: 0.0222152\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  45%|####5     | 9/20 [02:58<03:45, 20.52s/it]\u001b[32m[I 2022-04-22 00:10:13,847]\u001b[0m Trial 15 finished with value: 0.022213637072721573 and parameters: {'num_leaves': 69}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  45%|####5     | 9/20 [02:58<03:45, 20.52s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[275]\tTrain's rmse: 0.0215603\tValid's rmse: 0.0222136\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068304 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216982\tValid's rmse: 0.0222217\n[200]\tTrain's rmse: 0.02161\tValid's rmse: 0.0222133\n[300]\tTrain's rmse: 0.0215367\tValid's rmse: 0.0222165\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  50%|#####     | 10/20 [03:16<03:16, 19.65s/it]\u001b[32m[I 2022-04-22 00:10:31,558]\u001b[0m Trial 16 finished with value: 0.022212249107559166 and parameters: {'num_leaves': 72}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  50%|#####     | 10/20 [03:16<03:16, 19.65s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[209]\tTrain's rmse: 0.0216026\tValid's rmse: 0.0222122\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192815 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217881\tValid's rmse: 0.0222303\n[200]\tTrain's rmse: 0.0217678\tValid's rmse: 0.0222183\n[300]\tTrain's rmse: 0.0217518\tValid's rmse: 0.0222154\n[400]\tTrain's rmse: 0.0217374\tValid's rmse: 0.0222107\n[500]\tTrain's rmse: 0.0217253\tValid's rmse: 0.0222059\n[600]\tTrain's rmse: 0.0217128\tValid's rmse: 0.0222043\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  55%|#####5    | 11/20 [03:33<02:50, 18.95s/it]\u001b[32m[I 2022-04-22 00:10:48,911]\u001b[0m Trial 17 finished with value: 0.02220264712821226 and parameters: {'num_leaves': 8}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  55%|#####5    | 11/20 [03:33<02:50, 18.95s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[531]\tTrain's rmse: 0.0217213\tValid's rmse: 0.0222026\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092542 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0218112\tValid's rmse: 0.0222434\n[200]\tTrain's rmse: 0.0218057\tValid's rmse: 0.0222312\n[300]\tTrain's rmse: 0.0218018\tValid's rmse: 0.0222227\n[400]\tTrain's rmse: 0.0217988\tValid's rmse: 0.0222175\n[500]\tTrain's rmse: 0.0217962\tValid's rmse: 0.0222132\n[600]\tTrain's rmse: 0.0217937\tValid's rmse: 0.022213\n[700]\tTrain's rmse: 0.0217916\tValid's rmse: 0.0222109\n[800]\tTrain's rmse: 0.0217895\tValid's rmse: 0.0222088\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  60%|######    | 12/20 [03:45<02:13, 16.74s/it]\u001b[32m[I 2022-04-22 00:11:00,606]\u001b[0m Trial 18 finished with value: 0.022208506147889988 and parameters: {'num_leaves': 2}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  60%|######    | 12/20 [03:45<02:13, 16.74s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[760]\tTrain's rmse: 0.0217903\tValid's rmse: 0.0222085\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068629 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217343\tValid's rmse: 0.0222207\n[200]\tTrain's rmse: 0.0216733\tValid's rmse: 0.0222079\n[300]\tTrain's rmse: 0.0216252\tValid's rmse: 0.0222109\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  65%|######5   | 13/20 [04:00<01:54, 16.32s/it]\u001b[32m[I 2022-04-22 00:11:15,942]\u001b[0m Trial 19 finished with value: 0.02220703368995085 and parameters: {'num_leaves': 39}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  65%|######5   | 13/20 [04:00<01:54, 16.32s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[210]\tTrain's rmse: 0.0216677\tValid's rmse: 0.022207\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068941 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217295\tValid's rmse: 0.0222224\n[200]\tTrain's rmse: 0.0216649\tValid's rmse: 0.0222095\n[300]\tTrain's rmse: 0.0216138\tValid's rmse: 0.0222134\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  70%|#######   | 14/20 [04:15<01:35, 15.85s/it]\u001b[32m[I 2022-04-22 00:11:30,710]\u001b[0m Trial 20 finished with value: 0.0222089030039731 and parameters: {'num_leaves': 43}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  70%|#######   | 14/20 [04:15<01:35, 15.85s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[210]\tTrain's rmse: 0.021659\tValid's rmse: 0.0222089\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067873 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0218112\tValid's rmse: 0.0222434\n[200]\tTrain's rmse: 0.0218057\tValid's rmse: 0.0222312\n[300]\tTrain's rmse: 0.0218018\tValid's rmse: 0.0222227\n[400]\tTrain's rmse: 0.0217988\tValid's rmse: 0.0222175\n[500]\tTrain's rmse: 0.0217962\tValid's rmse: 0.0222132\n[600]\tTrain's rmse: 0.0217937\tValid's rmse: 0.022213\n[700]\tTrain's rmse: 0.0217916\tValid's rmse: 0.0222109\n[800]\tTrain's rmse: 0.0217895\tValid's rmse: 0.0222088\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  75%|#######5  | 15/20 [04:26<01:12, 14.56s/it]\u001b[32m[I 2022-04-22 00:11:42,280]\u001b[0m Trial 21 finished with value: 0.022208506147889984 and parameters: {'num_leaves': 2}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  75%|#######5  | 15/20 [04:26<01:12, 14.56s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[760]\tTrain's rmse: 0.0217903\tValid's rmse: 0.0222085\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068523 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021706\tValid's rmse: 0.0222231\n[200]\tTrain's rmse: 0.0216246\tValid's rmse: 0.0222111\n[300]\tTrain's rmse: 0.0215571\tValid's rmse: 0.0222122\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  80%|########  | 16/20 [04:44<01:02, 15.50s/it]\u001b[32m[I 2022-04-22 00:11:59,968]\u001b[0m Trial 22 finished with value: 0.022209590618615452 and parameters: {'num_leaves': 64}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  80%|########  | 16/20 [04:44<01:02, 15.50s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[225]\tTrain's rmse: 0.0216065\tValid's rmse: 0.0222096\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068108 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021666\tValid's rmse: 0.0222258\n[200]\tTrain's rmse: 0.0215495\tValid's rmse: 0.0222203\n[300]\tTrain's rmse: 0.0214529\tValid's rmse: 0.0222225\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  85%|########5 | 17/20 [05:06<00:52, 17.38s/it]\u001b[32m[I 2022-04-22 00:12:21,704]\u001b[0m Trial 23 finished with value: 0.022218952336698697 and parameters: {'num_leaves': 111}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  85%|########5 | 17/20 [05:06<00:52, 17.38s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[205]\tTrain's rmse: 0.0215442\tValid's rmse: 0.022219\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067759 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216387\tValid's rmse: 0.0222272\n[200]\tTrain's rmse: 0.0214972\tValid's rmse: 0.0222249\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  90%|######### | 18/20 [05:25<00:35, 17.99s/it]\u001b[32m[I 2022-04-22 00:12:41,115]\u001b[0m Trial 24 finished with value: 0.022223520409238348 and parameters: {'num_leaves': 150}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[156]\tTrain's rmse: 0.0215564\tValid's rmse: 0.0222235\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  90%|######### | 18/20 [05:25<00:35, 17.99s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217371\tValid's rmse: 0.022222\n[200]\tTrain's rmse: 0.0216785\tValid's rmse: 0.0222129\n[300]\tTrain's rmse: 0.0216322\tValid's rmse: 0.0222168\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  95%|#########5| 19/20 [05:39<00:16, 16.86s/it]\u001b[32m[I 2022-04-22 00:12:55,335]\u001b[0m Trial 25 finished with value: 0.022211962124691887 and parameters: {'num_leaves': 37}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  95%|#########5| 19/20 [05:39<00:16, 16.86s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[210]\tTrain's rmse: 0.0216731\tValid's rmse: 0.022212\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067641 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216112\tValid's rmse: 0.0222328\n[200]\tTrain's rmse: 0.0214443\tValid's rmse: 0.0222306\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201: 100%|##########| 20/20 [05:57<00:00, 17.08s/it]\u001b[32m[I 2022-04-22 00:13:12,955]\u001b[0m Trial 26 finished with value: 0.02223006611853927 and parameters: {'num_leaves': 198}. Best is trial 8 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201: 100%|##########| 20/20 [05:57<00:00, 17.88s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[104]\tTrain's rmse: 0.0216037\tValid's rmse: 0.0222301\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116776 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021784\tValid's rmse: 0.0222294\n[200]\tTrain's rmse: 0.0217585\tValid's rmse: 0.0222132\n[300]\tTrain's rmse: 0.0217377\tValid's rmse: 0.0222072\n[400]\tTrain's rmse: 0.0217192\tValid's rmse: 0.0222025\n[500]\tTrain's rmse: 0.0217045\tValid's rmse: 0.0222032\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  10%|#         | 1/10 [00:17<02:36, 17.36s/it]\u001b[32m[I 2022-04-22 00:13:30,320]\u001b[0m Trial 27 finished with value: 0.022200945470640433 and parameters: {'bagging_fraction': 0.7838132292133247, 'bagging_freq': 4}. Best is trial 27 with value: 0.022200945470640433.\u001b[0m\nbagging, val_score: 0.022201:  10%|#         | 1/10 [00:17<02:36, 17.36s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[448]\tTrain's rmse: 0.0217118\tValid's rmse: 0.0222009\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068994 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021783\tValid's rmse: 0.0222264\n[200]\tTrain's rmse: 0.0217589\tValid's rmse: 0.0222142\n[300]\tTrain's rmse: 0.0217387\tValid's rmse: 0.0222053\n[400]\tTrain's rmse: 0.0217228\tValid's rmse: 0.0221993\n[500]\tTrain's rmse: 0.0217076\tValid's rmse: 0.0221986\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  20%|##        | 2/10 [00:30<01:58, 14.78s/it]\u001b[32m[I 2022-04-22 00:13:43,303]\u001b[0m Trial 28 finished with value: 0.022197637179300646 and parameters: {'bagging_fraction': 0.48325625760368196, 'bagging_freq': 4}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  20%|##        | 2/10 [00:30<01:58, 14.78s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[424]\tTrain's rmse: 0.0217187\tValid's rmse: 0.0221976\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067584 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217825\tValid's rmse: 0.0222308\n[200]\tTrain's rmse: 0.0217579\tValid's rmse: 0.0222171\n[300]\tTrain's rmse: 0.0217382\tValid's rmse: 0.022209\n[400]\tTrain's rmse: 0.0217201\tValid's rmse: 0.0222086\n[500]\tTrain's rmse: 0.0217052\tValid's rmse: 0.0222084\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  30%|###       | 3/10 [00:46<01:48, 15.47s/it]\u001b[32m[I 2022-04-22 00:13:59,592]\u001b[0m Trial 29 finished with value: 0.022207176730970703 and parameters: {'bagging_fraction': 0.6148392308110517, 'bagging_freq': 2}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  30%|###       | 3/10 [00:46<01:48, 15.47s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[418]\tTrain's rmse: 0.0217175\tValid's rmse: 0.0222072\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066468 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217824\tValid's rmse: 0.0222307\n[200]\tTrain's rmse: 0.0217573\tValid's rmse: 0.0222161\n[300]\tTrain's rmse: 0.0217367\tValid's rmse: 0.0222118\n[400]\tTrain's rmse: 0.0217193\tValid's rmse: 0.0222104\n[500]\tTrain's rmse: 0.021704\tValid's rmse: 0.0222083\n[600]\tTrain's rmse: 0.021689\tValid's rmse: 0.0222083\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  40%|####      | 4/10 [01:07<01:45, 17.54s/it]\u001b[32m[I 2022-04-22 00:14:20,292]\u001b[0m Trial 30 finished with value: 0.022206669807525874 and parameters: {'bagging_fraction': 0.8143193194385123, 'bagging_freq': 1}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  40%|####      | 4/10 [01:07<01:45, 17.54s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[550]\tTrain's rmse: 0.0216964\tValid's rmse: 0.0222067\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067893 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217823\tValid's rmse: 0.022232\n[200]\tTrain's rmse: 0.0217569\tValid's rmse: 0.0222171\n[300]\tTrain's rmse: 0.021737\tValid's rmse: 0.0222166\n[400]\tTrain's rmse: 0.0217201\tValid's rmse: 0.0222115\n[500]\tTrain's rmse: 0.0217052\tValid's rmse: 0.0222098\n[600]\tTrain's rmse: 0.0216903\tValid's rmse: 0.0222081\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  50%|#####     | 5/10 [01:27<01:33, 18.66s/it]\u001b[32m[I 2022-04-22 00:14:40,958]\u001b[0m Trial 31 finished with value: 0.022207840594554207 and parameters: {'bagging_fraction': 0.8390501014179597, 'bagging_freq': 5}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  50%|#####     | 5/10 [01:27<01:33, 18.66s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[590]\tTrain's rmse: 0.0216916\tValid's rmse: 0.0222078\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068402 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217833\tValid's rmse: 0.0222278\n[200]\tTrain's rmse: 0.0217585\tValid's rmse: 0.0222168\n[300]\tTrain's rmse: 0.0217377\tValid's rmse: 0.022213\n[400]\tTrain's rmse: 0.0217207\tValid's rmse: 0.0222084\n[500]\tTrain's rmse: 0.0217052\tValid's rmse: 0.0222063\n[600]\tTrain's rmse: 0.0216904\tValid's rmse: 0.0222047\n[700]\tTrain's rmse: 0.0216777\tValid's rmse: 0.0222047\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  60%|######    | 6/10 [01:51<01:21, 20.28s/it]\u001b[32m[I 2022-04-22 00:15:04,376]\u001b[0m Trial 32 finished with value: 0.022203937596305356 and parameters: {'bagging_fraction': 0.8993412749330394, 'bagging_freq': 4}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  60%|######    | 6/10 [01:51<01:21, 20.28s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[612]\tTrain's rmse: 0.0216888\tValid's rmse: 0.0222039\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068327 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217825\tValid's rmse: 0.0222311\n[200]\tTrain's rmse: 0.0217583\tValid's rmse: 0.0222163\n[300]\tTrain's rmse: 0.021739\tValid's rmse: 0.0222104\n[400]\tTrain's rmse: 0.0217233\tValid's rmse: 0.022205\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  70%|#######   | 7/10 [02:03<00:53, 17.75s/it]\u001b[32m[I 2022-04-22 00:15:16,903]\u001b[0m Trial 33 finished with value: 0.022203750101744708 and parameters: {'bagging_fraction': 0.5249216044437016, 'bagging_freq': 4}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  70%|#######   | 7/10 [02:03<00:53, 17.75s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[368]\tTrain's rmse: 0.0217278\tValid's rmse: 0.0222038\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071672 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217827\tValid's rmse: 0.0222312\n[200]\tTrain's rmse: 0.0217571\tValid's rmse: 0.0222171\n[300]\tTrain's rmse: 0.0217372\tValid's rmse: 0.0222143\n[400]\tTrain's rmse: 0.0217196\tValid's rmse: 0.0222113\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  80%|########  | 8/10 [02:20<00:34, 17.45s/it]\u001b[32m[I 2022-04-22 00:15:33,730]\u001b[0m Trial 34 finished with value: 0.022211129401612233 and parameters: {'bagging_fraction': 0.8824087996426702, 'bagging_freq': 1}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  80%|########  | 8/10 [02:20<00:34, 17.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[387]\tTrain's rmse: 0.0217218\tValid's rmse: 0.0222111\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217823\tValid's rmse: 0.0222285\n[200]\tTrain's rmse: 0.0217577\tValid's rmse: 0.0222176\n[300]\tTrain's rmse: 0.0217378\tValid's rmse: 0.0222127\n[400]\tTrain's rmse: 0.021721\tValid's rmse: 0.0222106\n[500]\tTrain's rmse: 0.0217059\tValid's rmse: 0.0222064\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198:  90%|######### | 9/10 [02:37<00:17, 17.25s/it]\u001b[32m[I 2022-04-22 00:15:50,535]\u001b[0m Trial 35 finished with value: 0.02220571312366694 and parameters: {'bagging_fraction': 0.6931509465838093, 'bagging_freq': 4}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198:  90%|######### | 9/10 [02:37<00:17, 17.25s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[488]\tTrain's rmse: 0.0217077\tValid's rmse: 0.0222057\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068688 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217828\tValid's rmse: 0.0222297\n[200]\tTrain's rmse: 0.0217578\tValid's rmse: 0.0222165\n[300]\tTrain's rmse: 0.0217376\tValid's rmse: 0.0222106\n[400]\tTrain's rmse: 0.0217202\tValid's rmse: 0.0222106\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022198: 100%|##########| 10/10 [02:50<00:00, 16.00s/it]\u001b[32m[I 2022-04-22 00:16:03,750]\u001b[0m Trial 36 finished with value: 0.022209245670289583 and parameters: {'bagging_fraction': 0.5917805544620538, 'bagging_freq': 2}. Best is trial 28 with value: 0.022197637179300646.\u001b[0m\nbagging, val_score: 0.022198: 100%|##########| 10/10 [02:50<00:00, 17.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[312]\tTrain's rmse: 0.0217356\tValid's rmse: 0.0222092\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022198:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072257 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021783\tValid's rmse: 0.0222264\n[200]\tTrain's rmse: 0.0217589\tValid's rmse: 0.0222142\n[300]\tTrain's rmse: 0.0217387\tValid's rmse: 0.0222053\n[400]\tTrain's rmse: 0.0217228\tValid's rmse: 0.0221993\n[500]\tTrain's rmse: 0.0217076\tValid's rmse: 0.0221986\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022198:  33%|###3      | 1/3 [00:13<00:26, 13.25s/it]\u001b[32m[I 2022-04-22 00:16:17,005]\u001b[0m Trial 37 finished with value: 0.022197637179300646 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.022197637179300646.\u001b[0m\nfeature_fraction_stage2, val_score: 0.022198:  33%|###3      | 1/3 [00:13<00:26, 13.25s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[424]\tTrain's rmse: 0.0217187\tValid's rmse: 0.0221976\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070809 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217835\tValid's rmse: 0.0222284\n[200]\tTrain's rmse: 0.0217593\tValid's rmse: 0.022214\n[300]\tTrain's rmse: 0.0217396\tValid's rmse: 0.0222055\n[400]\tTrain's rmse: 0.0217238\tValid's rmse: 0.0222005\n[500]\tTrain's rmse: 0.0217088\tValid's rmse: 0.0221988\n[600]\tTrain's rmse: 0.0216954\tValid's rmse: 0.022199\n[700]\tTrain's rmse: 0.0216827\tValid's rmse: 0.0222015\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022198:  67%|######6   | 2/3 [00:30<00:15, 15.82s/it]\u001b[32m[I 2022-04-22 00:16:34,628]\u001b[0m Trial 38 finished with value: 0.02219753613183182 and parameters: {'feature_fraction': 0.92}. Best is trial 38 with value: 0.02219753613183182.\u001b[0m\nfeature_fraction_stage2, val_score: 0.022198:  67%|######6   | 2/3 [00:30<00:15, 15.82s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216906\tValid's rmse: 0.0221975\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069482 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217833\tValid's rmse: 0.0222282\n[200]\tTrain's rmse: 0.0217589\tValid's rmse: 0.0222143\n[300]\tTrain's rmse: 0.0217389\tValid's rmse: 0.0222052\n[400]\tTrain's rmse: 0.0217229\tValid's rmse: 0.0222007\n[500]\tTrain's rmse: 0.0217076\tValid's rmse: 0.0221988\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022198: 100%|##########| 3/3 [00:43<00:00, 14.57s/it]\u001b[32m[I 2022-04-22 00:16:47,721]\u001b[0m Trial 39 finished with value: 0.022198166312578052 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 38 with value: 0.02219753613183182.\u001b[0m\nfeature_fraction_stage2, val_score: 0.022198: 100%|##########| 3/3 [00:43<00:00, 14.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[430]\tTrain's rmse: 0.021718\tValid's rmse: 0.0221982\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069025 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217792\tValid's rmse: 0.0222291\n[200]\tTrain's rmse: 0.021751\tValid's rmse: 0.0222172\n[300]\tTrain's rmse: 0.0217278\tValid's rmse: 0.0222087\n[400]\tTrain's rmse: 0.0217082\tValid's rmse: 0.0222047\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:   5%|5         | 1/20 [00:11<03:46, 11.93s/it]\u001b[32m[I 2022-04-22 00:16:59,664]\u001b[0m Trial 40 finished with value: 0.022203343129590027 and parameters: {'lambda_l1': 0.0005447851460006296, 'lambda_l2': 1.4357268692715181e-08}. Best is trial 40 with value: 0.022203343129590027.\u001b[0m\nregularization_factors, val_score: 0.022198:   5%|5         | 1/20 [00:11<03:46, 11.93s/it]","output_type":"stream"},{"name":"stdout","text":"[500]\tTrain's rmse: 0.0216888\tValid's rmse: 0.022204\nEarly stopping, best iteration is:\n[406]\tTrain's rmse: 0.021707\tValid's rmse: 0.0222033\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072602 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217808\tValid's rmse: 0.0222291\n[200]\tTrain's rmse: 0.0217537\tValid's rmse: 0.0222166\n[300]\tTrain's rmse: 0.0217312\tValid's rmse: 0.0222048\n[400]\tTrain's rmse: 0.021712\tValid's rmse: 0.0222039\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  10%|#         | 2/20 [00:22<03:19, 11.06s/it]\u001b[32m[I 2022-04-22 00:17:10,115]\u001b[0m Trial 41 finished with value: 0.02220204990930759 and parameters: {'lambda_l1': 1.6939157333213008e-05, 'lambda_l2': 2.370504446161362}. Best is trial 41 with value: 0.02220204990930759.\u001b[0m\nregularization_factors, val_score: 0.022198:  10%|#         | 2/20 [00:22<03:19, 11.06s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[360]\tTrain's rmse: 0.0217194\tValid's rmse: 0.022202\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072955 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217793\tValid's rmse: 0.022228\n[200]\tTrain's rmse: 0.0217514\tValid's rmse: 0.0222172\n[300]\tTrain's rmse: 0.0217282\tValid's rmse: 0.0222063\n[400]\tTrain's rmse: 0.0217081\tValid's rmse: 0.0222038\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  15%|#5        | 3/20 [00:33<03:08, 11.08s/it]\u001b[32m[I 2022-04-22 00:17:21,222]\u001b[0m Trial 42 finished with value: 0.022202424103220812 and parameters: {'lambda_l1': 0.0019060353339332185, 'lambda_l2': 1.0109070587312032e-06}. Best is trial 41 with value: 0.02220204990930759.\u001b[0m\nregularization_factors, val_score: 0.022198:  15%|#5        | 3/20 [00:33<03:08, 11.08s/it]","output_type":"stream"},{"name":"stdout","text":"[500]\tTrain's rmse: 0.0216886\tValid's rmse: 0.022204\nEarly stopping, best iteration is:\n[406]\tTrain's rmse: 0.0217069\tValid's rmse: 0.0222024\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217793\tValid's rmse: 0.022229\n[200]\tTrain's rmse: 0.0217511\tValid's rmse: 0.0222168\n[300]\tTrain's rmse: 0.0217278\tValid's rmse: 0.0222067\n[400]\tTrain's rmse: 0.021708\tValid's rmse: 0.022204\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  20%|##        | 4/20 [00:45<03:03, 11.46s/it]\u001b[32m[I 2022-04-22 00:17:33,256]\u001b[0m Trial 43 finished with value: 0.022203067956912344 and parameters: {'lambda_l1': 2.753483730889554e-05, 'lambda_l2': 4.517783232819513e-08}. Best is trial 41 with value: 0.02220204990930759.\u001b[0m\nregularization_factors, val_score: 0.022198:  20%|##        | 4/20 [00:45<03:03, 11.46s/it]","output_type":"stream"},{"name":"stdout","text":"[500]\tTrain's rmse: 0.0216887\tValid's rmse: 0.0222035\nEarly stopping, best iteration is:\n[406]\tTrain's rmse: 0.0217068\tValid's rmse: 0.0222031\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071604 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217793\tValid's rmse: 0.022229\n[200]\tTrain's rmse: 0.0217511\tValid's rmse: 0.0222168\n[300]\tTrain's rmse: 0.0217278\tValid's rmse: 0.0222067\n[400]\tTrain's rmse: 0.021708\tValid's rmse: 0.022204\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  25%|##5       | 5/20 [00:56<02:49, 11.27s/it]\u001b[32m[I 2022-04-22 00:17:44,198]\u001b[0m Trial 44 finished with value: 0.022203067980240552 and parameters: {'lambda_l1': 2.1875738152964774e-05, 'lambda_l2': 1.7966260313941258e-08}. Best is trial 41 with value: 0.02220204990930759.\u001b[0m\nregularization_factors, val_score: 0.022198:  25%|##5       | 5/20 [00:56<02:49, 11.27s/it]","output_type":"stream"},{"name":"stdout","text":"[500]\tTrain's rmse: 0.0216887\tValid's rmse: 0.0222035\nEarly stopping, best iteration is:\n[406]\tTrain's rmse: 0.0217068\tValid's rmse: 0.0222031\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068147 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217876\tValid's rmse: 0.0222331\n[200]\tTrain's rmse: 0.0217683\tValid's rmse: 0.0222246\n[300]\tTrain's rmse: 0.0217528\tValid's rmse: 0.0222207\n[400]\tTrain's rmse: 0.0217407\tValid's rmse: 0.0222152\n[500]\tTrain's rmse: 0.0217294\tValid's rmse: 0.0222146\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  30%|###       | 6/20 [01:11<02:54, 12.48s/it]\u001b[32m[I 2022-04-22 00:17:59,019]\u001b[0m Trial 45 finished with value: 0.022213617141437242 and parameters: {'lambda_l1': 1.7286646528724985, 'lambda_l2': 1.572248631574682e-08}. Best is trial 41 with value: 0.02220204990930759.\u001b[0m\nregularization_factors, val_score: 0.022198:  30%|###       | 6/20 [01:11<02:54, 12.48s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[426]\tTrain's rmse: 0.0217378\tValid's rmse: 0.0222136\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068424 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217813\tValid's rmse: 0.0222289\n[200]\tTrain's rmse: 0.0217545\tValid's rmse: 0.022219\n[300]\tTrain's rmse: 0.0217324\tValid's rmse: 0.0222063\n[400]\tTrain's rmse: 0.0217133\tValid's rmse: 0.0222034\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  35%|###5      | 7/20 [01:22<02:37, 12.11s/it]\u001b[32m[I 2022-04-22 00:18:10,378]\u001b[0m Trial 46 finished with value: 0.022201778340328895 and parameters: {'lambda_l1': 3.605870575653961e-07, 'lambda_l2': 3.061947050509827}. Best is trial 46 with value: 0.022201778340328895.\u001b[0m\nregularization_factors, val_score: 0.022198:  35%|###5      | 7/20 [01:22<02:37, 12.11s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[360]\tTrain's rmse: 0.0217205\tValid's rmse: 0.0222018\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068345 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217793\tValid's rmse: 0.0222282\n[200]\tTrain's rmse: 0.0217512\tValid's rmse: 0.022217\n[300]\tTrain's rmse: 0.0217282\tValid's rmse: 0.0222065\n[400]\tTrain's rmse: 0.0217085\tValid's rmse: 0.0222038\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  40%|####      | 8/20 [01:33<02:20, 11.74s/it]\u001b[32m[I 2022-04-22 00:18:21,312]\u001b[0m Trial 47 finished with value: 0.022202477777715248 and parameters: {'lambda_l1': 0.004273676744347146, 'lambda_l2': 7.958085181533452e-05}. Best is trial 46 with value: 0.022201778340328895.\u001b[0m\nregularization_factors, val_score: 0.022198:  40%|####      | 8/20 [01:33<02:20, 11.74s/it]","output_type":"stream"},{"name":"stdout","text":"[500]\tTrain's rmse: 0.0216887\tValid's rmse: 0.0222036\nEarly stopping, best iteration is:\n[406]\tTrain's rmse: 0.0217073\tValid's rmse: 0.0222025\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068585 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217793\tValid's rmse: 0.0222282\n[200]\tTrain's rmse: 0.0217512\tValid's rmse: 0.022217\n[300]\tTrain's rmse: 0.0217282\tValid's rmse: 0.0222065\n[400]\tTrain's rmse: 0.0217085\tValid's rmse: 0.0222038\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  45%|####5     | 9/20 [01:44<02:06, 11.49s/it]\u001b[32m[I 2022-04-22 00:18:32,256]\u001b[0m Trial 48 finished with value: 0.02220247816222251 and parameters: {'lambda_l1': 0.004191490423119662, 'lambda_l2': 1.988046967519144e-05}. Best is trial 46 with value: 0.022201778340328895.\u001b[0m\nregularization_factors, val_score: 0.022198:  45%|####5     | 9/20 [01:44<02:06, 11.49s/it]","output_type":"stream"},{"name":"stdout","text":"[500]\tTrain's rmse: 0.0216886\tValid's rmse: 0.0222036\nEarly stopping, best iteration is:\n[406]\tTrain's rmse: 0.0217073\tValid's rmse: 0.0222025\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217801\tValid's rmse: 0.022226\n[200]\tTrain's rmse: 0.021753\tValid's rmse: 0.0222153\n[300]\tTrain's rmse: 0.0217303\tValid's rmse: 0.0222041\n[400]\tTrain's rmse: 0.0217104\tValid's rmse: 0.0222019\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  50%|#####     | 10/20 [01:55<01:54, 11.46s/it]\u001b[32m[I 2022-04-22 00:18:43,662]\u001b[0m Trial 49 finished with value: 0.022199410864522966 and parameters: {'lambda_l1': 0.06997282828477701, 'lambda_l2': 0.1411004151543841}. Best is trial 49 with value: 0.022199410864522966.\u001b[0m\nregularization_factors, val_score: 0.022198:  50%|#####     | 10/20 [01:55<01:54, 11.46s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[360]\tTrain's rmse: 0.0217178\tValid's rmse: 0.0221994\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080880 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217918\tValid's rmse: 0.0222344\n[200]\tTrain's rmse: 0.0217755\tValid's rmse: 0.0222259\n[300]\tTrain's rmse: 0.0217632\tValid's rmse: 0.0222195\n[400]\tTrain's rmse: 0.0217537\tValid's rmse: 0.022218\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  55%|#####5    | 11/20 [02:10<01:50, 12.30s/it]\u001b[32m[I 2022-04-22 00:18:57,847]\u001b[0m Trial 50 finished with value: 0.022216494359633045 and parameters: {'lambda_l1': 4.830474747357921, 'lambda_l2': 0.01905602711787504}. Best is trial 49 with value: 0.022199410864522966.\u001b[0m\nregularization_factors, val_score: 0.022198:  55%|#####5    | 11/20 [02:10<01:50, 12.30s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[368]\tTrain's rmse: 0.0217565\tValid's rmse: 0.0222165\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068436 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217825\tValid's rmse: 0.0222271\n[200]\tTrain's rmse: 0.0217571\tValid's rmse: 0.0222132\n[300]\tTrain's rmse: 0.0217358\tValid's rmse: 0.0222038\n[400]\tTrain's rmse: 0.0217173\tValid's rmse: 0.0222017\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022198:  60%|######    | 12/20 [02:22<01:38, 12.29s/it]\u001b[32m[I 2022-04-22 00:19:10,139]\u001b[0m Trial 51 finished with value: 0.02220070772960981 and parameters: {'lambda_l1': 1.1867471851128069e-07, 'lambda_l2': 7.731777073757493}. Best is trial 49 with value: 0.022199410864522966.\u001b[0m\nregularization_factors, val_score: 0.022198:  60%|######    | 12/20 [02:22<01:38, 12.29s/it]","output_type":"stream"},{"name":"stdout","text":"[500]\tTrain's rmse: 0.0217\tValid's rmse: 0.0222011\nEarly stopping, best iteration is:\n[406]\tTrain's rmse: 0.0217163\tValid's rmse: 0.0222007\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068447 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222278\n[200]\tTrain's rmse: 0.0217545\tValid's rmse: 0.0222143\n[300]\tTrain's rmse: 0.0217328\tValid's rmse: 0.0222015\n[400]\tTrain's rmse: 0.0217141\tValid's rmse: 0.0221999\n[500]\tTrain's rmse: 0.0216964\tValid's rmse: 0.0221978\n[600]\tTrain's rmse: 0.0216796\tValid's rmse: 0.0221967\n[700]\tTrain's rmse: 0.0216642\tValid's rmse: 0.0221993\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194:  65%|######5   | 13/20 [02:37<01:32, 13.24s/it]\u001b[32m[I 2022-04-22 00:19:25,549]\u001b[0m Trial 52 finished with value: 0.022194439090888106 and parameters: {'lambda_l1': 0.18750412706074973, 'lambda_l2': 0.013534853826986295}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194:  65%|######5   | 13/20 [02:37<01:32, 13.24s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216742\tValid's rmse: 0.0221944\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067668 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217803\tValid's rmse: 0.0222277\n[200]\tTrain's rmse: 0.0217533\tValid's rmse: 0.022218\n[300]\tTrain's rmse: 0.0217308\tValid's rmse: 0.0222068\n[400]\tTrain's rmse: 0.0217115\tValid's rmse: 0.0222043\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194:  70%|#######   | 14/20 [02:48<01:14, 12.48s/it]\u001b[32m[I 2022-04-22 00:19:36,266]\u001b[0m Trial 53 finished with value: 0.02220196707212449 and parameters: {'lambda_l1': 0.11738262355308896, 'lambda_l2': 0.011894284390590525}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194:  70%|#######   | 14/20 [02:48<01:14, 12.48s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[362]\tTrain's rmse: 0.0217183\tValid's rmse: 0.022202\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067023 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217806\tValid's rmse: 0.0222268\n[200]\tTrain's rmse: 0.0217538\tValid's rmse: 0.022217\n[300]\tTrain's rmse: 0.0217314\tValid's rmse: 0.0222051\n[400]\tTrain's rmse: 0.0217123\tValid's rmse: 0.0222018\n[500]\tTrain's rmse: 0.0216945\tValid's rmse: 0.0221983\n[600]\tTrain's rmse: 0.021677\tValid's rmse: 0.0221984\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194:  75%|#######5  | 15/20 [03:03<01:06, 13.26s/it]\u001b[32m[I 2022-04-22 00:19:51,325]\u001b[0m Trial 54 finished with value: 0.022197362886366673 and parameters: {'lambda_l1': 0.13139563898005757, 'lambda_l2': 0.042155965669413514}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194:  75%|#######5  | 15/20 [03:03<01:06, 13.26s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[562]\tTrain's rmse: 0.0216838\tValid's rmse: 0.0221974\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068745 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217807\tValid's rmse: 0.0222274\n[200]\tTrain's rmse: 0.0217538\tValid's rmse: 0.0222155\n[300]\tTrain's rmse: 0.0217316\tValid's rmse: 0.0222031\n[400]\tTrain's rmse: 0.0217126\tValid's rmse: 0.0221996\n[500]\tTrain's rmse: 0.0216949\tValid's rmse: 0.0221976\n[600]\tTrain's rmse: 0.0216775\tValid's rmse: 0.0221961\n[700]\tTrain's rmse: 0.0216621\tValid's rmse: 0.0222006\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194:  80%|########  | 16/20 [03:18<00:55, 13.87s/it]\u001b[32m[I 2022-04-22 00:20:06,609]\u001b[0m Trial 55 finished with value: 0.022195505965650415 and parameters: {'lambda_l1': 0.1552234401182276, 'lambda_l2': 0.0015682401919559364}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194:  80%|########  | 16/20 [03:18<00:55, 13.87s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216722\tValid's rmse: 0.0221955\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068976 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217853\tValid's rmse: 0.0222304\n[200]\tTrain's rmse: 0.0217637\tValid's rmse: 0.0222192\n[300]\tTrain's rmse: 0.0217459\tValid's rmse: 0.0222124\n[400]\tTrain's rmse: 0.0217318\tValid's rmse: 0.0222062\n[500]\tTrain's rmse: 0.0217192\tValid's rmse: 0.022204\n[600]\tTrain's rmse: 0.021708\tValid's rmse: 0.0222033\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194:  85%|########5 | 17/20 [03:36<00:45, 15.06s/it]\u001b[32m[I 2022-04-22 00:20:24,459]\u001b[0m Trial 56 finished with value: 0.02220268381101239 and parameters: {'lambda_l1': 0.9349690865034823, 'lambda_l2': 0.001647906103477955}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194:  85%|########5 | 17/20 [03:36<00:45, 15.06s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[588]\tTrain's rmse: 0.0217094\tValid's rmse: 0.0222027\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068899 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217794\tValid's rmse: 0.0222284\n[200]\tTrain's rmse: 0.0217515\tValid's rmse: 0.0222171\n[300]\tTrain's rmse: 0.0217282\tValid's rmse: 0.0222071\n[400]\tTrain's rmse: 0.0217088\tValid's rmse: 0.0222034\n[500]\tTrain's rmse: 0.0216898\tValid's rmse: 0.022202\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194:  90%|######### | 18/20 [03:49<00:28, 14.35s/it]\u001b[32m[I 2022-04-22 00:20:37,161]\u001b[0m Trial 57 finished with value: 0.022202027403689033 and parameters: {'lambda_l1': 0.02062387901649977, 'lambda_l2': 0.0008129655330658777}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194:  90%|######### | 18/20 [03:49<00:28, 14.35s/it]","output_type":"stream"},{"name":"stdout","text":"[600]\tTrain's rmse: 0.0216721\tValid's rmse: 0.0222027\nEarly stopping, best iteration is:\n[500]\tTrain's rmse: 0.0216898\tValid's rmse: 0.022202\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217948\tValid's rmse: 0.0222344\n[200]\tTrain's rmse: 0.0217802\tValid's rmse: 0.0222262\n[300]\tTrain's rmse: 0.0217694\tValid's rmse: 0.0222202\n[400]\tTrain's rmse: 0.0217611\tValid's rmse: 0.022218\n[500]\tTrain's rmse: 0.021754\tValid's rmse: 0.0222176\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194:  95%|#########5| 19/20 [04:05<00:14, 14.78s/it]\u001b[32m[I 2022-04-22 00:20:52,938]\u001b[0m Trial 58 finished with value: 0.02221692359345858 and parameters: {'lambda_l1': 7.891633972198921, 'lambda_l2': 5.769613733752579e-06}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194:  95%|#########5| 19/20 [04:05<00:14, 14.78s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[428]\tTrain's rmse: 0.021759\tValid's rmse: 0.0222169\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069007 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217832\tValid's rmse: 0.0222284\n[200]\tTrain's rmse: 0.0217588\tValid's rmse: 0.0222145\n[300]\tTrain's rmse: 0.0217387\tValid's rmse: 0.0222055\n[400]\tTrain's rmse: 0.0217225\tValid's rmse: 0.022201\n[500]\tTrain's rmse: 0.0217069\tValid's rmse: 0.0221992\n[600]\tTrain's rmse: 0.0216933\tValid's rmse: 0.0221996\n[700]\tTrain's rmse: 0.02168\tValid's rmse: 0.0222022\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022194: 100%|##########| 20/20 [04:21<00:00, 15.30s/it]\u001b[32m[I 2022-04-22 00:21:09,462]\u001b[0m Trial 59 finished with value: 0.022197741813762217 and parameters: {'lambda_l1': 0.46133293299188266, 'lambda_l2': 0.36532181362222493}. Best is trial 52 with value: 0.022194439090888106.\u001b[0m\nregularization_factors, val_score: 0.022194: 100%|##########| 20/20 [04:21<00:00, 13.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[620]\tTrain's rmse: 0.0216904\tValid's rmse: 0.0221977\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022194:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069406 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222278\n[200]\tTrain's rmse: 0.0217545\tValid's rmse: 0.0222143\n[300]\tTrain's rmse: 0.0217328\tValid's rmse: 0.0222015\n[400]\tTrain's rmse: 0.0217141\tValid's rmse: 0.0221999\n[500]\tTrain's rmse: 0.0216964\tValid's rmse: 0.0221978\n[600]\tTrain's rmse: 0.0216796\tValid's rmse: 0.0221967\n[700]\tTrain's rmse: 0.0216642\tValid's rmse: 0.0221993\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022194:  20%|##        | 1/5 [00:16<01:06, 16.61s/it]\u001b[32m[I 2022-04-22 00:21:26,089]\u001b[0m Trial 60 finished with value: 0.022194439090888106 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.022194439090888106.\u001b[0m\nmin_data_in_leaf, val_score: 0.022194:  20%|##        | 1/5 [00:16<01:06, 16.61s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216742\tValid's rmse: 0.0221944\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067951 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222278\n[200]\tTrain's rmse: 0.0217545\tValid's rmse: 0.0222143\n[300]\tTrain's rmse: 0.0217328\tValid's rmse: 0.0222015\n[400]\tTrain's rmse: 0.0217141\tValid's rmse: 0.0221999\n[500]\tTrain's rmse: 0.0216964\tValid's rmse: 0.0221978\n[600]\tTrain's rmse: 0.0216796\tValid's rmse: 0.0221967\n[700]\tTrain's rmse: 0.0216642\tValid's rmse: 0.0221993\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022194:  40%|####      | 2/5 [00:32<00:48, 16.11s/it]\u001b[32m[I 2022-04-22 00:21:41,842]\u001b[0m Trial 61 finished with value: 0.022194439090888106 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.022194439090888106.\u001b[0m\nmin_data_in_leaf, val_score: 0.022194:  40%|####      | 2/5 [00:32<00:48, 16.11s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216742\tValid's rmse: 0.0221944\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067953 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222278\n[200]\tTrain's rmse: 0.0217545\tValid's rmse: 0.0222143\n[300]\tTrain's rmse: 0.0217328\tValid's rmse: 0.0222015\n[400]\tTrain's rmse: 0.0217141\tValid's rmse: 0.0221999\n[500]\tTrain's rmse: 0.0216964\tValid's rmse: 0.0221978\n[600]\tTrain's rmse: 0.0216796\tValid's rmse: 0.0221967\n[700]\tTrain's rmse: 0.0216642\tValid's rmse: 0.0221993\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022194:  60%|######    | 3/5 [00:48<00:32, 16.27s/it]\u001b[32m[I 2022-04-22 00:21:58,304]\u001b[0m Trial 62 finished with value: 0.022194439090888106 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.022194439090888106.\u001b[0m\nmin_data_in_leaf, val_score: 0.022194:  60%|######    | 3/5 [00:48<00:32, 16.27s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216742\tValid's rmse: 0.0221944\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067402 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222278\n[200]\tTrain's rmse: 0.0217545\tValid's rmse: 0.0222143\n[300]\tTrain's rmse: 0.0217328\tValid's rmse: 0.0222015\n[400]\tTrain's rmse: 0.0217141\tValid's rmse: 0.0221999\n[500]\tTrain's rmse: 0.0216964\tValid's rmse: 0.0221978\n[600]\tTrain's rmse: 0.0216796\tValid's rmse: 0.0221967\n[700]\tTrain's rmse: 0.0216642\tValid's rmse: 0.0221993\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022194:  80%|########  | 4/5 [01:04<00:15, 15.98s/it]\u001b[32m[I 2022-04-22 00:22:13,828]\u001b[0m Trial 63 finished with value: 0.022194439090888106 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.022194439090888106.\u001b[0m\nmin_data_in_leaf, val_score: 0.022194:  80%|########  | 4/5 [01:04<00:15, 15.98s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216742\tValid's rmse: 0.0221944\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067812 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222278\n[200]\tTrain's rmse: 0.0217545\tValid's rmse: 0.0222143\n[300]\tTrain's rmse: 0.0217328\tValid's rmse: 0.0222015\n[400]\tTrain's rmse: 0.0217141\tValid's rmse: 0.0221999\n[500]\tTrain's rmse: 0.0216964\tValid's rmse: 0.0221978\n[600]\tTrain's rmse: 0.0216796\tValid's rmse: 0.0221967\n[700]\tTrain's rmse: 0.0216642\tValid's rmse: 0.0221993\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022194: 100%|##########| 5/5 [01:20<00:00, 16.15s/it]\u001b[32m[I 2022-04-22 00:22:30,286]\u001b[0m Trial 64 finished with value: 0.022194439090888106 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.022194439090888106.\u001b[0m\nmin_data_in_leaf, val_score: 0.022194: 100%|##########| 5/5 [01:20<00:00, 16.16s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[636]\tTrain's rmse: 0.0216742\tValid's rmse: 0.0221944\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stderr","text":"\u001b[32m[I 2022-04-22 00:22:31,613]\u001b[0m A new study created in memory with name: no-name-53686dfc-3c43-48ff-bdee-8fc840ad67c8\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059799 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215202\tValid's rmse: 0.0251051\n[200]\tTrain's rmse: 0.0214947\tValid's rmse: 0.0250906\n[300]\tTrain's rmse: 0.0214754\tValid's rmse: 0.0250798\n[400]\tTrain's rmse: 0.0214593\tValid's rmse: 0.0250706\n[500]\tTrain's rmse: 0.0214457\tValid's rmse: 0.0250643\n[600]\tTrain's rmse: 0.0214327\tValid's rmse: 0.0250579\n[700]\tTrain's rmse: 0.0214208\tValid's rmse: 0.0250554\n[800]\tTrain's rmse: 0.0214106\tValid's rmse: 0.0250509\n[900]\tTrain's rmse: 0.0214005\tValid's rmse: 0.0250448\n[1000]\tTrain's rmse: 0.0213901\tValid's rmse: 0.0250387\n[1100]\tTrain's rmse: 0.0213803\tValid's rmse: 0.0250409\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025038:  14%|#4        | 1/7 [00:22<02:15, 22.59s/it]\u001b[32m[I 2022-04-22 00:22:54,211]\u001b[0m Trial 0 finished with value: 0.025037787064584614 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.025037787064584614.\u001b[0m\nfeature_fraction, val_score: 0.025038:  14%|#4        | 1/7 [00:22<02:15, 22.59s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1030]\tTrain's rmse: 0.021387\tValid's rmse: 0.0250378\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066650 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215169\tValid's rmse: 0.0250939\n[200]\tTrain's rmse: 0.0214904\tValid's rmse: 0.0250745\n[300]\tTrain's rmse: 0.0214699\tValid's rmse: 0.0250659\n[400]\tTrain's rmse: 0.021453\tValid's rmse: 0.0250598\n[500]\tTrain's rmse: 0.0214386\tValid's rmse: 0.0250514\n[600]\tTrain's rmse: 0.0214245\tValid's rmse: 0.0250477\n[700]\tTrain's rmse: 0.0214117\tValid's rmse: 0.0250431\n[800]\tTrain's rmse: 0.0214002\tValid's rmse: 0.0250386\n[900]\tTrain's rmse: 0.021389\tValid's rmse: 0.0250283\n[1000]\tTrain's rmse: 0.0213777\tValid's rmse: 0.0250207\n[1100]\tTrain's rmse: 0.021367\tValid's rmse: 0.0250216\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025019:  29%|##8       | 2/7 [00:46<01:57, 23.44s/it]\u001b[32m[I 2022-04-22 00:23:18,247]\u001b[0m Trial 1 finished with value: 0.025019429185763376 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.025019429185763376.\u001b[0m\nfeature_fraction, val_score: 0.025019:  29%|##8       | 2/7 [00:46<01:57, 23.44s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1052]\tTrain's rmse: 0.0213719\tValid's rmse: 0.0250194\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215176\tValid's rmse: 0.0250973\n[200]\tTrain's rmse: 0.0214916\tValid's rmse: 0.0250819\n[300]\tTrain's rmse: 0.0214722\tValid's rmse: 0.0250747\n[400]\tTrain's rmse: 0.0214549\tValid's rmse: 0.0250641\n[500]\tTrain's rmse: 0.021441\tValid's rmse: 0.0250581\n[600]\tTrain's rmse: 0.0214272\tValid's rmse: 0.0250552\n[700]\tTrain's rmse: 0.0214148\tValid's rmse: 0.0250499\n[800]\tTrain's rmse: 0.0214037\tValid's rmse: 0.0250452\n[900]\tTrain's rmse: 0.0213929\tValid's rmse: 0.0250372\n[1000]\tTrain's rmse: 0.0213821\tValid's rmse: 0.0250308\n[1100]\tTrain's rmse: 0.0213717\tValid's rmse: 0.0250331\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025019:  43%|####2     | 3/7 [01:10<01:34, 23.53s/it]\u001b[32m[I 2022-04-22 00:23:41,881]\u001b[0m Trial 2 finished with value: 0.02502967451856664 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.025019429185763376.\u001b[0m\nfeature_fraction, val_score: 0.025019:  43%|####2     | 3/7 [01:10<01:34, 23.53s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1027]\tTrain's rmse: 0.0213792\tValid's rmse: 0.0250297\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060992 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215188\tValid's rmse: 0.0251026\n[200]\tTrain's rmse: 0.0214928\tValid's rmse: 0.0250879\n[300]\tTrain's rmse: 0.0214737\tValid's rmse: 0.0250759\n[400]\tTrain's rmse: 0.0214574\tValid's rmse: 0.0250645\n[500]\tTrain's rmse: 0.0214438\tValid's rmse: 0.0250582\n[600]\tTrain's rmse: 0.0214306\tValid's rmse: 0.0250525\n[700]\tTrain's rmse: 0.0214186\tValid's rmse: 0.0250507\n[800]\tTrain's rmse: 0.0214081\tValid's rmse: 0.0250472\n[900]\tTrain's rmse: 0.0213973\tValid's rmse: 0.0250412\n[1000]\tTrain's rmse: 0.0213866\tValid's rmse: 0.0250335\n[1100]\tTrain's rmse: 0.0213769\tValid's rmse: 0.0250357\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025019:  57%|#####7    | 4/7 [01:32<01:09, 23.21s/it]\u001b[32m[I 2022-04-22 00:24:04,592]\u001b[0m Trial 3 finished with value: 0.02503209746824251 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.025019429185763376.\u001b[0m\nfeature_fraction, val_score: 0.025019:  57%|#####7    | 4/7 [01:32<01:09, 23.21s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1029]\tTrain's rmse: 0.0213837\tValid's rmse: 0.0250321\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215221\tValid's rmse: 0.0251129\n[200]\tTrain's rmse: 0.0214968\tValid's rmse: 0.0250965\n[300]\tTrain's rmse: 0.021478\tValid's rmse: 0.0250877\n[400]\tTrain's rmse: 0.0214626\tValid's rmse: 0.0250763\n[500]\tTrain's rmse: 0.0214493\tValid's rmse: 0.025068\n[600]\tTrain's rmse: 0.0214369\tValid's rmse: 0.0250615\n[700]\tTrain's rmse: 0.0214256\tValid's rmse: 0.0250562\n[800]\tTrain's rmse: 0.0214154\tValid's rmse: 0.025051\n[900]\tTrain's rmse: 0.0214056\tValid's rmse: 0.0250461\n[1000]\tTrain's rmse: 0.0213957\tValid's rmse: 0.02504\n[1100]\tTrain's rmse: 0.0213865\tValid's rmse: 0.0250396\n[1200]\tTrain's rmse: 0.0213781\tValid's rmse: 0.0250366\n[1300]\tTrain's rmse: 0.0213696\tValid's rmse: 0.0250365\n[1400]\tTrain's rmse: 0.0213612\tValid's rmse: 0.0250333\n[1500]\tTrain's rmse: 0.0213533\tValid's rmse: 0.0250327\n[1600]\tTrain's rmse: 0.0213453\tValid's rmse: 0.0250264\n[1700]\tTrain's rmse: 0.0213372\tValid's rmse: 0.0250252\n[1800]\tTrain's rmse: 0.02133\tValid's rmse: 0.0250213\n[1900]\tTrain's rmse: 0.0213228\tValid's rmse: 0.0250193\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018:  71%|#######1  | 5/7 [02:07<00:54, 27.19s/it]\u001b[32m[I 2022-04-22 00:24:38,850]\u001b[0m Trial 4 finished with value: 0.025017629064798954 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018:  71%|#######1  | 5/7 [02:07<00:54, 27.19s/it]","output_type":"stream"},{"name":"stdout","text":"[2000]\tTrain's rmse: 0.0213158\tValid's rmse: 0.0250176\nDid not meet early stopping. Best iteration is:\n[2000]\tTrain's rmse: 0.0213158\tValid's rmse: 0.0250176\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021517\tValid's rmse: 0.0250913\n[200]\tTrain's rmse: 0.0214905\tValid's rmse: 0.0250716\n[300]\tTrain's rmse: 0.0214698\tValid's rmse: 0.0250642\n[400]\tTrain's rmse: 0.0214527\tValid's rmse: 0.0250606\n[500]\tTrain's rmse: 0.0214384\tValid's rmse: 0.0250513\n[600]\tTrain's rmse: 0.021424\tValid's rmse: 0.0250457\n[700]\tTrain's rmse: 0.0214114\tValid's rmse: 0.0250415\n[800]\tTrain's rmse: 0.0213997\tValid's rmse: 0.0250383\n[900]\tTrain's rmse: 0.0213886\tValid's rmse: 0.0250294\n[1000]\tTrain's rmse: 0.0213774\tValid's rmse: 0.025022\n[1100]\tTrain's rmse: 0.0213664\tValid's rmse: 0.0250224\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018:  86%|########5 | 6/7 [02:31<00:26, 26.19s/it]\u001b[32m[I 2022-04-22 00:25:03,095]\u001b[0m Trial 5 finished with value: 0.025020526329578924 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018:  86%|########5 | 6/7 [02:31<00:26, 26.19s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1030]\tTrain's rmse: 0.0213739\tValid's rmse: 0.0250205\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069681 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215167\tValid's rmse: 0.0250944\n[200]\tTrain's rmse: 0.0214907\tValid's rmse: 0.0250773\n[300]\tTrain's rmse: 0.0214704\tValid's rmse: 0.0250682\n[400]\tTrain's rmse: 0.0214534\tValid's rmse: 0.0250621\n[500]\tTrain's rmse: 0.0214393\tValid's rmse: 0.0250535\n[600]\tTrain's rmse: 0.0214252\tValid's rmse: 0.0250483\n[700]\tTrain's rmse: 0.0214126\tValid's rmse: 0.0250426\n[800]\tTrain's rmse: 0.0214013\tValid's rmse: 0.0250373\n[900]\tTrain's rmse: 0.02139\tValid's rmse: 0.0250285\n[1000]\tTrain's rmse: 0.021379\tValid's rmse: 0.0250226\n[1100]\tTrain's rmse: 0.0213684\tValid's rmse: 0.0250243\n[1200]\tTrain's rmse: 0.0213587\tValid's rmse: 0.0250227\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018: 100%|##########| 7/7 [02:57<00:00, 26.12s/it]\u001b[32m[I 2022-04-22 00:25:29,066]\u001b[0m Trial 6 finished with value: 0.025021501616482204 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018: 100%|##########| 7/7 [02:57<00:00, 25.35s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1147]\tTrain's rmse: 0.0213639\tValid's rmse: 0.0250215\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.025018:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058120 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214765\tValid's rmse: 0.0250914\n[200]\tTrain's rmse: 0.0214161\tValid's rmse: 0.0250644\n[300]\tTrain's rmse: 0.0213679\tValid's rmse: 0.0250482\n[400]\tTrain's rmse: 0.0213245\tValid's rmse: 0.0250332\n[500]\tTrain's rmse: 0.021286\tValid's rmse: 0.0250228\n[600]\tTrain's rmse: 0.0212492\tValid's rmse: 0.0250129\n[700]\tTrain's rmse: 0.0212139\tValid's rmse: 0.0250082\n[800]\tTrain's rmse: 0.0211811\tValid's rmse: 0.0250019\n[900]\tTrain's rmse: 0.0211498\tValid's rmse: 0.0249963\n[1000]\tTrain's rmse: 0.021119\tValid's rmse: 0.0249897\n[1100]\tTrain's rmse: 0.0210893\tValid's rmse: 0.0249894\n[1200]\tTrain's rmse: 0.0210611\tValid's rmse: 0.024986\nEarly stopping, best iteration is:\n[1150]\tTrain's rmse: 0.0210748\tValid's rmse: 0.0249853\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:   5%|5         | 1/20 [00:41<13:04, 41.31s/it]\u001b[32m[I 2022-04-22 00:26:10,386]\u001b[0m Trial 7 finished with value: 0.024985308043902078 and parameters: {'num_leaves': 48}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:   5%|5         | 1/20 [00:41<13:04, 41.31s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021497\tValid's rmse: 0.025098\n[200]\tTrain's rmse: 0.0214533\tValid's rmse: 0.025073\n[300]\tTrain's rmse: 0.0214194\tValid's rmse: 0.0250586\n[400]\tTrain's rmse: 0.0213894\tValid's rmse: 0.0250458\n[500]\tTrain's rmse: 0.0213635\tValid's rmse: 0.0250358\n[600]\tTrain's rmse: 0.0213387\tValid's rmse: 0.0250267\n[700]\tTrain's rmse: 0.0213154\tValid's rmse: 0.025024\n[800]\tTrain's rmse: 0.0212935\tValid's rmse: 0.0250174\n[900]\tTrain's rmse: 0.0212735\tValid's rmse: 0.0250112\n[1000]\tTrain's rmse: 0.0212532\tValid's rmse: 0.0250023\n[1100]\tTrain's rmse: 0.0212338\tValid's rmse: 0.0250019\n[1200]\tTrain's rmse: 0.021215\tValid's rmse: 0.0249988\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  10%|#         | 2/20 [01:13<10:42, 35.70s/it]\u001b[32m[I 2022-04-22 00:26:42,168]\u001b[0m Trial 8 finished with value: 0.02499827613466927 and parameters: {'num_leaves': 27}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  10%|#         | 2/20 [01:13<10:42, 35.70s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0212252\tValid's rmse: 0.0249983\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058469 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213913\tValid's rmse: 0.0250759\n[200]\tTrain's rmse: 0.0212569\tValid's rmse: 0.0250466\n[300]\tTrain's rmse: 0.0211399\tValid's rmse: 0.025033\n[400]\tTrain's rmse: 0.0210316\tValid's rmse: 0.0250184\n[500]\tTrain's rmse: 0.0209313\tValid's rmse: 0.0250069\n[600]\tTrain's rmse: 0.0208364\tValid's rmse: 0.0250009\n[700]\tTrain's rmse: 0.0207443\tValid's rmse: 0.0250014\nEarly stopping, best iteration is:\n[601]\tTrain's rmse: 0.0208355\tValid's rmse: 0.0250008\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  15%|#5        | 3/20 [01:57<11:12, 39.56s/it]\u001b[32m[I 2022-04-22 00:27:26,307]\u001b[0m Trial 9 finished with value: 0.0250008303865706 and parameters: {'num_leaves': 202}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  15%|#5        | 3/20 [01:57<11:12, 39.56s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068059 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213862\tValid's rmse: 0.0250759\n[200]\tTrain's rmse: 0.0212465\tValid's rmse: 0.0250447\n[300]\tTrain's rmse: 0.0211254\tValid's rmse: 0.0250313\n[400]\tTrain's rmse: 0.0210129\tValid's rmse: 0.0250169\n[500]\tTrain's rmse: 0.0209089\tValid's rmse: 0.0250056\n[600]\tTrain's rmse: 0.0208105\tValid's rmse: 0.0249984\n[700]\tTrain's rmse: 0.0207147\tValid's rmse: 0.024996\n[800]\tTrain's rmse: 0.0206239\tValid's rmse: 0.0249964\n[900]\tTrain's rmse: 0.0205376\tValid's rmse: 0.0249932\n[1000]\tTrain's rmse: 0.0204525\tValid's rmse: 0.0249892\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0204705\tValid's rmse: 0.0249885\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  20%|##        | 4/20 [03:06<13:40, 51.26s/it]\u001b[32m[I 2022-04-22 00:28:35,518]\u001b[0m Trial 10 finished with value: 0.02498854335649863 and parameters: {'num_leaves': 215}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  20%|##        | 4/20 [03:06<13:40, 51.26s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060091 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213885\tValid's rmse: 0.0250763\n[200]\tTrain's rmse: 0.0212513\tValid's rmse: 0.0250449\n[300]\tTrain's rmse: 0.021132\tValid's rmse: 0.0250308\n[400]\tTrain's rmse: 0.0210222\tValid's rmse: 0.0250149\n[500]\tTrain's rmse: 0.02092\tValid's rmse: 0.0250049\n[600]\tTrain's rmse: 0.0208224\tValid's rmse: 0.0249982\n[700]\tTrain's rmse: 0.0207285\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0206396\tValid's rmse: 0.0249952\n[900]\tTrain's rmse: 0.0205551\tValid's rmse: 0.0249928\n[1000]\tTrain's rmse: 0.0204703\tValid's rmse: 0.02499\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0204884\tValid's rmse: 0.0249891\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  25%|##5       | 5/20 [04:14<14:17, 57.20s/it]\u001b[32m[I 2022-04-22 00:29:43,234]\u001b[0m Trial 11 finished with value: 0.0249890591011333 and parameters: {'num_leaves': 209}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  25%|##5       | 5/20 [04:14<14:17, 57.20s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068274 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213748\tValid's rmse: 0.0250776\n[200]\tTrain's rmse: 0.021225\tValid's rmse: 0.0250473\n[300]\tTrain's rmse: 0.0210951\tValid's rmse: 0.0250328\n[400]\tTrain's rmse: 0.0209742\tValid's rmse: 0.0250196\n[500]\tTrain's rmse: 0.0208618\tValid's rmse: 0.0250101\n[600]\tTrain's rmse: 0.0207547\tValid's rmse: 0.0250007\n[700]\tTrain's rmse: 0.0206511\tValid's rmse: 0.0249981\nEarly stopping, best iteration is:\n[699]\tTrain's rmse: 0.0206521\tValid's rmse: 0.0249978\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  30%|###       | 6/20 [05:10<13:16, 56.86s/it]\u001b[32m[I 2022-04-22 00:30:39,454]\u001b[0m Trial 12 finished with value: 0.02499778631823486 and parameters: {'num_leaves': 246}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  30%|###       | 6/20 [05:10<13:16, 56.86s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063044 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215115\tValid's rmse: 0.0251053\n[200]\tTrain's rmse: 0.0214787\tValid's rmse: 0.0250863\n[300]\tTrain's rmse: 0.0214538\tValid's rmse: 0.0250744\n[400]\tTrain's rmse: 0.0214328\tValid's rmse: 0.0250616\n[500]\tTrain's rmse: 0.0214152\tValid's rmse: 0.0250524\n[600]\tTrain's rmse: 0.021398\tValid's rmse: 0.0250455\n[700]\tTrain's rmse: 0.0213822\tValid's rmse: 0.0250403\n[800]\tTrain's rmse: 0.0213673\tValid's rmse: 0.0250348\n[900]\tTrain's rmse: 0.0213535\tValid's rmse: 0.0250287\n[1000]\tTrain's rmse: 0.0213396\tValid's rmse: 0.0250218\n[1100]\tTrain's rmse: 0.0213261\tValid's rmse: 0.0250223\n[1200]\tTrain's rmse: 0.0213137\tValid's rmse: 0.0250183\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  35%|###5      | 7/20 [05:37<10:14, 47.25s/it]\u001b[32m[I 2022-04-22 00:31:06,919]\u001b[0m Trial 13 finished with value: 0.02501768003901564 and parameters: {'num_leaves': 16}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  35%|###5      | 7/20 [05:37<10:14, 47.25s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1190]\tTrain's rmse: 0.021315\tValid's rmse: 0.0250177\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008182 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214212\tValid's rmse: 0.02508\n[200]\tTrain's rmse: 0.0213138\tValid's rmse: 0.0250481\n[300]\tTrain's rmse: 0.021222\tValid's rmse: 0.0250333\n[400]\tTrain's rmse: 0.0211381\tValid's rmse: 0.0250186\n[500]\tTrain's rmse: 0.0210608\tValid's rmse: 0.0250078\n[600]\tTrain's rmse: 0.0209873\tValid's rmse: 0.0249992\n[700]\tTrain's rmse: 0.0209168\tValid's rmse: 0.0249992\nEarly stopping, best iteration is:\n[655]\tTrain's rmse: 0.0209484\tValid's rmse: 0.0249972\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  40%|####      | 8/20 [06:20<09:09, 45.77s/it]\u001b[32m[I 2022-04-22 00:31:49,509]\u001b[0m Trial 14 finished with value: 0.024997246656033107 and parameters: {'num_leaves': 135}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  40%|####      | 8/20 [06:20<09:09, 45.77s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058461 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213906\tValid's rmse: 0.0250764\n[200]\tTrain's rmse: 0.0212549\tValid's rmse: 0.0250453\n[300]\tTrain's rmse: 0.0211375\tValid's rmse: 0.0250313\n[400]\tTrain's rmse: 0.0210289\tValid's rmse: 0.0250161\n[500]\tTrain's rmse: 0.0209279\tValid's rmse: 0.0250065\n[600]\tTrain's rmse: 0.0208326\tValid's rmse: 0.0250006\n[700]\tTrain's rmse: 0.0207399\tValid's rmse: 0.0249994\nEarly stopping, best iteration is:\n[661]\tTrain's rmse: 0.0207758\tValid's rmse: 0.0249984\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  45%|####5     | 9/20 [07:08<08:29, 46.33s/it]\u001b[32m[I 2022-04-22 00:32:37,078]\u001b[0m Trial 15 finished with value: 0.024998437574066553 and parameters: {'num_leaves': 204}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  45%|####5     | 9/20 [07:08<08:29, 46.33s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058116 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213992\tValid's rmse: 0.0250779\n[200]\tTrain's rmse: 0.021272\tValid's rmse: 0.0250466\n[300]\tTrain's rmse: 0.021162\tValid's rmse: 0.0250326\n[400]\tTrain's rmse: 0.0210607\tValid's rmse: 0.0250173\n[500]\tTrain's rmse: 0.0209666\tValid's rmse: 0.0250078\n[600]\tTrain's rmse: 0.0208768\tValid's rmse: 0.0249995\n[700]\tTrain's rmse: 0.020791\tValid's rmse: 0.0249962\n[800]\tTrain's rmse: 0.0207102\tValid's rmse: 0.0249955\n[900]\tTrain's rmse: 0.0206325\tValid's rmse: 0.0249927\n[1000]\tTrain's rmse: 0.0205549\tValid's rmse: 0.0249903\nEarly stopping, best iteration is:\n[980]\tTrain's rmse: 0.0205704\tValid's rmse: 0.0249888\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024985:  50%|#####     | 10/20 [08:12<08:38, 51.88s/it]\u001b[32m[I 2022-04-22 00:33:41,383]\u001b[0m Trial 16 finished with value: 0.02498879646166825 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 0.024985308043902078.\u001b[0m\nnum_leaves, val_score: 0.024985:  50%|#####     | 10/20 [08:12<08:38, 51.88s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0250849\n[200]\tTrain's rmse: 0.0213795\tValid's rmse: 0.025054\n[300]\tTrain's rmse: 0.0213157\tValid's rmse: 0.0250386\n[400]\tTrain's rmse: 0.0212585\tValid's rmse: 0.0250218\n[500]\tTrain's rmse: 0.0212067\tValid's rmse: 0.02501\n[600]\tTrain's rmse: 0.0211576\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0211106\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210652\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.021023\tValid's rmse: 0.0249872\n[1000]\tTrain's rmse: 0.0209806\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.0209403\tValid's rmse: 0.024978\n[1200]\tTrain's rmse: 0.0209012\tValid's rmse: 0.0249765\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209224\tValid's rmse: 0.0249745\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  55%|#####5    | 11/20 [09:02<07:41, 51.32s/it]\u001b[32m[I 2022-04-22 00:34:31,438]\u001b[0m Trial 17 finished with value: 0.0249745372385883 and parameters: {'num_leaves': 74}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  55%|#####5    | 11/20 [09:02<07:41, 51.32s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059826 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214563\tValid's rmse: 0.0250854\n[200]\tTrain's rmse: 0.0213788\tValid's rmse: 0.0250546\n[300]\tTrain's rmse: 0.0213144\tValid's rmse: 0.0250404\n[400]\tTrain's rmse: 0.0212565\tValid's rmse: 0.0250253\n[500]\tTrain's rmse: 0.0212042\tValid's rmse: 0.0250133\n[600]\tTrain's rmse: 0.0211544\tValid's rmse: 0.0250039\n[700]\tTrain's rmse: 0.0211068\tValid's rmse: 0.0249992\n[800]\tTrain's rmse: 0.0210612\tValid's rmse: 0.0249952\n[900]\tTrain's rmse: 0.0210189\tValid's rmse: 0.0249882\n[1000]\tTrain's rmse: 0.0209764\tValid's rmse: 0.0249808\n[1100]\tTrain's rmse: 0.0209355\tValid's rmse: 0.02498\n[1200]\tTrain's rmse: 0.0208959\tValid's rmse: 0.0249792\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209176\tValid's rmse: 0.0249779\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  60%|######    | 12/20 [09:52<06:47, 50.90s/it]\u001b[32m[I 2022-04-22 00:35:21,375]\u001b[0m Trial 18 finished with value: 0.024977941692683806 and parameters: {'num_leaves': 75}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  60%|######    | 12/20 [09:52<06:47, 50.90s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058628 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214549\tValid's rmse: 0.0250847\n[200]\tTrain's rmse: 0.0213762\tValid's rmse: 0.0250541\n[300]\tTrain's rmse: 0.0213112\tValid's rmse: 0.0250401\n[400]\tTrain's rmse: 0.0212523\tValid's rmse: 0.0250244\n[500]\tTrain's rmse: 0.021199\tValid's rmse: 0.0250098\n[600]\tTrain's rmse: 0.0211484\tValid's rmse: 0.0250005\n[700]\tTrain's rmse: 0.0210998\tValid's rmse: 0.0249963\n[800]\tTrain's rmse: 0.0210537\tValid's rmse: 0.0249923\n[900]\tTrain's rmse: 0.0210108\tValid's rmse: 0.0249853\n[1000]\tTrain's rmse: 0.0209669\tValid's rmse: 0.0249788\n[1100]\tTrain's rmse: 0.020925\tValid's rmse: 0.0249776\n[1200]\tTrain's rmse: 0.0208846\tValid's rmse: 0.024977\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209066\tValid's rmse: 0.0249757\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  65%|######5   | 13/20 [10:42<05:55, 50.81s/it]\u001b[32m[I 2022-04-22 00:36:11,991]\u001b[0m Trial 19 finished with value: 0.024975665472204405 and parameters: {'num_leaves': 77}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  65%|######5   | 13/20 [10:42<05:55, 50.81s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059376 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214416\tValid's rmse: 0.0250835\n[200]\tTrain's rmse: 0.0213511\tValid's rmse: 0.0250508\n[300]\tTrain's rmse: 0.0212746\tValid's rmse: 0.0250364\n[400]\tTrain's rmse: 0.0212062\tValid's rmse: 0.025019\n[500]\tTrain's rmse: 0.0211438\tValid's rmse: 0.0250063\n[600]\tTrain's rmse: 0.0210844\tValid's rmse: 0.0249964\n[700]\tTrain's rmse: 0.0210272\tValid's rmse: 0.0249924\n[800]\tTrain's rmse: 0.0209721\tValid's rmse: 0.0249902\n[900]\tTrain's rmse: 0.0209208\tValid's rmse: 0.0249837\n[1000]\tTrain's rmse: 0.0208689\tValid's rmse: 0.0249768\n[1100]\tTrain's rmse: 0.02082\tValid's rmse: 0.0249772\nEarly stopping, best iteration is:\n[1014]\tTrain's rmse: 0.0208617\tValid's rmse: 0.0249757\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  70%|#######   | 14/20 [11:34<05:05, 50.94s/it]\u001b[32m[I 2022-04-22 00:37:03,234]\u001b[0m Trial 20 finished with value: 0.024975737127401813 and parameters: {'num_leaves': 98}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  70%|#######   | 14/20 [11:34<05:05, 50.94s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060251 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214242\tValid's rmse: 0.0250813\n[200]\tTrain's rmse: 0.021319\tValid's rmse: 0.0250499\n[300]\tTrain's rmse: 0.0212294\tValid's rmse: 0.0250345\n[400]\tTrain's rmse: 0.0211481\tValid's rmse: 0.0250176\n[500]\tTrain's rmse: 0.0210732\tValid's rmse: 0.025005\n[600]\tTrain's rmse: 0.021002\tValid's rmse: 0.0249973\n[700]\tTrain's rmse: 0.0209334\tValid's rmse: 0.0249949\n[800]\tTrain's rmse: 0.0208677\tValid's rmse: 0.024992\n[900]\tTrain's rmse: 0.020806\tValid's rmse: 0.0249851\n[1000]\tTrain's rmse: 0.0207441\tValid's rmse: 0.0249809\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0207569\tValid's rmse: 0.0249788\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  75%|#######5  | 15/20 [12:29<04:20, 52.14s/it]\u001b[32m[I 2022-04-22 00:37:58,146]\u001b[0m Trial 21 finished with value: 0.024978834055807267 and parameters: {'num_leaves': 129}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  75%|#######5  | 15/20 [12:29<04:20, 52.14s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063961 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0250852\n[200]\tTrain's rmse: 0.0213819\tValid's rmse: 0.0250554\n[300]\tTrain's rmse: 0.0213195\tValid's rmse: 0.0250405\n[400]\tTrain's rmse: 0.0212632\tValid's rmse: 0.0250234\n[500]\tTrain's rmse: 0.0212123\tValid's rmse: 0.0250124\n[600]\tTrain's rmse: 0.0211638\tValid's rmse: 0.0250046\n[700]\tTrain's rmse: 0.0211179\tValid's rmse: 0.0250024\n[800]\tTrain's rmse: 0.0210738\tValid's rmse: 0.0249994\n[900]\tTrain's rmse: 0.0210326\tValid's rmse: 0.0249923\n[1000]\tTrain's rmse: 0.0209914\tValid's rmse: 0.0249862\n[1100]\tTrain's rmse: 0.0209514\tValid's rmse: 0.0249848\n[1200]\tTrain's rmse: 0.0209133\tValid's rmse: 0.0249838\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209342\tValid's rmse: 0.024982\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  80%|########  | 16/20 [13:18<03:24, 51.19s/it]\u001b[32m[I 2022-04-22 00:38:47,117]\u001b[0m Trial 22 finished with value: 0.024982030596530327 and parameters: {'num_leaves': 72}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  80%|########  | 16/20 [13:18<03:24, 51.19s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021429\tValid's rmse: 0.0250822\n[200]\tTrain's rmse: 0.0213283\tValid's rmse: 0.0250517\n[300]\tTrain's rmse: 0.0212427\tValid's rmse: 0.0250373\n[400]\tTrain's rmse: 0.0211649\tValid's rmse: 0.0250198\n[500]\tTrain's rmse: 0.0210932\tValid's rmse: 0.025007\n[600]\tTrain's rmse: 0.0210247\tValid's rmse: 0.0249976\n[700]\tTrain's rmse: 0.0209591\tValid's rmse: 0.0249954\nEarly stopping, best iteration is:\n[655]\tTrain's rmse: 0.0209885\tValid's rmse: 0.0249943\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  85%|########5 | 17/20 [13:56<02:22, 47.43s/it]\u001b[32m[I 2022-04-22 00:39:25,829]\u001b[0m Trial 23 finished with value: 0.02499434417508548 and parameters: {'num_leaves': 120}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  85%|########5 | 17/20 [13:56<02:22, 47.43s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060176 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214099\tValid's rmse: 0.0250777\n[200]\tTrain's rmse: 0.0212924\tValid's rmse: 0.0250466\n[300]\tTrain's rmse: 0.0211915\tValid's rmse: 0.0250328\n[400]\tTrain's rmse: 0.021099\tValid's rmse: 0.0250163\n[500]\tTrain's rmse: 0.021014\tValid's rmse: 0.0250042\n[600]\tTrain's rmse: 0.0209328\tValid's rmse: 0.0249941\n[700]\tTrain's rmse: 0.0208552\tValid's rmse: 0.0249943\n[800]\tTrain's rmse: 0.0207806\tValid's rmse: 0.024991\n[900]\tTrain's rmse: 0.0207097\tValid's rmse: 0.0249853\n[1000]\tTrain's rmse: 0.0206393\tValid's rmse: 0.0249846\nEarly stopping, best iteration is:\n[980]\tTrain's rmse: 0.0206535\tValid's rmse: 0.0249818\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  90%|######### | 18/20 [14:58<01:43, 51.74s/it]\u001b[32m[I 2022-04-22 00:40:27,584]\u001b[0m Trial 24 finished with value: 0.02498181169129736 and parameters: {'num_leaves': 157}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  90%|######### | 18/20 [14:58<01:43, 51.74s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058926 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214599\tValid's rmse: 0.0250858\n[200]\tTrain's rmse: 0.0213856\tValid's rmse: 0.0250559\n[300]\tTrain's rmse: 0.0213245\tValid's rmse: 0.025041\n[400]\tTrain's rmse: 0.0212697\tValid's rmse: 0.0250242\n[500]\tTrain's rmse: 0.0212202\tValid's rmse: 0.0250138\n[600]\tTrain's rmse: 0.0211731\tValid's rmse: 0.025006\n[700]\tTrain's rmse: 0.0211281\tValid's rmse: 0.0250026\n[800]\tTrain's rmse: 0.0210851\tValid's rmse: 0.0249975\n[900]\tTrain's rmse: 0.0210452\tValid's rmse: 0.0249916\n[1000]\tTrain's rmse: 0.0210055\tValid's rmse: 0.0249845\n[1100]\tTrain's rmse: 0.0209671\tValid's rmse: 0.0249815\n[1200]\tTrain's rmse: 0.02093\tValid's rmse: 0.0249788\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209504\tValid's rmse: 0.0249776\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  95%|#########5| 19/20 [15:47<00:50, 50.93s/it]\u001b[32m[I 2022-04-22 00:41:16,635]\u001b[0m Trial 25 finished with value: 0.024977583546187027 and parameters: {'num_leaves': 69}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975:  95%|#########5| 19/20 [15:47<00:50, 50.93s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059899 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214838\tValid's rmse: 0.0250938\n[200]\tTrain's rmse: 0.0214292\tValid's rmse: 0.0250673\n[300]\tTrain's rmse: 0.0213855\tValid's rmse: 0.025051\n[400]\tTrain's rmse: 0.0213473\tValid's rmse: 0.0250361\n[500]\tTrain's rmse: 0.0213131\tValid's rmse: 0.0250253\n[600]\tTrain's rmse: 0.0212807\tValid's rmse: 0.0250161\n[700]\tTrain's rmse: 0.0212503\tValid's rmse: 0.0250125\n[800]\tTrain's rmse: 0.0212214\tValid's rmse: 0.0250062\n[900]\tTrain's rmse: 0.021194\tValid's rmse: 0.0249997\n[1000]\tTrain's rmse: 0.0211668\tValid's rmse: 0.0249936\n[1100]\tTrain's rmse: 0.021141\tValid's rmse: 0.0249928\n[1200]\tTrain's rmse: 0.0211163\tValid's rmse: 0.0249905\nEarly stopping, best iteration is:\n[1195]\tTrain's rmse: 0.0211176\tValid's rmse: 0.0249898\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975: 100%|##########| 20/20 [16:27<00:00, 47.70s/it]\u001b[32m[I 2022-04-22 00:41:56,796]\u001b[0m Trial 26 finished with value: 0.024989816608611146 and parameters: {'num_leaves': 40}. Best is trial 17 with value: 0.0249745372385883.\u001b[0m\nnum_leaves, val_score: 0.024975: 100%|##########| 20/20 [16:27<00:00, 49.39s/it]\nbagging, val_score: 0.024975:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059237 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214525\tValid's rmse: 0.0250851\n[200]\tTrain's rmse: 0.0213726\tValid's rmse: 0.0250564\n[300]\tTrain's rmse: 0.0213061\tValid's rmse: 0.0250367\n[400]\tTrain's rmse: 0.0212462\tValid's rmse: 0.0250262\n[500]\tTrain's rmse: 0.021191\tValid's rmse: 0.0250199\n[600]\tTrain's rmse: 0.0211388\tValid's rmse: 0.0250113\n[700]\tTrain's rmse: 0.0210901\tValid's rmse: 0.0250062\n[800]\tTrain's rmse: 0.0210437\tValid's rmse: 0.0250015\n[900]\tTrain's rmse: 0.0209987\tValid's rmse: 0.0249969\n[1000]\tTrain's rmse: 0.020955\tValid's rmse: 0.0249959\n[1100]\tTrain's rmse: 0.0209136\tValid's rmse: 0.0249955\n[1200]\tTrain's rmse: 0.0208731\tValid's rmse: 0.0249944\n[1300]\tTrain's rmse: 0.0208339\tValid's rmse: 0.0249917\nEarly stopping, best iteration is:\n[1272]\tTrain's rmse: 0.0208444\tValid's rmse: 0.0249908\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  10%|#         | 1/10 [00:54<08:10, 54.54s/it]\u001b[32m[I 2022-04-22 00:42:51,347]\u001b[0m Trial 27 finished with value: 0.024990827158618292 and parameters: {'bagging_fraction': 0.6394522736306505, 'bagging_freq': 7}. Best is trial 27 with value: 0.024990827158618292.\u001b[0m\nbagging, val_score: 0.024975:  10%|#         | 1/10 [00:54<08:10, 54.54s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219483 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214522\tValid's rmse: 0.0250867\n[200]\tTrain's rmse: 0.0213713\tValid's rmse: 0.0250556\n[300]\tTrain's rmse: 0.0213042\tValid's rmse: 0.025038\n[400]\tTrain's rmse: 0.0212453\tValid's rmse: 0.025024\n[500]\tTrain's rmse: 0.0211908\tValid's rmse: 0.0250145\n[600]\tTrain's rmse: 0.0211386\tValid's rmse: 0.0250105\n[700]\tTrain's rmse: 0.0210892\tValid's rmse: 0.025006\n[800]\tTrain's rmse: 0.021043\tValid's rmse: 0.0250042\n[900]\tTrain's rmse: 0.0209985\tValid's rmse: 0.0250013\n[1000]\tTrain's rmse: 0.0209544\tValid's rmse: 0.0250023\nEarly stopping, best iteration is:\n[959]\tTrain's rmse: 0.0209725\tValid's rmse: 0.0249994\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  20%|##        | 2/10 [01:40<06:34, 49.31s/it]\u001b[32m[I 2022-04-22 00:43:36,995]\u001b[0m Trial 28 finished with value: 0.02499935661727621 and parameters: {'bagging_fraction': 0.6390785590070994, 'bagging_freq': 3}. Best is trial 27 with value: 0.024990827158618292.\u001b[0m\nbagging, val_score: 0.024975:  20%|##        | 2/10 [01:40<06:34, 49.31s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064642 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214523\tValid's rmse: 0.0250834\n[200]\tTrain's rmse: 0.0213717\tValid's rmse: 0.0250521\n[300]\tTrain's rmse: 0.0213045\tValid's rmse: 0.0250378\n[400]\tTrain's rmse: 0.0212459\tValid's rmse: 0.0250237\n[500]\tTrain's rmse: 0.0211909\tValid's rmse: 0.0250109\n[600]\tTrain's rmse: 0.0211391\tValid's rmse: 0.0250065\n[700]\tTrain's rmse: 0.0210894\tValid's rmse: 0.0250003\n[800]\tTrain's rmse: 0.0210433\tValid's rmse: 0.0249962\n[900]\tTrain's rmse: 0.0209991\tValid's rmse: 0.0249932\n[1000]\tTrain's rmse: 0.0209559\tValid's rmse: 0.0249915\n[1100]\tTrain's rmse: 0.0209147\tValid's rmse: 0.0249886\nEarly stopping, best iteration is:\n[1056]\tTrain's rmse: 0.0209325\tValid's rmse: 0.0249882\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  30%|###       | 3/10 [02:28<05:41, 48.82s/it]\u001b[32m[I 2022-04-22 00:44:25,244]\u001b[0m Trial 29 finished with value: 0.024988236456137104 and parameters: {'bagging_fraction': 0.6384628851057791, 'bagging_freq': 4}. Best is trial 29 with value: 0.024988236456137104.\u001b[0m\nbagging, val_score: 0.024975:  30%|###       | 3/10 [02:28<05:41, 48.82s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075163 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214542\tValid's rmse: 0.0250847\n[200]\tTrain's rmse: 0.0213749\tValid's rmse: 0.0250593\n[300]\tTrain's rmse: 0.0213096\tValid's rmse: 0.0250414\n[400]\tTrain's rmse: 0.0212501\tValid's rmse: 0.0250278\n[500]\tTrain's rmse: 0.0211954\tValid's rmse: 0.0250229\n[600]\tTrain's rmse: 0.0211444\tValid's rmse: 0.0250127\n[700]\tTrain's rmse: 0.0210959\tValid's rmse: 0.0250114\n[800]\tTrain's rmse: 0.0210502\tValid's rmse: 0.0250079\n[900]\tTrain's rmse: 0.0210064\tValid's rmse: 0.0250064\n[1000]\tTrain's rmse: 0.0209631\tValid's rmse: 0.0250029\n[1100]\tTrain's rmse: 0.0209217\tValid's rmse: 0.0250021\n[1200]\tTrain's rmse: 0.0208821\tValid's rmse: 0.0249984\n[1300]\tTrain's rmse: 0.0208435\tValid's rmse: 0.024993\n[1400]\tTrain's rmse: 0.0208053\tValid's rmse: 0.024992\nEarly stopping, best iteration is:\n[1372]\tTrain's rmse: 0.0208157\tValid's rmse: 0.0249895\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  40%|####      | 4/10 [03:25<05:13, 52.22s/it]\u001b[32m[I 2022-04-22 00:45:22,664]\u001b[0m Trial 30 finished with value: 0.02498950838694769 and parameters: {'bagging_fraction': 0.573391420678481, 'bagging_freq': 7}. Best is trial 29 with value: 0.024988236456137104.\u001b[0m\nbagging, val_score: 0.024975:  40%|####      | 4/10 [03:25<05:13, 52.22s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059511 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214593\tValid's rmse: 0.0250885\n[200]\tTrain's rmse: 0.0213854\tValid's rmse: 0.0250588\n[300]\tTrain's rmse: 0.0213237\tValid's rmse: 0.025047\n[400]\tTrain's rmse: 0.0212679\tValid's rmse: 0.025031\n[500]\tTrain's rmse: 0.0212174\tValid's rmse: 0.0250197\n[600]\tTrain's rmse: 0.0211688\tValid's rmse: 0.0250087\n[700]\tTrain's rmse: 0.0211235\tValid's rmse: 0.0250068\n[800]\tTrain's rmse: 0.0210807\tValid's rmse: 0.0250035\n[900]\tTrain's rmse: 0.0210388\tValid's rmse: 0.0249999\n[1000]\tTrain's rmse: 0.0209987\tValid's rmse: 0.0249959\n[1100]\tTrain's rmse: 0.0209599\tValid's rmse: 0.0249946\n[1200]\tTrain's rmse: 0.0209229\tValid's rmse: 0.0249953\nEarly stopping, best iteration is:\n[1129]\tTrain's rmse: 0.0209492\tValid's rmse: 0.0249933\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  50%|#####     | 5/10 [04:13<04:13, 50.61s/it]\u001b[32m[I 2022-04-22 00:46:10,423]\u001b[0m Trial 31 finished with value: 0.024993298784607584 and parameters: {'bagging_fraction': 0.4122942134315543, 'bagging_freq': 5}. Best is trial 29 with value: 0.024988236456137104.\u001b[0m\nbagging, val_score: 0.024975:  50%|#####     | 5/10 [04:13<04:13, 50.61s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059101 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021448\tValid's rmse: 0.0250899\n[200]\tTrain's rmse: 0.0213641\tValid's rmse: 0.02506\n[300]\tTrain's rmse: 0.0212948\tValid's rmse: 0.0250407\n[400]\tTrain's rmse: 0.0212327\tValid's rmse: 0.0250262\n[500]\tTrain's rmse: 0.0211761\tValid's rmse: 0.0250149\n[600]\tTrain's rmse: 0.0211215\tValid's rmse: 0.0250076\n[700]\tTrain's rmse: 0.0210708\tValid's rmse: 0.0250036\n[800]\tTrain's rmse: 0.0210228\tValid's rmse: 0.0249981\n[900]\tTrain's rmse: 0.0209775\tValid's rmse: 0.0249948\n[1000]\tTrain's rmse: 0.0209332\tValid's rmse: 0.0249925\n[1100]\tTrain's rmse: 0.0208915\tValid's rmse: 0.0249906\n[1200]\tTrain's rmse: 0.0208516\tValid's rmse: 0.0249898\n[1300]\tTrain's rmse: 0.0208122\tValid's rmse: 0.0249901\nEarly stopping, best iteration is:\n[1215]\tTrain's rmse: 0.0208456\tValid's rmse: 0.0249893\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  60%|######    | 6/10 [04:58<03:14, 48.66s/it]\u001b[32m[I 2022-04-22 00:46:55,304]\u001b[0m Trial 32 finished with value: 0.02498927800950081 and parameters: {'bagging_fraction': 0.864767680361689, 'bagging_freq': 1}. Best is trial 29 with value: 0.024988236456137104.\u001b[0m\nbagging, val_score: 0.024975:  60%|######    | 6/10 [04:58<03:14, 48.66s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058273 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214518\tValid's rmse: 0.0250871\n[200]\tTrain's rmse: 0.0213701\tValid's rmse: 0.0250569\n[300]\tTrain's rmse: 0.0213027\tValid's rmse: 0.0250419\n[400]\tTrain's rmse: 0.0212411\tValid's rmse: 0.0250267\n[500]\tTrain's rmse: 0.0211859\tValid's rmse: 0.0250164\n[600]\tTrain's rmse: 0.0211326\tValid's rmse: 0.0250089\n[700]\tTrain's rmse: 0.0210823\tValid's rmse: 0.0250058\n[800]\tTrain's rmse: 0.0210345\tValid's rmse: 0.025001\n[900]\tTrain's rmse: 0.020989\tValid's rmse: 0.0249988\n[1000]\tTrain's rmse: 0.0209445\tValid's rmse: 0.0249951\n[1100]\tTrain's rmse: 0.0209024\tValid's rmse: 0.0249924\nEarly stopping, best iteration is:\n[1060]\tTrain's rmse: 0.0209191\tValid's rmse: 0.0249919\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  70%|#######   | 7/10 [05:47<02:26, 48.79s/it]\u001b[32m[I 2022-04-22 00:47:44,362]\u001b[0m Trial 33 finished with value: 0.024991850400569702 and parameters: {'bagging_fraction': 0.7080397056865178, 'bagging_freq': 4}. Best is trial 29 with value: 0.024988236456137104.\u001b[0m\nbagging, val_score: 0.024975:  70%|#######   | 7/10 [05:47<02:26, 48.79s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058987 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214489\tValid's rmse: 0.0250868\n[200]\tTrain's rmse: 0.0213637\tValid's rmse: 0.0250591\n[300]\tTrain's rmse: 0.0212945\tValid's rmse: 0.0250402\n[400]\tTrain's rmse: 0.0212323\tValid's rmse: 0.0250243\n[500]\tTrain's rmse: 0.0211748\tValid's rmse: 0.0250173\n[600]\tTrain's rmse: 0.0211209\tValid's rmse: 0.0250126\n[700]\tTrain's rmse: 0.0210704\tValid's rmse: 0.0250077\n[800]\tTrain's rmse: 0.0210224\tValid's rmse: 0.0250022\n[900]\tTrain's rmse: 0.020978\tValid's rmse: 0.0250011\n[1000]\tTrain's rmse: 0.0209342\tValid's rmse: 0.0250001\n[1100]\tTrain's rmse: 0.0208916\tValid's rmse: 0.0249987\nEarly stopping, best iteration is:\n[1052]\tTrain's rmse: 0.0209119\tValid's rmse: 0.0249982\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  80%|########  | 8/10 [06:36<01:37, 48.97s/it]\u001b[32m[I 2022-04-22 00:48:33,703]\u001b[0m Trial 34 finished with value: 0.024998227888126355 and parameters: {'bagging_fraction': 0.8629307309236631, 'bagging_freq': 4}. Best is trial 29 with value: 0.024988236456137104.\u001b[0m\nbagging, val_score: 0.024975:  80%|########  | 8/10 [06:36<01:37, 48.97s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062691 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214546\tValid's rmse: 0.0250826\n[200]\tTrain's rmse: 0.0213766\tValid's rmse: 0.025058\n[300]\tTrain's rmse: 0.0213117\tValid's rmse: 0.0250407\n[400]\tTrain's rmse: 0.0212531\tValid's rmse: 0.0250257\n[500]\tTrain's rmse: 0.0211996\tValid's rmse: 0.0250174\n[600]\tTrain's rmse: 0.0211491\tValid's rmse: 0.0250101\n[700]\tTrain's rmse: 0.0211014\tValid's rmse: 0.0250078\n[800]\tTrain's rmse: 0.0210562\tValid's rmse: 0.0250053\n[900]\tTrain's rmse: 0.0210127\tValid's rmse: 0.0250002\n[1000]\tTrain's rmse: 0.0209707\tValid's rmse: 0.0249963\n[1100]\tTrain's rmse: 0.0209296\tValid's rmse: 0.0249982\nEarly stopping, best iteration is:\n[1009]\tTrain's rmse: 0.020967\tValid's rmse: 0.0249954\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  90%|######### | 9/10 [07:20<00:47, 47.36s/it]\u001b[32m[I 2022-04-22 00:49:17,537]\u001b[0m Trial 35 finished with value: 0.02499538494541072 and parameters: {'bagging_fraction': 0.5458154574342053, 'bagging_freq': 7}. Best is trial 29 with value: 0.024988236456137104.\u001b[0m\nbagging, val_score: 0.024975:  90%|######### | 9/10 [07:20<00:47, 47.36s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059208 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214537\tValid's rmse: 0.0250879\n[200]\tTrain's rmse: 0.0213741\tValid's rmse: 0.025055\n[300]\tTrain's rmse: 0.0213084\tValid's rmse: 0.0250383\n[400]\tTrain's rmse: 0.0212496\tValid's rmse: 0.0250225\n[500]\tTrain's rmse: 0.0211965\tValid's rmse: 0.0250142\n[600]\tTrain's rmse: 0.0211459\tValid's rmse: 0.0250103\n[700]\tTrain's rmse: 0.021098\tValid's rmse: 0.0249998\n[800]\tTrain's rmse: 0.0210531\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.0210092\tValid's rmse: 0.0249934\n[1000]\tTrain's rmse: 0.0209665\tValid's rmse: 0.0249912\n[1100]\tTrain's rmse: 0.020926\tValid's rmse: 0.0249878\n[1200]\tTrain's rmse: 0.0208867\tValid's rmse: 0.0249894\nEarly stopping, best iteration is:\n[1102]\tTrain's rmse: 0.0209253\tValid's rmse: 0.0249877\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975: 100%|##########| 10/10 [08:09<00:00, 47.67s/it]\u001b[32m[I 2022-04-22 00:50:05,890]\u001b[0m Trial 36 finished with value: 0.024987688883853554 and parameters: {'bagging_fraction': 0.5502882976582053, 'bagging_freq': 4}. Best is trial 36 with value: 0.024987688883853554.\u001b[0m\nbagging, val_score: 0.024975: 100%|##########| 10/10 [08:09<00:00, 48.91s/it]\nfeature_fraction_stage2, val_score: 0.024975:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059775 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0250849\n[200]\tTrain's rmse: 0.0213795\tValid's rmse: 0.025054\n[300]\tTrain's rmse: 0.0213157\tValid's rmse: 0.0250386\n[400]\tTrain's rmse: 0.0212585\tValid's rmse: 0.0250218\n[500]\tTrain's rmse: 0.0212067\tValid's rmse: 0.02501\n[600]\tTrain's rmse: 0.0211576\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0211106\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210652\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.021023\tValid's rmse: 0.0249872\n[1000]\tTrain's rmse: 0.0209806\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.0209403\tValid's rmse: 0.024978\n[1200]\tTrain's rmse: 0.0209012\tValid's rmse: 0.0249765\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209224\tValid's rmse: 0.0249745\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024975:  33%|###3      | 1/3 [00:48<01:36, 48.11s/it]\u001b[32m[I 2022-04-22 00:50:54,013]\u001b[0m Trial 37 finished with value: 0.0249745372385883 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.0249745372385883.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024975:  33%|###3      | 1/3 [00:48<01:36, 48.11s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214505\tValid's rmse: 0.0250777\n[200]\tTrain's rmse: 0.0213705\tValid's rmse: 0.025046\n[300]\tTrain's rmse: 0.0213037\tValid's rmse: 0.0250328\n[400]\tTrain's rmse: 0.0212447\tValid's rmse: 0.025017\n[500]\tTrain's rmse: 0.0211903\tValid's rmse: 0.0250073\n[600]\tTrain's rmse: 0.0211391\tValid's rmse: 0.0249966\n[700]\tTrain's rmse: 0.0210891\tValid's rmse: 0.0249935\n[800]\tTrain's rmse: 0.0210423\tValid's rmse: 0.0249901\n[900]\tTrain's rmse: 0.020998\tValid's rmse: 0.024988\n[1000]\tTrain's rmse: 0.0209539\tValid's rmse: 0.0249832\n[1100]\tTrain's rmse: 0.020912\tValid's rmse: 0.0249827\n[1200]\tTrain's rmse: 0.0208716\tValid's rmse: 0.0249823\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0208935\tValid's rmse: 0.0249797\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024975:  67%|######6   | 2/3 [01:40<00:50, 50.35s/it]\u001b[32m[I 2022-04-22 00:51:45,930]\u001b[0m Trial 38 finished with value: 0.02497970959928113 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.0249745372385883.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024975:  67%|######6   | 2/3 [01:40<00:50, 50.35s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060914 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214529\tValid's rmse: 0.0250809\n[200]\tTrain's rmse: 0.0213741\tValid's rmse: 0.0250543\n[300]\tTrain's rmse: 0.0213089\tValid's rmse: 0.0250411\n[400]\tTrain's rmse: 0.0212504\tValid's rmse: 0.0250266\n[500]\tTrain's rmse: 0.021198\tValid's rmse: 0.0250127\n[600]\tTrain's rmse: 0.0211481\tValid's rmse: 0.0250052\n[700]\tTrain's rmse: 0.0210999\tValid's rmse: 0.0250033\n[800]\tTrain's rmse: 0.0210546\tValid's rmse: 0.0249976\n[900]\tTrain's rmse: 0.0210114\tValid's rmse: 0.0249915\n[1000]\tTrain's rmse: 0.0209681\tValid's rmse: 0.0249833\n[1100]\tTrain's rmse: 0.0209265\tValid's rmse: 0.0249835\nEarly stopping, best iteration is:\n[1014]\tTrain's rmse: 0.0209621\tValid's rmse: 0.0249821\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024975: 100%|##########| 3/3 [02:25<00:00, 47.99s/it]\u001b[32m[I 2022-04-22 00:52:31,108]\u001b[0m Trial 39 finished with value: 0.024982103279174456 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.0249745372385883.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024975: 100%|##########| 3/3 [02:25<00:00, 48.40s/it]\nregularization_factors, val_score: 0.024975:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070453 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214203\tValid's rmse: 0.0250924\n[200]\tTrain's rmse: 0.0213118\tValid's rmse: 0.0250676\n[300]\tTrain's rmse: 0.0212203\tValid's rmse: 0.025056\n[400]\tTrain's rmse: 0.021137\tValid's rmse: 0.0250367\n[500]\tTrain's rmse: 0.0210601\tValid's rmse: 0.0250276\n[600]\tTrain's rmse: 0.0209879\tValid's rmse: 0.0250172\n[700]\tTrain's rmse: 0.0209197\tValid's rmse: 0.0250114\n[800]\tTrain's rmse: 0.0208547\tValid's rmse: 0.0250102\nEarly stopping, best iteration is:\n[780]\tTrain's rmse: 0.0208671\tValid's rmse: 0.0250095\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:   5%|5         | 1/20 [00:27<08:33, 27.02s/it]\u001b[32m[I 2022-04-22 00:52:58,141]\u001b[0m Trial 40 finished with value: 0.025009494819983137 and parameters: {'lambda_l1': 0.011799193990740675, 'lambda_l2': 1.5823019553804794e-08}. Best is trial 40 with value: 0.025009494819983137.\u001b[0m\nregularization_factors, val_score: 0.024975:   5%|5         | 1/20 [00:27<08:33, 27.02s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059310 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214196\tValid's rmse: 0.0250928\n[200]\tTrain's rmse: 0.021311\tValid's rmse: 0.0250693\n[300]\tTrain's rmse: 0.0212193\tValid's rmse: 0.0250558\n[400]\tTrain's rmse: 0.0211351\tValid's rmse: 0.0250387\n[500]\tTrain's rmse: 0.0210579\tValid's rmse: 0.0250324\n[600]\tTrain's rmse: 0.0209855\tValid's rmse: 0.0250196\n[700]\tTrain's rmse: 0.0209172\tValid's rmse: 0.0250157\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  10%|#         | 2/20 [00:51<07:36, 25.37s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[671]\tTrain's rmse: 0.0209367\tValid's rmse: 0.0250145\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-04-22 00:53:22,352]\u001b[0m Trial 41 finished with value: 0.025014508521017647 and parameters: {'lambda_l1': 4.709322099387306e-05, 'lambda_l2': 0.04439174216146772}. Best is trial 40 with value: 0.025009494819983137.\u001b[0m\nregularization_factors, val_score: 0.024975:  10%|#         | 2/20 [00:51<07:36, 25.37s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060320 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214519\tValid's rmse: 0.0250847\n[200]\tTrain's rmse: 0.0213708\tValid's rmse: 0.0250538\n[300]\tTrain's rmse: 0.0213034\tValid's rmse: 0.0250403\n[400]\tTrain's rmse: 0.0212422\tValid's rmse: 0.025026\n[500]\tTrain's rmse: 0.0211863\tValid's rmse: 0.025014\n[600]\tTrain's rmse: 0.0211336\tValid's rmse: 0.0250065\n[700]\tTrain's rmse: 0.0210832\tValid's rmse: 0.0250025\n[800]\tTrain's rmse: 0.0210349\tValid's rmse: 0.0249968\n[900]\tTrain's rmse: 0.0209903\tValid's rmse: 0.0249893\n[1000]\tTrain's rmse: 0.0209458\tValid's rmse: 0.0249849\n[1100]\tTrain's rmse: 0.0209025\tValid's rmse: 0.0249839\n[1200]\tTrain's rmse: 0.0208612\tValid's rmse: 0.0249818\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0208838\tValid's rmse: 0.0249808\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  15%|#5        | 3/20 [01:38<10:04, 35.55s/it]\u001b[32m[I 2022-04-22 00:54:10,025]\u001b[0m Trial 42 finished with value: 0.02498075956182247 and parameters: {'lambda_l1': 0.4180973270356108, 'lambda_l2': 0.1334383257116156}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  15%|#5        | 3/20 [01:38<10:04, 35.55s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008855 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tTrain's rmse: 0.0215275\tValid's rmse: 0.0251217\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[200]\tTrain's rmse: 0.0215058\tValid's rmse: 0.0251125\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[300]\tTrain's rmse: 0.0214921\tValid's rmse: 0.025108\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[400]\tTrain's rmse: 0.0214813\tValid's rmse: 0.0251023\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[500]\tTrain's rmse: 0.0214732\tValid's rmse: 0.0250965\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[600]\tTrain's rmse: 0.0214665\tValid's rmse: 0.0250937\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[700]\tTrain's rmse: 0.0214608\tValid's rmse: 0.0250904\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[800]\tTrain's rmse: 0.0214555\tValid's rmse: 0.0250882\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[900]\tTrain's rmse: 0.0214512\tValid's rmse: 0.025084\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1000]\tTrain's rmse: 0.0214471\tValid's rmse: 0.0250785\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1100]\tTrain's rmse: 0.0214435\tValid's rmse: 0.0250785\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1200]\tTrain's rmse: 0.0214406\tValid's rmse: 0.0250768\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[1163]\tTrain's rmse: 0.0214416\tValid's rmse: 0.0250761\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  20%|##        | 4/20 [02:31<11:18, 42.42s/it]\u001b[32m[I 2022-04-22 00:55:02,976]\u001b[0m Trial 43 finished with value: 0.025076071641423687 and parameters: {'lambda_l1': 8.457983263062081, 'lambda_l2': 4.1857083291920686e-05}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  20%|##        | 4/20 [02:31<11:18, 42.42s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214192\tValid's rmse: 0.0250914\n[200]\tTrain's rmse: 0.0213098\tValid's rmse: 0.0250665\n[300]\tTrain's rmse: 0.0212185\tValid's rmse: 0.0250549\n[400]\tTrain's rmse: 0.0211344\tValid's rmse: 0.0250377\n[500]\tTrain's rmse: 0.0210573\tValid's rmse: 0.0250298\n[600]\tTrain's rmse: 0.0209847\tValid's rmse: 0.0250225\n[700]\tTrain's rmse: 0.0209166\tValid's rmse: 0.0250182\n[800]\tTrain's rmse: 0.0208513\tValid's rmse: 0.0250168\n[900]\tTrain's rmse: 0.0207894\tValid's rmse: 0.0250161\nEarly stopping, best iteration is:\n[815]\tTrain's rmse: 0.0208414\tValid's rmse: 0.0250153\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  25%|##5       | 5/20 [02:59<09:14, 36.98s/it]\u001b[32m[I 2022-04-22 00:55:30,317]\u001b[0m Trial 44 finished with value: 0.025015313814044312 and parameters: {'lambda_l1': 0.0023519862555791845, 'lambda_l2': 1.1074567587460985e-08}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  25%|##5       | 5/20 [02:59<09:14, 36.98s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059240 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214192\tValid's rmse: 0.0250931\n[200]\tTrain's rmse: 0.0213096\tValid's rmse: 0.0250679\n[300]\tTrain's rmse: 0.0212179\tValid's rmse: 0.0250533\n[400]\tTrain's rmse: 0.0211342\tValid's rmse: 0.0250366\n[500]\tTrain's rmse: 0.0210567\tValid's rmse: 0.0250305\n[600]\tTrain's rmse: 0.0209845\tValid's rmse: 0.025023\n[700]\tTrain's rmse: 0.0209164\tValid's rmse: 0.0250208\n[800]\tTrain's rmse: 0.0208509\tValid's rmse: 0.0250219\nEarly stopping, best iteration is:\n[712]\tTrain's rmse: 0.0209084\tValid's rmse: 0.0250199\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  30%|###       | 6/20 [03:24<07:40, 32.89s/it]\u001b[32m[I 2022-04-22 00:55:55,265]\u001b[0m Trial 45 finished with value: 0.025019914193595394 and parameters: {'lambda_l1': 1.0114378025459996e-06, 'lambda_l2': 3.199212409839454e-07}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  30%|###       | 6/20 [03:24<07:40, 32.89s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059620 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214195\tValid's rmse: 0.0250935\n[200]\tTrain's rmse: 0.0213108\tValid's rmse: 0.02507\n[300]\tTrain's rmse: 0.0212192\tValid's rmse: 0.0250583\n[400]\tTrain's rmse: 0.021135\tValid's rmse: 0.0250404\n[500]\tTrain's rmse: 0.0210581\tValid's rmse: 0.0250317\n[600]\tTrain's rmse: 0.0209863\tValid's rmse: 0.0250224\n[700]\tTrain's rmse: 0.0209177\tValid's rmse: 0.0250208\n[800]\tTrain's rmse: 0.0208532\tValid's rmse: 0.0250215\nEarly stopping, best iteration is:\n[717]\tTrain's rmse: 0.0209065\tValid's rmse: 0.0250199\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  35%|###5      | 7/20 [03:49<06:35, 30.39s/it]\u001b[32m[I 2022-04-22 00:56:20,497]\u001b[0m Trial 46 finished with value: 0.025019856318961364 and parameters: {'lambda_l1': 0.0014638168090582884, 'lambda_l2': 0.00010241323993573478}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  35%|###5      | 7/20 [03:49<06:35, 30.39s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059511 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215095\tValid's rmse: 0.025112\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[200]\tTrain's rmse: 0.0214763\tValid's rmse: 0.0250968\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[300]\tTrain's rmse: 0.0214525\tValid's rmse: 0.0250896\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[400]\tTrain's rmse: 0.0214326\tValid's rmse: 0.0250818\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[500]\tTrain's rmse: 0.0214158\tValid's rmse: 0.0250739\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[600]\tTrain's rmse: 0.0214009\tValid's rmse: 0.0250689\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[700]\tTrain's rmse: 0.021387\tValid's rmse: 0.025062\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[800]\tTrain's rmse: 0.0213739\tValid's rmse: 0.0250564\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[900]\tTrain's rmse: 0.0213621\tValid's rmse: 0.0250499\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1000]\tTrain's rmse: 0.0213507\tValid's rmse: 0.0250425\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1100]\tTrain's rmse: 0.0213398\tValid's rmse: 0.0250391\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1200]\tTrain's rmse: 0.0213301\tValid's rmse: 0.0250366\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1300]\tTrain's rmse: 0.0213201\tValid's rmse: 0.0250353\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1400]\tTrain's rmse: 0.0213105\tValid's rmse: 0.0250313\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1500]\tTrain's rmse: 0.0213016\tValid's rmse: 0.0250291\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1600]\tTrain's rmse: 0.0212929\tValid's rmse: 0.0250262\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1700]\tTrain's rmse: 0.0212844\tValid's rmse: 0.0250249\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1800]\tTrain's rmse: 0.0212759\tValid's rmse: 0.0250205\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1900]\tTrain's rmse: 0.021268\tValid's rmse: 0.0250205\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[2000]\tTrain's rmse: 0.0212605\tValid's rmse: 0.0250189\nDid not meet early stopping. Best iteration is:\n[2000]\tTrain's rmse: 0.0212605\tValid's rmse: 0.0250189\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  40%|####      | 8/20 [05:23<10:08, 50.72s/it]\u001b[32m[I 2022-04-22 00:57:54,762]\u001b[0m Trial 47 finished with value: 0.025018943457848157 and parameters: {'lambda_l1': 3.8542453539241137, 'lambda_l2': 1.384742776692214e-07}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  40%|####      | 8/20 [05:23<10:08, 50.72s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214194\tValid's rmse: 0.0250925\n[200]\tTrain's rmse: 0.0213102\tValid's rmse: 0.0250677\n[300]\tTrain's rmse: 0.021219\tValid's rmse: 0.025056\n[400]\tTrain's rmse: 0.0211354\tValid's rmse: 0.0250386\n[500]\tTrain's rmse: 0.0210581\tValid's rmse: 0.0250315\n[600]\tTrain's rmse: 0.0209857\tValid's rmse: 0.0250216\n[700]\tTrain's rmse: 0.0209177\tValid's rmse: 0.0250207\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  45%|####5     | 9/20 [05:47<07:46, 42.42s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[662]\tTrain's rmse: 0.0209433\tValid's rmse: 0.0250187\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-04-22 00:58:18,931]\u001b[0m Trial 48 finished with value: 0.025018692400788706 and parameters: {'lambda_l1': 4.476021550512451e-06, 'lambda_l2': 0.10682008246787082}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  45%|####5     | 9/20 [05:47<07:46, 42.42s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063699 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.02149\tValid's rmse: 0.0251011\n[200]\tTrain's rmse: 0.0214408\tValid's rmse: 0.0250769\n[300]\tTrain's rmse: 0.0214026\tValid's rmse: 0.0250675\n[400]\tTrain's rmse: 0.0213698\tValid's rmse: 0.0250546\n[500]\tTrain's rmse: 0.0213405\tValid's rmse: 0.0250444\n[600]\tTrain's rmse: 0.0213131\tValid's rmse: 0.0250359\n[700]\tTrain's rmse: 0.021287\tValid's rmse: 0.0250265\n[800]\tTrain's rmse: 0.0212624\tValid's rmse: 0.025019\n[900]\tTrain's rmse: 0.0212396\tValid's rmse: 0.0250128\n[1000]\tTrain's rmse: 0.0212169\tValid's rmse: 0.0250043\n[1100]\tTrain's rmse: 0.0211953\tValid's rmse: 0.025004\n[1200]\tTrain's rmse: 0.0211744\tValid's rmse: 0.0250016\nEarly stopping, best iteration is:\n[1184]\tTrain's rmse: 0.0211778\tValid's rmse: 0.0250009\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  50%|#####     | 10/20 [06:46<07:55, 47.57s/it]\u001b[32m[I 2022-04-22 00:59:18,038]\u001b[0m Trial 49 finished with value: 0.02500093960143494 and parameters: {'lambda_l1': 1.7227467845448747, 'lambda_l2': 3.333687724024096e-08}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  50%|#####     | 10/20 [06:46<07:55, 47.57s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060131 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214365\tValid's rmse: 0.0250873\n[200]\tTrain's rmse: 0.0213415\tValid's rmse: 0.0250559\n[300]\tTrain's rmse: 0.0212604\tValid's rmse: 0.0250428\n[400]\tTrain's rmse: 0.0211872\tValid's rmse: 0.0250281\n[500]\tTrain's rmse: 0.0211207\tValid's rmse: 0.0250197\n[600]\tTrain's rmse: 0.0210561\tValid's rmse: 0.0250156\n[700]\tTrain's rmse: 0.020996\tValid's rmse: 0.0250135\n[800]\tTrain's rmse: 0.0209384\tValid's rmse: 0.0250113\n[900]\tTrain's rmse: 0.0208826\tValid's rmse: 0.0250069\n[1000]\tTrain's rmse: 0.0208292\tValid's rmse: 0.0250039\n[1100]\tTrain's rmse: 0.020778\tValid's rmse: 0.0250032\n[1200]\tTrain's rmse: 0.0207288\tValid's rmse: 0.0250013\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0207558\tValid's rmse: 0.025001\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  55%|#####5    | 11/20 [07:24<06:41, 44.65s/it]\u001b[32m[I 2022-04-22 00:59:56,053]\u001b[0m Trial 50 finished with value: 0.02500104223705662 and parameters: {'lambda_l1': 1.6347844717468715e-08, 'lambda_l2': 8.799973881260957}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  55%|#####5    | 11/20 [07:24<06:41, 44.65s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214323\tValid's rmse: 0.0250868\n[200]\tTrain's rmse: 0.0213331\tValid's rmse: 0.025057\n[300]\tTrain's rmse: 0.02125\tValid's rmse: 0.0250447\n[400]\tTrain's rmse: 0.0211746\tValid's rmse: 0.0250306\n[500]\tTrain's rmse: 0.0211054\tValid's rmse: 0.0250223\n[600]\tTrain's rmse: 0.0210392\tValid's rmse: 0.0250157\n[700]\tTrain's rmse: 0.0209772\tValid's rmse: 0.0250136\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.0210056\tValid's rmse: 0.0250129\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  60%|######    | 12/20 [07:53<05:18, 39.76s/it]\u001b[32m[I 2022-04-22 01:00:24,647]\u001b[0m Trial 51 finished with value: 0.025012929986753273 and parameters: {'lambda_l1': 0.15803819912094652, 'lambda_l2': 0.009808938597593233}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  60%|######    | 12/20 [07:53<05:18, 39.76s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059954 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214353\tValid's rmse: 0.0250861\n[200]\tTrain's rmse: 0.0213388\tValid's rmse: 0.0250572\n[300]\tTrain's rmse: 0.0212568\tValid's rmse: 0.0250435\n[400]\tTrain's rmse: 0.0211829\tValid's rmse: 0.0250308\n[500]\tTrain's rmse: 0.0211155\tValid's rmse: 0.025023\n[600]\tTrain's rmse: 0.0210502\tValid's rmse: 0.0250186\n[700]\tTrain's rmse: 0.0209893\tValid's rmse: 0.025014\n[800]\tTrain's rmse: 0.0209308\tValid's rmse: 0.0250118\n[900]\tTrain's rmse: 0.0208754\tValid's rmse: 0.0250059\n[1000]\tTrain's rmse: 0.0208206\tValid's rmse: 0.025002\nEarly stopping, best iteration is:\n[980]\tTrain's rmse: 0.0208316\tValid's rmse: 0.0250006\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  65%|######5   | 13/20 [08:29<04:30, 38.62s/it]\u001b[32m[I 2022-04-22 01:01:00,642]\u001b[0m Trial 52 finished with value: 0.02500061190171917 and parameters: {'lambda_l1': 0.08873551950670533, 'lambda_l2': 4.216387262047669}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  65%|######5   | 13/20 [08:29<04:30, 38.62s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064511 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214373\tValid's rmse: 0.0250854\n[200]\tTrain's rmse: 0.0213424\tValid's rmse: 0.0250566\n[300]\tTrain's rmse: 0.0212626\tValid's rmse: 0.0250419\n[400]\tTrain's rmse: 0.0211897\tValid's rmse: 0.025029\n[500]\tTrain's rmse: 0.0211233\tValid's rmse: 0.0250228\n[600]\tTrain's rmse: 0.021059\tValid's rmse: 0.0250196\n[700]\tTrain's rmse: 0.0209987\tValid's rmse: 0.0250158\n[800]\tTrain's rmse: 0.0209409\tValid's rmse: 0.0250142\n[900]\tTrain's rmse: 0.0208854\tValid's rmse: 0.0250096\n[1000]\tTrain's rmse: 0.0208308\tValid's rmse: 0.0250048\n[1100]\tTrain's rmse: 0.0207794\tValid's rmse: 0.0250047\nEarly stopping, best iteration is:\n[1061]\tTrain's rmse: 0.0207993\tValid's rmse: 0.0250032\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  70%|#######   | 14/20 [09:08<03:51, 38.60s/it]\u001b[32m[I 2022-04-22 01:01:39,195]\u001b[0m Trial 53 finished with value: 0.02500316046258011 and parameters: {'lambda_l1': 0.07271999528493711, 'lambda_l2': 6.18211905597004}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  70%|#######   | 14/20 [09:08<03:51, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077405 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214346\tValid's rmse: 0.0250865\n[200]\tTrain's rmse: 0.0213371\tValid's rmse: 0.0250576\n[300]\tTrain's rmse: 0.0212558\tValid's rmse: 0.0250425\n[400]\tTrain's rmse: 0.0211816\tValid's rmse: 0.0250308\n[500]\tTrain's rmse: 0.0211134\tValid's rmse: 0.025023\n[600]\tTrain's rmse: 0.0210484\tValid's rmse: 0.0250172\n[700]\tTrain's rmse: 0.0209869\tValid's rmse: 0.0250136\n[800]\tTrain's rmse: 0.0209286\tValid's rmse: 0.0250098\n[900]\tTrain's rmse: 0.0208737\tValid's rmse: 0.0250048\n[1000]\tTrain's rmse: 0.0208192\tValid's rmse: 0.0250021\n[1100]\tTrain's rmse: 0.0207667\tValid's rmse: 0.0250013\n[1200]\tTrain's rmse: 0.020716\tValid's rmse: 0.0250012\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0207439\tValid's rmse: 0.0249992\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  75%|#######5  | 15/20 [09:50<03:18, 39.66s/it]\u001b[32m[I 2022-04-22 01:02:21,310]\u001b[0m Trial 54 finished with value: 0.024999180114275075 and parameters: {'lambda_l1': 0.17132546455981176, 'lambda_l2': 0.49838122171123356}. Best is trial 42 with value: 0.02498075956182247.\u001b[0m\nregularization_factors, val_score: 0.024975:  75%|#######5  | 15/20 [09:50<03:18, 39.66s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061567 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214527\tValid's rmse: 0.0250852\n[200]\tTrain's rmse: 0.0213728\tValid's rmse: 0.0250557\n[300]\tTrain's rmse: 0.0213061\tValid's rmse: 0.0250419\n[400]\tTrain's rmse: 0.0212462\tValid's rmse: 0.0250268\n[500]\tTrain's rmse: 0.0211913\tValid's rmse: 0.0250157\n[600]\tTrain's rmse: 0.0211398\tValid's rmse: 0.0250076\n[700]\tTrain's rmse: 0.0210905\tValid's rmse: 0.0250028\n[800]\tTrain's rmse: 0.0210439\tValid's rmse: 0.0249985\n[900]\tTrain's rmse: 0.021\tValid's rmse: 0.0249904\n[1000]\tTrain's rmse: 0.0209559\tValid's rmse: 0.0249843\n[1100]\tTrain's rmse: 0.0209137\tValid's rmse: 0.0249816\n[1200]\tTrain's rmse: 0.0208729\tValid's rmse: 0.0249802\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0208953\tValid's rmse: 0.024979\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  80%|########  | 16/20 [10:40<02:51, 42.89s/it]\u001b[32m[I 2022-04-22 01:03:11,713]\u001b[0m Trial 55 finished with value: 0.024978957213522113 and parameters: {'lambda_l1': 0.4412689335389584, 'lambda_l2': 0.0049068193123625314}. Best is trial 55 with value: 0.024978957213522113.\u001b[0m\nregularization_factors, val_score: 0.024975:  80%|########  | 16/20 [10:40<02:51, 42.89s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060305 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214195\tValid's rmse: 0.0250926\n[200]\tTrain's rmse: 0.0213096\tValid's rmse: 0.0250674\n[300]\tTrain's rmse: 0.0212183\tValid's rmse: 0.0250536\n[400]\tTrain's rmse: 0.0211344\tValid's rmse: 0.0250355\n[500]\tTrain's rmse: 0.0210576\tValid's rmse: 0.0250286\n[600]\tTrain's rmse: 0.0209846\tValid's rmse: 0.0250207\n[700]\tTrain's rmse: 0.0209163\tValid's rmse: 0.0250157\n[800]\tTrain's rmse: 0.0208507\tValid's rmse: 0.0250153\nEarly stopping, best iteration is:\n[779]\tTrain's rmse: 0.0208637\tValid's rmse: 0.025014\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  85%|########5 | 17/20 [11:07<01:54, 38.15s/it]\u001b[32m[I 2022-04-22 01:03:38,843]\u001b[0m Trial 56 finished with value: 0.025013984267294714 and parameters: {'lambda_l1': 0.00011777049061082607, 'lambda_l2': 0.003158947956123982}. Best is trial 55 with value: 0.024978957213522113.\u001b[0m\nregularization_factors, val_score: 0.024975:  85%|########5 | 17/20 [11:07<01:54, 38.15s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065838 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214207\tValid's rmse: 0.0250911\n[200]\tTrain's rmse: 0.0213124\tValid's rmse: 0.0250663\n[300]\tTrain's rmse: 0.0212206\tValid's rmse: 0.0250535\n[400]\tTrain's rmse: 0.0211371\tValid's rmse: 0.0250405\n[500]\tTrain's rmse: 0.0210599\tValid's rmse: 0.0250317\n[600]\tTrain's rmse: 0.0209873\tValid's rmse: 0.0250229\n[700]\tTrain's rmse: 0.0209193\tValid's rmse: 0.0250191\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  90%|######### | 18/20 [11:32<01:08, 34.01s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[654]\tTrain's rmse: 0.0209506\tValid's rmse: 0.0250182\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-04-22 01:04:03,218]\u001b[0m Trial 57 finished with value: 0.02501815001057734 and parameters: {'lambda_l1': 0.015467029305280534, 'lambda_l2': 0.0009361115913548117}. Best is trial 55 with value: 0.024978957213522113.\u001b[0m\nregularization_factors, val_score: 0.024975:  90%|######### | 18/20 [11:32<01:08, 34.01s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060889 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214485\tValid's rmse: 0.0250839\n[200]\tTrain's rmse: 0.0213645\tValid's rmse: 0.0250556\n[300]\tTrain's rmse: 0.0212946\tValid's rmse: 0.0250405\n[400]\tTrain's rmse: 0.0212315\tValid's rmse: 0.0250249\n[500]\tTrain's rmse: 0.0211742\tValid's rmse: 0.0250161\n[600]\tTrain's rmse: 0.0211198\tValid's rmse: 0.02501\n[700]\tTrain's rmse: 0.0210675\tValid's rmse: 0.0250069\n[800]\tTrain's rmse: 0.0210178\tValid's rmse: 0.0250026\n[900]\tTrain's rmse: 0.0209712\tValid's rmse: 0.0249968\n[1000]\tTrain's rmse: 0.0209244\tValid's rmse: 0.0249902\n[1100]\tTrain's rmse: 0.0208799\tValid's rmse: 0.0249915\nEarly stopping, best iteration is:\n[1013]\tTrain's rmse: 0.0209185\tValid's rmse: 0.0249888\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  95%|#########5| 19/20 [12:14<00:36, 36.59s/it]\u001b[32m[I 2022-04-22 01:04:45,804]\u001b[0m Trial 58 finished with value: 0.024988792219014597 and parameters: {'lambda_l1': 0.372645492867481, 'lambda_l2': 5.325567891420669e-05}. Best is trial 55 with value: 0.024978957213522113.\u001b[0m\nregularization_factors, val_score: 0.024975:  95%|#########5| 19/20 [12:14<00:36, 36.59s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214195\tValid's rmse: 0.0250935\n[200]\tTrain's rmse: 0.0213111\tValid's rmse: 0.0250703\n[300]\tTrain's rmse: 0.021219\tValid's rmse: 0.0250578\n[400]\tTrain's rmse: 0.0211346\tValid's rmse: 0.0250397\n[500]\tTrain's rmse: 0.0210576\tValid's rmse: 0.0250321\n[600]\tTrain's rmse: 0.0209854\tValid's rmse: 0.0250226\n[700]\tTrain's rmse: 0.0209165\tValid's rmse: 0.0250195\n[800]\tTrain's rmse: 0.020851\tValid's rmse: 0.0250187\nEarly stopping, best iteration is:\n[775]\tTrain's rmse: 0.0208666\tValid's rmse: 0.025018\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975: 100%|##########| 20/20 [12:41<00:00, 33.71s/it]\u001b[32m[I 2022-04-22 01:05:12,791]\u001b[0m Trial 59 finished with value: 0.02501800041159402 and parameters: {'lambda_l1': 0.0013987065082970889, 'lambda_l2': 3.371145778191206e-06}. Best is trial 55 with value: 0.024978957213522113.\u001b[0m\nregularization_factors, val_score: 0.024975: 100%|##########| 20/20 [12:41<00:00, 38.08s/it]\nmin_data_in_leaf, val_score: 0.024975:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0250849\n[200]\tTrain's rmse: 0.0213795\tValid's rmse: 0.025054\n[300]\tTrain's rmse: 0.0213157\tValid's rmse: 0.0250386\n[400]\tTrain's rmse: 0.0212585\tValid's rmse: 0.0250218\n[500]\tTrain's rmse: 0.0212067\tValid's rmse: 0.02501\n[600]\tTrain's rmse: 0.0211576\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0211106\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210652\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.021023\tValid's rmse: 0.0249872\n[1000]\tTrain's rmse: 0.0209806\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.0209403\tValid's rmse: 0.024978\n[1200]\tTrain's rmse: 0.0209012\tValid's rmse: 0.0249765\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209224\tValid's rmse: 0.0249745\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  20%|##        | 1/5 [00:49<03:17, 49.46s/it]\u001b[32m[I 2022-04-22 01:06:02,264]\u001b[0m Trial 60 finished with value: 0.0249745372385883 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.0249745372385883.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  20%|##        | 1/5 [00:49<03:17, 49.46s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0250849\n[200]\tTrain's rmse: 0.0213795\tValid's rmse: 0.025054\n[300]\tTrain's rmse: 0.0213157\tValid's rmse: 0.0250386\n[400]\tTrain's rmse: 0.0212585\tValid's rmse: 0.0250218\n[500]\tTrain's rmse: 0.0212067\tValid's rmse: 0.02501\n[600]\tTrain's rmse: 0.0211576\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0211106\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210652\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.021023\tValid's rmse: 0.0249872\n[1000]\tTrain's rmse: 0.0209806\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.0209403\tValid's rmse: 0.024978\n[1200]\tTrain's rmse: 0.0209012\tValid's rmse: 0.0249765\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209224\tValid's rmse: 0.0249745\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  40%|####      | 2/5 [01:39<02:29, 49.83s/it]\u001b[32m[I 2022-04-22 01:06:52,347]\u001b[0m Trial 61 finished with value: 0.0249745372385883 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.0249745372385883.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  40%|####      | 2/5 [01:39<02:29, 49.83s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059262 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0250849\n[200]\tTrain's rmse: 0.0213795\tValid's rmse: 0.025054\n[300]\tTrain's rmse: 0.0213157\tValid's rmse: 0.0250386\n[400]\tTrain's rmse: 0.0212585\tValid's rmse: 0.0250218\n[500]\tTrain's rmse: 0.0212067\tValid's rmse: 0.02501\n[600]\tTrain's rmse: 0.0211576\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0211106\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210652\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.021023\tValid's rmse: 0.0249872\n[1000]\tTrain's rmse: 0.0209806\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.0209403\tValid's rmse: 0.024978\n[1200]\tTrain's rmse: 0.0209012\tValid's rmse: 0.0249765\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209224\tValid's rmse: 0.0249745\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  60%|######    | 3/5 [02:28<01:39, 49.62s/it]\u001b[32m[I 2022-04-22 01:07:41,717]\u001b[0m Trial 62 finished with value: 0.0249745372385883 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.0249745372385883.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  60%|######    | 3/5 [02:28<01:39, 49.62s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0250849\n[200]\tTrain's rmse: 0.0213795\tValid's rmse: 0.025054\n[300]\tTrain's rmse: 0.0213157\tValid's rmse: 0.0250386\n[400]\tTrain's rmse: 0.0212585\tValid's rmse: 0.0250218\n[500]\tTrain's rmse: 0.0212067\tValid's rmse: 0.02501\n[600]\tTrain's rmse: 0.0211576\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0211106\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210652\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.021023\tValid's rmse: 0.0249872\n[1000]\tTrain's rmse: 0.0209806\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.0209403\tValid's rmse: 0.024978\n[1200]\tTrain's rmse: 0.0209012\tValid's rmse: 0.0249765\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209224\tValid's rmse: 0.0249745\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  80%|########  | 4/5 [03:18<00:49, 49.68s/it]\u001b[32m[I 2022-04-22 01:08:31,494]\u001b[0m Trial 63 finished with value: 0.0249745372385883 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.0249745372385883.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  80%|########  | 4/5 [03:18<00:49, 49.68s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058762 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214568\tValid's rmse: 0.0250849\n[200]\tTrain's rmse: 0.0213795\tValid's rmse: 0.025054\n[300]\tTrain's rmse: 0.0213157\tValid's rmse: 0.0250386\n[400]\tTrain's rmse: 0.0212585\tValid's rmse: 0.0250218\n[500]\tTrain's rmse: 0.0212067\tValid's rmse: 0.02501\n[600]\tTrain's rmse: 0.0211576\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0211106\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210652\tValid's rmse: 0.0249942\n[900]\tTrain's rmse: 0.021023\tValid's rmse: 0.0249872\n[1000]\tTrain's rmse: 0.0209806\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.0209403\tValid's rmse: 0.024978\n[1200]\tTrain's rmse: 0.0209012\tValid's rmse: 0.0249765\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209224\tValid's rmse: 0.0249745\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975: 100%|##########| 5/5 [04:07<00:00, 49.51s/it]\u001b[32m[I 2022-04-22 01:09:20,695]\u001b[0m Trial 64 finished with value: 0.0249745372385883 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.0249745372385883.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975: 100%|##########| 5/5 [04:07<00:00, 49.58s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"CV_SCORES: [0.12899740589835765, 0.4543590445606956, 0.4486879296122644]\nCV_SCORE: 0.3440147933571059\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def predictor(feature_df, feat_cols, models, is_train=True):\n    X = feature_df[feat_cols]\n    \n    # 推論\n    preds = list(map(lambda model: model.predict(X, num_iteration=model.best_iteration), models))\n    print(preds)\n    \n    # スコアは学習時のみ計算\n    if is_train:\n        scores = list(map(lambda pred: evaluator(feature_df, pred), preds))\n        print(\"SCORES:\", scores)\n\n    # 推論結果をバギング\n    pred = np.array(preds).mean(axis=0)\n\n    # スコアは学習時のみ計算\n    if is_train:\n        score = evaluator(feature_df, pred)\n        print(\"SCORE:\", score)\n    \n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:49:14.615683Z","iopub.execute_input":"2022-04-22T01:49:14.615975Z","iopub.status.idle":"2022-04-22T01:49:14.624757Z","shell.execute_reply.started":"2022-04-22T01:49:14.615947Z","shell.execute_reply":"2022-04-22T01:49:14.623670Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# 試験用データは学習用にも検証用にも使用していないものを使う\ntest_df = feature_df[('2022-02-01' <= feature_df['Date'])].copy()\npred = predictor(test_df, feat_cols, models)\npred","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:49:17.193358Z","iopub.execute_input":"2022-04-22T01:49:17.193712Z","iopub.status.idle":"2022-04-22T01:49:20.820076Z","shell.execute_reply.started":"2022-04-22T01:49:17.193677Z","shell.execute_reply":"2022-04-22T01:49:20.819437Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[array([0.00074257, 0.00074257, 0.00074257, ..., 0.00075342, 0.00071982,\n       0.00072872]), array([-2.46000363e-04,  8.69382747e-05, -8.04961914e-05, ...,\n        1.08611387e-03, -1.20911552e-03, -3.41828595e-04]), array([-3.26334984e-04, -6.68373770e-05, -7.98768512e-04, ...,\n        2.35351554e-03, -2.64243061e-03, -4.70299300e-04])]\nSCORES: [-0.15051142405326676, -0.021692750583157745, -0.043747919866109555]\nSCORE: 0.002811158472073113\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([ 5.67440497e-05,  2.54222798e-04, -4.55657360e-05, ...,\n        1.39768333e-03, -1.04390711e-03, -2.78033099e-05])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"# 時系列APIのロード\nimport jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:59:53.952279Z","iopub.execute_input":"2022-04-22T01:59:53.953042Z","iopub.status.idle":"2022-04-22T01:59:53.987455Z","shell.execute_reply.started":"2022-04-22T01:59:53.953001Z","shell.execute_reply":"2022-04-22T01:59:53.986252Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/2566298185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 時系列APIのロード\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjpx_tokyo_market_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjpx_tokyo_market_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0miter_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/jpx-tokyo-stock-exchange-prediction/jpx_tokyo_market_prediction/competition.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mjpx_tokyo_market_prediction.competition.make_env\u001b[0;34m()\u001b[0m\n","\u001b[0;31mException\u001b[0m: You can only call `make_env()` once."],"ename":"Exception","evalue":"You can only call `make_env()` once.","output_type":"error"}]},{"cell_type":"code","source":"# supplemental filesを履歴データの初期状態としてセットアップ\npast_df = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T01:53:28.752499Z","iopub.execute_input":"2022-04-22T01:53:28.753006Z","iopub.status.idle":"2022-04-22T01:53:29.521180Z","shell.execute_reply.started":"2022-04-22T01:53:28.752973Z","shell.execute_reply":"2022-04-22T01:53:29.520052Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# 日次で推論・登録\nfor i, (prices, options, financials, trades, secondary_prices, sample_prediction) in enumerate(iter_test):\n    current_date = prices[\"Date\"].iloc[0]\n    print(f\"count {i}, {current_date}\")\n\n    if i == 0:\n        # リークを防止するため、時系列APIから受け取ったデータより未来のデータを削除\n        past_df = past_df[past_df[\"Date\"] < current_date]\n\n    # リソース確保のため古い履歴を削除\n    threshold = (pd.Timestamp(current_date) - pd.offsets.BDay(80)).strftime(\"%Y-%m-%d\")\n    past_df = past_df[past_df[\"Date\"] >= threshold]\n    \n    # 時系列APIから受け取ったデータを履歴データに統合\n    base_df = collector(prices, options, financials, trades, secondary_prices, stock_list)\n    past_df = pd.concat([past_df, base_df]).reset_index(drop=True)\n\n    # 特徴量エンジニアリング\n    feature_df, feat_cols, label_col = preprocessor(past_df, False)\n\n    # 予測対象レコードだけを抽出\n    feature_df = feature_df[feature_df['Date'] == current_date]\n\n    # 推論\n    feature_df[\"pred\"] = predictor(feature_df, feat_cols, models, False)\n\n    # 推論結果からRANKを導出し、提出データに反映\n    feature_df = add_rank(feature_df)\n    write_df(feature_df, f\"result_{i}\")\n    feature_map = feature_df.set_index('SecuritiesCode')['Rank'].to_dict()\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(feature_map)\n\n    # 結果を登録\n    env.predict(sample_prediction)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:00:01.864198Z","iopub.execute_input":"2022-04-22T02:00:01.865172Z","iopub.status.idle":"2022-04-22T02:00:01.902646Z","shell.execute_reply.started":"2022-04-22T02:00:01.865126Z","shell.execute_reply":"2022-04-22T02:00:01.901472Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/2348017407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 日次で推論・登録\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinancials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrades\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_prices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_prediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcurrent_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"count {i}, {current_date}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/input/jpx-tokyo-stock-exchange-prediction/jpx_tokyo_market_prediction/competition.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36miter_test\u001b[0;34m()\u001b[0m\n","\u001b[0;31mException\u001b[0m: You can only iterate over `iter_test()` once."],"ename":"Exception","evalue":"You can only iterate over `iter_test()` once.","output_type":"error"}]}]}