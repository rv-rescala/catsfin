{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T10:21:37.020294Z","iopub.execute_input":"2022-04-22T10:21:37.020949Z","iopub.status.idle":"2022-04-22T10:21:38.209725Z","shell.execute_reply.started":"2022-04-22T10:21:37.020839Z","shell.execute_reply":"2022-04-22T10:21:38.208989Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# I/O Func\nMODEL_NAME = \"APPLE\"\nBASE_PATH = Path(f'/kaggle/working')\n\ndef adjusting_price(price, key: str):\n    \"\"\"[Adjusting Close Price]\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n\n    def generate_adjusted(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, f\"CumulativeAdjustmentFactor{key}\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = (\n            df[f\"CumulativeAdjustmentFactor{key}\"] * df[key]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[f\"Adjusted{key}\"] == 0, f\"Adjusted{key}\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = df.loc[:, f\"Adjusted{key}\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted).reset_index(drop=True)\n\n    # price.set_index(\"Date\", inplace=True)\n    return price\n\ndef adjusting_volume(price, key = \"Volume\"):\n    \"\"\"[Adjusting Close Price]\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n\n    def generate_adjusted(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, f\"CumulativeAdjustmentFactor{key}\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = (\n            df[key] / df[f\"CumulativeAdjustmentFactor{key}\"]  \n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[f\"Adjusted{key}\"] == 0, f\"Adjusted{key}\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, f\"Adjusted{key}\"] = df.loc[:, f\"Adjusted{key}\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted).reset_index(drop=True)\n\n    # price.set_index(\"Date\", inplace=True)\n    return price\n\ndef read_prices(dir_name: str, securities_code: int = None):\n    \"\"\"[Important: the dateset of 2020/10/1 is lost because of system failer in JPX, see: https://www.jpx.co.jp/corporate/news/news-releases/0060/20201019-01.html]\n    \n    \"\"\"\n    base_path = Path(f'../input/jpx-tokyo-stock-exchange-prediction/{dir_name}')\n    df = pd.read_csv(base_path / 'stock_prices.csv')\n    df = df[df['Open'].notna()]\n    if securities_code:\n        df = df[df[\"SecuritiesCode\"] == securities_code]\n    return df\n\ndef read_stock_list(securities_code: int = None, only_universe: bool = True):\n    df = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv')\n    if only_universe:\n        df = df[df['Universe0']]\n    if securities_code:\n        df = df[df[\"SecuritiesCode\"] == securities_code]\n    return df\n\ndef merge_data(prices, stock_list):\n    # stock_prices がベース\n    base_df = prices.copy()\n    \n    # stock_listと結合\n    _stock_list = stock_list.copy()\n    _stock_list.rename(columns={'Close': 'Close_x'}, inplace=True)\n    base_df = base_df.merge(_stock_list, on='SecuritiesCode', how=\"left\")\n    # format\n    base_df.loc[: ,\"Date\"] = pd.to_datetime(base_df.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n    base_df.loc[: ,\"EffectiveDate\"] = pd.to_datetime(base_df.loc[: ,\"EffectiveDate\"], format=\"%Y%m%d\")\n    return base_df\n\ndef read_train_data_by_price(securities_code: int = None, with_supplemental: bool = True):\n    \"\"\"[The train base is price dataset, the other data are joined to prices DF by left join]\n    \n    \"\"\"\n    # origin\n    df = merge_data(prices=read_prices(dir_name=\"train_files\", securities_code=securities_code), stock_list=read_stock_list(securities_code=securities_code))\n    \n    # supplyment\n    if with_supplemental:\n        supplemental_df = merge_data(prices=read_prices(dir_name=\"supplemental_files\", securities_code=securities_code), stock_list=read_stock_list(securities_code=securities_code))\n        df = pd.concat([df, supplemental_df]).reset_index(drop=True)\n        \n    df = adjusting_price(df, \"Close\")\n    df = adjusting_price(df, \"Open\")\n    df = adjusting_price(df, \"High\")\n    df = adjusting_price(df, \"Low\")\n    df = adjusting_volume(df)\n    return df\n\ndef collector(prices, options, financials, trades, secondary_prices, stock_list):\n    # 読み込んだデータを統合して一つのファイルに纏める\n    df = merge_data(prices, stock_list)\n    # AdjustedClose項目の生成\n    df = adjusting_price(df, \"Close\")\n    df = adjusting_price(df, \"Open\")\n    df = adjusting_price(df, \"High\")\n    df = adjusting_price(df, \"Low\")\n    df = adjusting_volume(df)\n    return df\n\ndef write_df(df, filename):\n    df.to_csv(f'{BASE_PATH}/{filename}_{MODEL_NAME}.csv',index = False)\n    \nimport joblib\ndef write_model(model, name):\n    # save model\n    joblib.dump(model, f'{BASE_PATH}/{name}_{MODEL_NAME}.pkl')\n\n\n# load model\ndef read_model(name):\n    return joblib.load(f'{BASE_PATH}/{name}_{MODEL_NAME}.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:21:38.211350Z","iopub.execute_input":"2022-04-22T10:21:38.211752Z","iopub.status.idle":"2022-04-22T10:21:38.234707Z","shell.execute_reply.started":"2022-04-22T10:21:38.211720Z","shell.execute_reply":"2022-04-22T10:21:38.233675Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"stock_list = read_stock_list()\nstock_list","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:21:38.235712Z","iopub.execute_input":"2022-04-22T10:21:38.236376Z","iopub.status.idle":"2022-04-22T10:21:38.321380Z","shell.execute_reply.started":"2022-04-22T10:21:38.236339Z","shell.execute_reply":"2022-04-22T10:21:38.319603Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      SecuritiesCode  EffectiveDate                        Name  \\\n0               1301       20211230            KYOKUYO CO.,LTD.   \n19              1332       20211230   Nippon Suisan Kaisha,Ltd.   \n20              1333       20211230  Maruha Nichiro Corporation   \n37              1375       20211230   YUKIGUNI MAITAKE CO.,LTD.   \n38              1376       20211230       KANEKO SEEDS CO.,LTD.   \n...              ...            ...                         ...   \n4408            9990       20211230     SAC'S BAR HOLDINGS INC.   \n4409            9991       20211230          GECOSS CORPORATION   \n4411            9993       20211230           YAMAZAWA CO.,LTD.   \n4412            9994       20211230          YAMAYA CORPORATION   \n4415            9997       20211230            BELLUNA CO.,LTD.   \n\n              Section/Products NewMarketSegment 33SectorCode  \\\n0     First Section (Domestic)     Prime Market           50   \n19    First Section (Domestic)     Prime Market           50   \n20    First Section (Domestic)     Prime Market           50   \n37    First Section (Domestic)     Prime Market           50   \n38    First Section (Domestic)  Standard Market           50   \n...                        ...              ...          ...   \n4408  First Section (Domestic)     Prime Market         6100   \n4409  First Section (Domestic)     Prime Market         6050   \n4411  First Section (Domestic)  Standard Market         6100   \n4412  First Section (Domestic)  Standard Market         6100   \n4415  First Section (Domestic)     Prime Market         6100   \n\n                           33SectorName 17SectorCode  \\\n0     Fishery, Agriculture and Forestry            1   \n19    Fishery, Agriculture and Forestry            1   \n20    Fishery, Agriculture and Forestry            1   \n37    Fishery, Agriculture and Forestry            1   \n38    Fishery, Agriculture and Forestry            1   \n...                                 ...          ...   \n4408                       Retail Trade           14   \n4409                    Wholesale Trade           13   \n4411                       Retail Trade           14   \n4412                       Retail Trade           14   \n4415                       Retail Trade           14   \n\n                       17SectorName NewIndexSeriesSizeCode NewIndexSeriesSize  \\\n0                            FOODS                       7      TOPIX Small 2   \n19                           FOODS                       4       TOPIX Mid400   \n20                           FOODS                       4       TOPIX Mid400   \n37                           FOODS                       6      TOPIX Small 1   \n38                           FOODS                       7      TOPIX Small 2   \n...                             ...                    ...                ...   \n4408                  RETAIL TRADE                       7      TOPIX Small 2   \n4409  COMMERCIAL & WHOLESALE TRADE                       7      TOPIX Small 2   \n4411                  RETAIL TRADE                       7      TOPIX Small 2   \n4412                  RETAIL TRADE                       7      TOPIX Small 2   \n4415                  RETAIL TRADE                       6      TOPIX Small 1   \n\n       TradeDate   Close  IssuedShares  MarketCapitalization  Universe0  \n0     20211230.0  3080.0    10928283.0          3.365911e+10       True  \n19    20211230.0   543.0   312430277.0          1.696496e+11       True  \n20    20211230.0  2405.0    52656910.0          1.266399e+11       True  \n37    20211230.0  1196.0    39910700.0          4.773320e+10       True  \n38    20211230.0  1504.0    11772626.0          1.770603e+10       True  \n...          ...     ...           ...                   ...        ...  \n4408  20211230.0   518.0    29859900.0          1.546743e+10       True  \n4409  20211230.0   825.0    36436125.0          3.005980e+10       True  \n4411  20211230.0  1626.0    10960825.0          1.782230e+10       True  \n4412  20211230.0  2447.0    10847870.0          2.654474e+10       True  \n4415  20211230.0   709.0    97244472.0          6.894633e+10       True  \n\n[2000 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SecuritiesCode</th>\n      <th>EffectiveDate</th>\n      <th>Name</th>\n      <th>Section/Products</th>\n      <th>NewMarketSegment</th>\n      <th>33SectorCode</th>\n      <th>33SectorName</th>\n      <th>17SectorCode</th>\n      <th>17SectorName</th>\n      <th>NewIndexSeriesSizeCode</th>\n      <th>NewIndexSeriesSize</th>\n      <th>TradeDate</th>\n      <th>Close</th>\n      <th>IssuedShares</th>\n      <th>MarketCapitalization</th>\n      <th>Universe0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1301</td>\n      <td>20211230</td>\n      <td>KYOKUYO CO.,LTD.</td>\n      <td>First Section (Domestic)</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>Fishery, Agriculture and Forestry</td>\n      <td>1</td>\n      <td>FOODS</td>\n      <td>7</td>\n      <td>TOPIX Small 2</td>\n      <td>20211230.0</td>\n      <td>3080.0</td>\n      <td>10928283.0</td>\n      <td>3.365911e+10</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1332</td>\n      <td>20211230</td>\n      <td>Nippon Suisan Kaisha,Ltd.</td>\n      <td>First Section (Domestic)</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>Fishery, Agriculture and Forestry</td>\n      <td>1</td>\n      <td>FOODS</td>\n      <td>4</td>\n      <td>TOPIX Mid400</td>\n      <td>20211230.0</td>\n      <td>543.0</td>\n      <td>312430277.0</td>\n      <td>1.696496e+11</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1333</td>\n      <td>20211230</td>\n      <td>Maruha Nichiro Corporation</td>\n      <td>First Section (Domestic)</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>Fishery, Agriculture and Forestry</td>\n      <td>1</td>\n      <td>FOODS</td>\n      <td>4</td>\n      <td>TOPIX Mid400</td>\n      <td>20211230.0</td>\n      <td>2405.0</td>\n      <td>52656910.0</td>\n      <td>1.266399e+11</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1375</td>\n      <td>20211230</td>\n      <td>YUKIGUNI MAITAKE CO.,LTD.</td>\n      <td>First Section (Domestic)</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>Fishery, Agriculture and Forestry</td>\n      <td>1</td>\n      <td>FOODS</td>\n      <td>6</td>\n      <td>TOPIX Small 1</td>\n      <td>20211230.0</td>\n      <td>1196.0</td>\n      <td>39910700.0</td>\n      <td>4.773320e+10</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1376</td>\n      <td>20211230</td>\n      <td>KANEKO SEEDS CO.,LTD.</td>\n      <td>First Section (Domestic)</td>\n      <td>Standard Market</td>\n      <td>50</td>\n      <td>Fishery, Agriculture and Forestry</td>\n      <td>1</td>\n      <td>FOODS</td>\n      <td>7</td>\n      <td>TOPIX Small 2</td>\n      <td>20211230.0</td>\n      <td>1504.0</td>\n      <td>11772626.0</td>\n      <td>1.770603e+10</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4408</th>\n      <td>9990</td>\n      <td>20211230</td>\n      <td>SAC'S BAR HOLDINGS INC.</td>\n      <td>First Section (Domestic)</td>\n      <td>Prime Market</td>\n      <td>6100</td>\n      <td>Retail Trade</td>\n      <td>14</td>\n      <td>RETAIL TRADE</td>\n      <td>7</td>\n      <td>TOPIX Small 2</td>\n      <td>20211230.0</td>\n      <td>518.0</td>\n      <td>29859900.0</td>\n      <td>1.546743e+10</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4409</th>\n      <td>9991</td>\n      <td>20211230</td>\n      <td>GECOSS CORPORATION</td>\n      <td>First Section (Domestic)</td>\n      <td>Prime Market</td>\n      <td>6050</td>\n      <td>Wholesale Trade</td>\n      <td>13</td>\n      <td>COMMERCIAL &amp; WHOLESALE TRADE</td>\n      <td>7</td>\n      <td>TOPIX Small 2</td>\n      <td>20211230.0</td>\n      <td>825.0</td>\n      <td>36436125.0</td>\n      <td>3.005980e+10</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4411</th>\n      <td>9993</td>\n      <td>20211230</td>\n      <td>YAMAZAWA CO.,LTD.</td>\n      <td>First Section (Domestic)</td>\n      <td>Standard Market</td>\n      <td>6100</td>\n      <td>Retail Trade</td>\n      <td>14</td>\n      <td>RETAIL TRADE</td>\n      <td>7</td>\n      <td>TOPIX Small 2</td>\n      <td>20211230.0</td>\n      <td>1626.0</td>\n      <td>10960825.0</td>\n      <td>1.782230e+10</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4412</th>\n      <td>9994</td>\n      <td>20211230</td>\n      <td>YAMAYA CORPORATION</td>\n      <td>First Section (Domestic)</td>\n      <td>Standard Market</td>\n      <td>6100</td>\n      <td>Retail Trade</td>\n      <td>14</td>\n      <td>RETAIL TRADE</td>\n      <td>7</td>\n      <td>TOPIX Small 2</td>\n      <td>20211230.0</td>\n      <td>2447.0</td>\n      <td>10847870.0</td>\n      <td>2.654474e+10</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4415</th>\n      <td>9997</td>\n      <td>20211230</td>\n      <td>BELLUNA CO.,LTD.</td>\n      <td>First Section (Domestic)</td>\n      <td>Prime Market</td>\n      <td>6100</td>\n      <td>Retail Trade</td>\n      <td>14</td>\n      <td>RETAIL TRADE</td>\n      <td>6</td>\n      <td>TOPIX Small 1</td>\n      <td>20211230.0</td>\n      <td>709.0</td>\n      <td>97244472.0</td>\n      <td>6.894633e+10</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df = read_train_data_by_price()\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:21:38.323243Z","iopub.execute_input":"2022-04-22T10:21:38.323923Z","iopub.status.idle":"2022-04-22T10:23:28.492518Z","shell.execute_reply.started":"2022-04-22T10:21:38.323892Z","shell.execute_reply":"2022-04-22T10:23:28.491972Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                 RowId       Date  SecuritiesCode    Open    High     Low  \\\n0        20170104_1301 2017-01-04            1301  2734.0  2755.0  2730.0   \n1        20170105_1301 2017-01-05            1301  2743.0  2747.0  2735.0   \n2        20170106_1301 2017-01-06            1301  2734.0  2744.0  2720.0   \n3        20170110_1301 2017-01-10            1301  2745.0  2754.0  2735.0   \n4        20170111_1301 2017-01-11            1301  2748.0  2752.0  2737.0   \n...                ...        ...             ...     ...     ...     ...   \n2436634  20220221_9997 2022-02-21            9997   725.0   729.0   719.0   \n2436635  20220222_9997 2022-02-22            9997   719.0   723.0   711.0   \n2436636  20220224_9997 2022-02-24            9997   709.0   725.0   708.0   \n2436637  20220225_9997 2022-02-25            9997   725.0   738.0   724.0   \n2436638  20220228_9997 2022-02-28            9997   731.0   737.0   726.0   \n\n          Close  Volume  AdjustmentFactor  ExpectedDividend  ...  \\\n0        2742.0   31400               1.0               NaN  ...   \n1        2738.0   17900               1.0               NaN  ...   \n2        2740.0   19900               1.0               NaN  ...   \n3        2748.0   24200               1.0               NaN  ...   \n4        2745.0    9300               1.0               NaN  ...   \n...         ...     ...               ...               ...  ...   \n2436634   727.0  116400               1.0               NaN  ...   \n2436635   721.0  225500               1.0               NaN  ...   \n2436636   719.0  195600               1.0               NaN  ...   \n2436637   733.0  170500               1.0               NaN  ...   \n2436638   734.0  288100               1.0               NaN  ...   \n\n         CumulativeAdjustmentFactorClose  AdjustedClose  \\\n0                                    1.0         2742.0   \n1                                    1.0         2738.0   \n2                                    1.0         2740.0   \n3                                    1.0         2748.0   \n4                                    1.0         2745.0   \n...                                  ...            ...   \n2436634                              1.0          727.0   \n2436635                              1.0          721.0   \n2436636                              1.0          719.0   \n2436637                              1.0          733.0   \n2436638                              1.0          734.0   \n\n        CumulativeAdjustmentFactorOpen AdjustedOpen  \\\n0                                  1.0       2734.0   \n1                                  1.0       2743.0   \n2                                  1.0       2734.0   \n3                                  1.0       2745.0   \n4                                  1.0       2748.0   \n...                                ...          ...   \n2436634                            1.0        725.0   \n2436635                            1.0        719.0   \n2436636                            1.0        709.0   \n2436637                            1.0        725.0   \n2436638                            1.0        731.0   \n\n        CumulativeAdjustmentFactorHigh AdjustedHigh  \\\n0                                  1.0       2755.0   \n1                                  1.0       2747.0   \n2                                  1.0       2744.0   \n3                                  1.0       2754.0   \n4                                  1.0       2752.0   \n...                                ...          ...   \n2436634                            1.0        729.0   \n2436635                            1.0        723.0   \n2436636                            1.0        725.0   \n2436637                            1.0        738.0   \n2436638                            1.0        737.0   \n\n        CumulativeAdjustmentFactorLow AdjustedLow  \\\n0                                 1.0      2730.0   \n1                                 1.0      2735.0   \n2                                 1.0      2720.0   \n3                                 1.0      2735.0   \n4                                 1.0      2737.0   \n...                               ...         ...   \n2436634                           1.0       719.0   \n2436635                           1.0       711.0   \n2436636                           1.0       708.0   \n2436637                           1.0       724.0   \n2436638                           1.0       726.0   \n\n        CumulativeAdjustmentFactorVolume AdjustedVolume  \n0                                    1.0        31400.0  \n1                                    1.0        17900.0  \n2                                    1.0        19900.0  \n3                                    1.0        24200.0  \n4                                    1.0         9300.0  \n...                                  ...            ...  \n2436634                              1.0       116400.0  \n2436635                              1.0       225500.0  \n2436636                              1.0       195600.0  \n2436637                              1.0       170500.0  \n2436638                              1.0       288100.0  \n\n[2436639 rows x 37 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowId</th>\n      <th>Date</th>\n      <th>SecuritiesCode</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>AdjustmentFactor</th>\n      <th>ExpectedDividend</th>\n      <th>...</th>\n      <th>CumulativeAdjustmentFactorClose</th>\n      <th>AdjustedClose</th>\n      <th>CumulativeAdjustmentFactorOpen</th>\n      <th>AdjustedOpen</th>\n      <th>CumulativeAdjustmentFactorHigh</th>\n      <th>AdjustedHigh</th>\n      <th>CumulativeAdjustmentFactorLow</th>\n      <th>AdjustedLow</th>\n      <th>CumulativeAdjustmentFactorVolume</th>\n      <th>AdjustedVolume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20170104_1301</td>\n      <td>2017-01-04</td>\n      <td>1301</td>\n      <td>2734.0</td>\n      <td>2755.0</td>\n      <td>2730.0</td>\n      <td>2742.0</td>\n      <td>31400</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2742.0</td>\n      <td>1.0</td>\n      <td>2734.0</td>\n      <td>1.0</td>\n      <td>2755.0</td>\n      <td>1.0</td>\n      <td>2730.0</td>\n      <td>1.0</td>\n      <td>31400.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20170105_1301</td>\n      <td>2017-01-05</td>\n      <td>1301</td>\n      <td>2743.0</td>\n      <td>2747.0</td>\n      <td>2735.0</td>\n      <td>2738.0</td>\n      <td>17900</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2738.0</td>\n      <td>1.0</td>\n      <td>2743.0</td>\n      <td>1.0</td>\n      <td>2747.0</td>\n      <td>1.0</td>\n      <td>2735.0</td>\n      <td>1.0</td>\n      <td>17900.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20170106_1301</td>\n      <td>2017-01-06</td>\n      <td>1301</td>\n      <td>2734.0</td>\n      <td>2744.0</td>\n      <td>2720.0</td>\n      <td>2740.0</td>\n      <td>19900</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2740.0</td>\n      <td>1.0</td>\n      <td>2734.0</td>\n      <td>1.0</td>\n      <td>2744.0</td>\n      <td>1.0</td>\n      <td>2720.0</td>\n      <td>1.0</td>\n      <td>19900.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20170110_1301</td>\n      <td>2017-01-10</td>\n      <td>1301</td>\n      <td>2745.0</td>\n      <td>2754.0</td>\n      <td>2735.0</td>\n      <td>2748.0</td>\n      <td>24200</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2748.0</td>\n      <td>1.0</td>\n      <td>2745.0</td>\n      <td>1.0</td>\n      <td>2754.0</td>\n      <td>1.0</td>\n      <td>2735.0</td>\n      <td>1.0</td>\n      <td>24200.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20170111_1301</td>\n      <td>2017-01-11</td>\n      <td>1301</td>\n      <td>2748.0</td>\n      <td>2752.0</td>\n      <td>2737.0</td>\n      <td>2745.0</td>\n      <td>9300</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2745.0</td>\n      <td>1.0</td>\n      <td>2748.0</td>\n      <td>1.0</td>\n      <td>2752.0</td>\n      <td>1.0</td>\n      <td>2737.0</td>\n      <td>1.0</td>\n      <td>9300.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2436634</th>\n      <td>20220221_9997</td>\n      <td>2022-02-21</td>\n      <td>9997</td>\n      <td>725.0</td>\n      <td>729.0</td>\n      <td>719.0</td>\n      <td>727.0</td>\n      <td>116400</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>727.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>729.0</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>116400.0</td>\n    </tr>\n    <tr>\n      <th>2436635</th>\n      <td>20220222_9997</td>\n      <td>2022-02-22</td>\n      <td>9997</td>\n      <td>719.0</td>\n      <td>723.0</td>\n      <td>711.0</td>\n      <td>721.0</td>\n      <td>225500</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>721.0</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>723.0</td>\n      <td>1.0</td>\n      <td>711.0</td>\n      <td>1.0</td>\n      <td>225500.0</td>\n    </tr>\n    <tr>\n      <th>2436636</th>\n      <td>20220224_9997</td>\n      <td>2022-02-24</td>\n      <td>9997</td>\n      <td>709.0</td>\n      <td>725.0</td>\n      <td>708.0</td>\n      <td>719.0</td>\n      <td>195600</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>719.0</td>\n      <td>1.0</td>\n      <td>709.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>708.0</td>\n      <td>1.0</td>\n      <td>195600.0</td>\n    </tr>\n    <tr>\n      <th>2436637</th>\n      <td>20220225_9997</td>\n      <td>2022-02-25</td>\n      <td>9997</td>\n      <td>725.0</td>\n      <td>738.0</td>\n      <td>724.0</td>\n      <td>733.0</td>\n      <td>170500</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>733.0</td>\n      <td>1.0</td>\n      <td>725.0</td>\n      <td>1.0</td>\n      <td>738.0</td>\n      <td>1.0</td>\n      <td>724.0</td>\n      <td>1.0</td>\n      <td>170500.0</td>\n    </tr>\n    <tr>\n      <th>2436638</th>\n      <td>20220228_9997</td>\n      <td>2022-02-28</td>\n      <td>9997</td>\n      <td>731.0</td>\n      <td>737.0</td>\n      <td>726.0</td>\n      <td>734.0</td>\n      <td>288100</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>734.0</td>\n      <td>1.0</td>\n      <td>731.0</td>\n      <td>1.0</td>\n      <td>737.0</td>\n      <td>1.0</td>\n      <td>726.0</td>\n      <td>1.0</td>\n      <td>288100.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2436639 rows × 37 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Featrue","metadata":{}},{"cell_type":"code","source":"def cal_moving_average(key:str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"MovingAverage{key}{period}\"\n            col_gap = f\"{col}GapPercent\"\n            df[col] = df[key].rolling(period, min_periods=1).mean()\n            df[col_gap] = (df[key] / df[col]) * 100.0\n        return df\n    return func\n\ndef cal_changing_ration(key:str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"ChangingRatio{key}{period}\"\n            df[col] = df[key].pct_change(period) * 100\n        return df\n    return func\n\ndef cal_historical_vix(key: str, periods):\n    def func(df):\n        for period in periods:\n            col = f\"HistoricalVIX{key}{period}\"\n            df[col] = np.log(df[key]).diff().rolling(period).std()\n        return df\n    return func\n\ndef add_columns_per_code(df, functions):\n    def func(df):\n        for f in functions:\n            df = f(df)\n        return df\n    df = df.sort_values([\"SecuritiesCode\", \"Date\"])\n    df = df.groupby(\"SecuritiesCode\").apply(func)\n    df = df.reset_index(drop=True)\n    return df\n\ndef add_columns_per_day(base_df):\n    base_df['diff_rate1'] = (base_df['Close'] - base_df['Open']) / base_df['Close']\n    base_df['diff_rate2'] = (base_df['High'] - base_df['Low']) / base_df['Close']    \n    return base_df\n\ndef generate_features(df):\n    base_df = df.copy()\n    prev_column_names = base_df.columns\n    periods = [5, 25, 75]\n    functions = [\n        cal_moving_average(\"AdjustedClose\", periods),\n        cal_moving_average(\"AdjustedOpen\", periods),\n        cal_moving_average(\"AdjustedHigh\", periods),\n        cal_moving_average(\"AdjustedLow\", periods),\n        cal_moving_average(\"AdjustedVolume\", periods),\n        cal_changing_ration(\"AdjustedClose\", periods),\n        cal_changing_ration(\"AdjustedOpen\", periods),\n        cal_changing_ration(\"AdjustedHigh\", periods),\n        cal_changing_ration(\"AdjustedLow\", periods),\n        cal_changing_ration(\"AdjustedVolume\", periods),\n        cal_historical_vix(\"AdjustedClose\", periods),\n        cal_historical_vix(\"AdjustedOpen\", periods),\n        cal_historical_vix(\"AdjustedHigh\", periods),\n        cal_historical_vix(\"AdjustedLow\", periods),\n        cal_historical_vix(\"AdjustedVolume\", periods)\n    ]\n    \n    base_df = add_columns_per_code(base_df, functions)\n    base_df = add_columns_per_day(base_df)\n    \n    add_column_names = list(set(base_df.columns) - set(prev_column_names))\n    #feats = feats[feats[\"HistoricalVIXAdjustedClose75\"] != 0]\n    return base_df, add_column_names\n\ndef select_features(feature_df, add_column_names, is_train):\n    base_cols = ['RowId', 'Date', 'SecuritiesCode']\n    numerical_cols = sorted(add_column_names)\n    categorical_cols = ['NewMarketSegment', '33SectorCode', '17SectorCode']\n    label_col = ['Target']\n    feat_cols = numerical_cols + categorical_cols\n    feature_df = feature_df[base_cols + feat_cols + label_col]\n    feature_df[categorical_cols] = feature_df[categorical_cols].astype('category')\n    if is_train:\n        feature_df.dropna(inplace=True)\n    else:\n        feature_df[numerical_cols] = feature_df[numerical_cols].fillna(0)\n        feature_df[numerical_cols] = feature_df[numerical_cols].replace([np.inf, -np.inf], 0)\n    return feature_df, feat_cols, label_col\n\ndef preprocessor(base_df, is_train=True):\n    feature_df = base_df.copy()\n    \n    ## 特徴量生成\n    feature_df, add_column_names = generate_features(feature_df)\n    \n    ## 特徴量選択\n    feature_df, feat_cols, label_col = select_features(feature_df, add_column_names, is_train)\n\n    # 上書き\n    feat_cols = ['33SectorCode', 'ChangingRatioAdjustedVolume25', 'diff_rate2', 'MovingAverageAdjustedHigh5GapPercent', 'MovingAverageAdjustedOpen5GapPercent', 'HistoricalVIXAdjustedLow5', 'MovingAverageAdjustedClose5GapPercent', 'HistoricalVIXAdjustedOpen5', 'MovingAverageAdjustedLow25GapPercent', 'ChangingRatioAdjustedVolume5', 'HistoricalVIXAdjustedOpen75', 'HistoricalVIXAdjustedVolume5', 'MovingAverageAdjustedVolume25GapPercent', 'diff_rate1', 'ChangingRatioAdjustedHigh5', 'ChangingRatioAdjustedOpen25', 'HistoricalVIXAdjustedOpen25', 'MovingAverageAdjustedClose25GapPercent', 'MovingAverageAdjustedVolume75GapPercent', 'ChangingRatioAdjustedLow25', 'ChangingRatioAdjustedLow5', 'HistoricalVIXAdjustedHigh75', 'MovingAverageAdjustedLow5GapPercent', 'ChangingRatioAdjustedClose75', 'MovingAverageAdjustedClose75', 'MovingAverageAdjustedClose75GapPercent', 'HistoricalVIXAdjustedVolume75']\n    return feature_df, feat_cols, label_col\n\nfeature_df, feat_cols, label_col = preprocessor(train_df)\nfeat_cols","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:23:28.493472Z","iopub.execute_input":"2022-04-22T10:23:28.494148Z","iopub.status.idle":"2022-04-22T10:25:17.099357Z","shell.execute_reply.started":"2022-04-22T10:23:28.494117Z","shell.execute_reply":"2022-04-22T10:25:17.097019Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['33SectorCode',\n 'ChangingRatioAdjustedVolume25',\n 'diff_rate2',\n 'MovingAverageAdjustedHigh5GapPercent',\n 'MovingAverageAdjustedOpen5GapPercent',\n 'HistoricalVIXAdjustedLow5',\n 'MovingAverageAdjustedClose5GapPercent',\n 'HistoricalVIXAdjustedOpen5',\n 'MovingAverageAdjustedLow25GapPercent',\n 'ChangingRatioAdjustedVolume5',\n 'HistoricalVIXAdjustedOpen75',\n 'HistoricalVIXAdjustedVolume5',\n 'MovingAverageAdjustedVolume25GapPercent',\n 'diff_rate1',\n 'ChangingRatioAdjustedHigh5',\n 'ChangingRatioAdjustedOpen25',\n 'HistoricalVIXAdjustedOpen25',\n 'MovingAverageAdjustedClose25GapPercent',\n 'MovingAverageAdjustedVolume75GapPercent',\n 'ChangingRatioAdjustedLow25',\n 'ChangingRatioAdjustedLow5',\n 'HistoricalVIXAdjustedHigh75',\n 'MovingAverageAdjustedLow5GapPercent',\n 'ChangingRatioAdjustedClose75',\n 'MovingAverageAdjustedClose75',\n 'MovingAverageAdjustedClose75GapPercent',\n 'HistoricalVIXAdjustedVolume75']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Learning","metadata":{}},{"cell_type":"code","source":"# 予測値を降順に並べて順位番号を振る関数\n# 言い換えると、目的変数から提出用項目を導出する関数\ndef add_rank(df, col_name=\"pred\"):\n    df[\"Rank\"] = df.groupby(\"Date\")[col_name].rank(ascending=False, method=\"first\") - 1 \n    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n    return df\n\ndef calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        #print(f\"date: {df['Date'].min()}\")\n        #print(f\"min: {df['Rank'].min()}\")\n        #print(f\"max: {df['Rank'].max()}\")\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        #print(f\"short: {short}\")\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    print(f\"sharpe_ratio: {sharpe_ratio}\")\n    return sharpe_ratio\n\n# 予測用のデータフレームと、予測結果をもとに、スコアを計算する関数\ndef evaluator(df, pred):\n    df[\"pred\"] = pred\n    df = add_rank(df)\n    score = calc_spread_return_sharpe(df)\n    return score\n\nimport lightgbm as lgb\nimport optuna.integration.lightgbm as lgb\n\n# 学習を実行する関数\ndef trainer(feature_df, feat_cols, label_col, fold_params, seed=2022, use_cache: bool = False):\n    scores = []\n    models = []\n    params = []\n    i = 0\n    for param in fold_params:\n        if not use_cache:\n            ################################\n            # データ準備\n            ################################\n            train = feature_df[(param[0] <= feature_df['Date']) & (feature_df['Date'] < param[1])]\n            valid = feature_df[(param[1] <= feature_df['Date']) & (feature_df['Date'] < param[2])]\n\n            X_train = train[feat_cols]\n            y_train = train[label_col]\n            X_valid = valid[feat_cols]\n            y_valid = valid[label_col]\n\n            lgb_train = lgb.Dataset(X_train, y_train)\n            lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n\n            ################################\n            # 学習\n            ################################\n            params = {\n                'task': 'train',                   # 学習\n                'boosting_type': 'gbdt',           # GBDT\n                'objective': 'regression',         # 回帰\n                'metric': 'rmse',                  # 損失（誤差）\n                'learning_rate': 0.01,             # 学習率\n                'lambda_l1': 0.5,                  # L1正則化項の係数\n                'lambda_l2': 0.5,                  # L2正則化項の係数\n                'num_leaves': 10,                  # 最大葉枚数\n                'feature_fraction': 0.5,           # ランダムに抽出される列の割合\n                'bagging_fraction': 0.5,           # ランダムに抽出される標本の割合\n                'bagging_freq': 5,                 # バギング実施頻度\n                'min_child_samples': 10,           # 葉に含まれる最小データ数\n                'seed': seed                       # シード値\n            } \n\n            lgb_results = {}                       \n            model = lgb.train( \n                params,                            # ハイパーパラメータ\n                lgb_train,                         # 訓練データ\n                valid_sets=[lgb_train, lgb_valid], # 検証データ\n                valid_names=['Train', 'Valid'],    # データセット名前\n                num_boost_round=2000,              # 計算回数\n                early_stopping_rounds=100,         # 計算打ち切り設定\n                evals_result=lgb_results,          # 学習の履歴\n                verbose_eval=100,                  # 学習過程の表示サイクル\n            )  \n\n            ################################\n            # 結果描画\n            ################################\n            fig = plt.figure(figsize=(10, 4))\n\n            # loss\n            plt.subplot(1,2,1)\n            loss_train = lgb_results['Train']['rmse']\n            loss_test = lgb_results['Valid']['rmse']   \n            plt.xlabel('Iteration')\n            plt.ylabel('logloss')\n            plt.plot(loss_train, label='train loss')\n            plt.plot(loss_test, label='valid loss')\n            plt.legend()\n\n            # feature importance\n            plt.subplot(1,2,2)\n            importance = pd.DataFrame({'feature':feat_cols, 'importance':model.feature_importance()})\n            write_df(importance, f\"importance_{i}\")\n            sns.barplot(x = 'importance', y = 'feature', data = importance.sort_values('importance', ascending=False))\n\n            plt.tight_layout()\n            plt.show()\n\n            ################################\n            # 評価\n            ################################\n            # 推論\n            pred =  model.predict(X_valid, num_iteration=model.best_iteration)\n            # 評価\n            score = evaluator(valid, pred)\n            print(f\"score {i}: {score}\")\n\n            scores.append(score)\n            models.append(model)\n            # save model\n            write_model(model, f'model_{i}')\n\n        else:\n            read_model(f'model_{i}')\n        i = i + 1\n    print(\"CV_SCORES:\", scores)\n    print(\"CV_SCORE:\", np.mean(scores))\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:25:17.100912Z","iopub.execute_input":"2022-04-22T10:25:17.101416Z","iopub.status.idle":"2022-04-22T10:25:18.832539Z","shell.execute_reply.started":"2022-04-22T10:25:17.101367Z","shell.execute_reply":"2022-04-22T10:25:18.831489Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"# 2020-12-23よりも前のデータは証券コードが2000個すべて揃っていないため、これ以降のデータのみを使う。\n# (学習用データの開始日、学習用データの終了日＝検証用データの開始日、検証用データの終了日)\nfold_params = [\n    ('2020-12-23', '2021-11-01', '2021-12-01'),\n    ('2021-01-23', '2021-12-01', '2022-01-01'),\n    ('2021-02-23', '2022-01-01', '2022-02-01'),\n]\nmodels = trainer(feature_df, feat_cols, label_col, fold_params, use_cache=False)\nmodels","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:25:18.834016Z","iopub.execute_input":"2022-04-22T10:25:18.834822Z","iopub.status.idle":"2022-04-22T11:31:00.468151Z","shell.execute_reply.started":"2022-04-22T10:25:18.834784Z","shell.execute_reply":"2022-04-22T11:31:00.467073Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-04-22 10:25:19,008]\u001b[0m A new study created in memory with name: no-name-393599c8-df02-4375-8b55-b3da5978ed4c\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068430 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  14%|#4        | 1/7 [00:03<00:22,  3.73s/it]\u001b[32m[I 2022-04-22 10:25:22,745]\u001b[0m Trial 0 finished with value: 0.02464466028893019 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  14%|#4        | 1/7 [00:03<00:22,  3.73s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214233\tValid's rmse: 0.0246642\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066861 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  29%|##8       | 2/7 [00:07<00:18,  3.79s/it]\u001b[32m[I 2022-04-22 10:25:26,573]\u001b[0m Trial 1 finished with value: 0.02464474349138154 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  29%|##8       | 2/7 [00:07<00:18,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021421\tValid's rmse: 0.0246673\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057864 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  43%|####2     | 3/7 [00:10<00:14,  3.56s/it]\u001b[32m[I 2022-04-22 10:25:29,869]\u001b[0m Trial 2 finished with value: 0.024644844918831402 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  43%|####2     | 3/7 [00:10<00:14,  3.56s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214272\tValid's rmse: 0.0246639\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214582\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061010 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  57%|#####7    | 4/7 [00:14<00:10,  3.54s/it]\u001b[32m[I 2022-04-22 10:25:33,378]\u001b[0m Trial 3 finished with value: 0.02464466028893019 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  57%|#####7    | 4/7 [00:14<00:10,  3.54s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214241\tValid's rmse: 0.0246651\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  71%|#######1  | 5/7 [00:17<00:06,  3.49s/it]\u001b[32m[I 2022-04-22 10:25:36,789]\u001b[0m Trial 4 finished with value: 0.024644775051576195 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  71%|#######1  | 5/7 [00:17<00:06,  3.49s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214249\tValid's rmse: 0.0246652\nEarly stopping, best iteration is:\n[2]\tTrain's rmse: 0.0214582\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066466 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645:  86%|########5 | 6/7 [00:21<00:03,  3.57s/it]\u001b[32m[I 2022-04-22 10:25:40,497]\u001b[0m Trial 5 finished with value: 0.024644748291800075 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645:  86%|########5 | 6/7 [00:21<00:03,  3.57s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214216\tValid's rmse: 0.0246665\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067530 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.024645: 100%|##########| 7/7 [00:25<00:00,  3.62s/it]\u001b[32m[I 2022-04-22 10:25:44,226]\u001b[0m Trial 6 finished with value: 0.02464466028893019 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.02464466028893019.\u001b[0m\nfeature_fraction, val_score: 0.024645: 100%|##########| 7/7 [00:25<00:00,  3.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214222\tValid's rmse: 0.0246653\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214586\tValid's rmse: 0.0246447\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178786 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:   5%|5         | 1/20 [00:05<01:47,  5.64s/it]\u001b[32m[I 2022-04-22 10:25:49,875]\u001b[0m Trial 7 finished with value: 0.024644753202070976 and parameters: {'num_leaves': 32}. Best is trial 7 with value: 0.024644753202070976.\u001b[0m\nnum_leaves, val_score: 0.024645:   5%|5         | 1/20 [00:05<01:47,  5.64s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213879\tValid's rmse: 0.0246676\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214582\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071930 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  10%|#         | 2/20 [00:13<02:05,  6.95s/it]\u001b[32m[I 2022-04-22 10:25:57,739]\u001b[0m Trial 8 finished with value: 0.024644756295401336 and parameters: {'num_leaves': 176}. Best is trial 7 with value: 0.024644753202070976.\u001b[0m\nnum_leaves, val_score: 0.024645:  10%|#         | 2/20 [00:13<02:05,  6.95s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021282\tValid's rmse: 0.0246715\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214569\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  15%|#5        | 3/20 [00:20<01:57,  6.93s/it]\u001b[32m[I 2022-04-22 10:26:04,657]\u001b[0m Trial 9 finished with value: 0.024644654835566514 and parameters: {'num_leaves': 118}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  15%|#5        | 3/20 [00:20<01:57,  6.93s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213154\tValid's rmse: 0.0246704\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214574\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066991 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  20%|##        | 4/20 [00:28<01:55,  7.25s/it]\u001b[32m[I 2022-04-22 10:26:12,389]\u001b[0m Trial 10 finished with value: 0.024644806265342174 and parameters: {'num_leaves': 168}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  20%|##        | 4/20 [00:28<01:55,  7.25s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212865\tValid's rmse: 0.0246707\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021457\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065366 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  25%|##5       | 5/20 [00:33<01:39,  6.61s/it]\u001b[32m[I 2022-04-22 10:26:17,873]\u001b[0m Trial 11 finished with value: 0.024644717931156933 and parameters: {'num_leaves': 49}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  25%|##5       | 5/20 [00:33<01:39,  6.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213695\tValid's rmse: 0.0246683\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021458\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167361 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  30%|###       | 6/20 [00:39<01:29,  6.41s/it]\u001b[32m[I 2022-04-22 10:26:23,883]\u001b[0m Trial 12 finished with value: 0.02464474115160017 and parameters: {'num_leaves': 55}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  30%|###       | 6/20 [00:39<01:29,  6.41s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213641\tValid's rmse: 0.0246691\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214579\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072958 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  35%|###5      | 7/20 [00:46<01:24,  6.51s/it]\u001b[32m[I 2022-04-22 10:26:30,603]\u001b[0m Trial 13 finished with value: 0.024644794182855846 and parameters: {'num_leaves': 101}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  35%|###5      | 7/20 [00:46<01:24,  6.51s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213267\tValid's rmse: 0.024671\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214575\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  40%|####      | 8/20 [00:53<01:18,  6.57s/it]\u001b[32m[I 2022-04-22 10:26:37,300]\u001b[0m Trial 14 finished with value: 0.024644742554268097 and parameters: {'num_leaves': 107}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  40%|####      | 8/20 [00:53<01:18,  6.57s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021323\tValid's rmse: 0.0246706\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214575\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065819 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  45%|####5     | 9/20 [01:00<01:16,  6.95s/it]\u001b[32m[I 2022-04-22 10:26:45,100]\u001b[0m Trial 15 finished with value: 0.02464478430784363 and parameters: {'num_leaves': 157}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  45%|####5     | 9/20 [01:00<01:16,  6.95s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212924\tValid's rmse: 0.0246711\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.021457\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066749 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  50%|#####     | 10/20 [01:09<01:14,  7.40s/it]\u001b[32m[I 2022-04-22 10:26:53,514]\u001b[0m Trial 16 finished with value: 0.024644763409307654 and parameters: {'num_leaves': 154}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  50%|#####     | 10/20 [01:09<01:14,  7.40s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021294\tValid's rmse: 0.0246702\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214571\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068326 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  55%|#####5    | 11/20 [01:18<01:10,  7.85s/it]\u001b[32m[I 2022-04-22 10:27:02,391]\u001b[0m Trial 17 finished with value: 0.024644755185227633 and parameters: {'num_leaves': 243}. Best is trial 9 with value: 0.024644654835566514.\u001b[0m\nnum_leaves, val_score: 0.024645:  55%|#####5    | 11/20 [01:18<01:10,  7.85s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212493\tValid's rmse: 0.0246703\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214566\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092249 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  60%|######    | 12/20 [01:22<00:54,  6.85s/it]\u001b[32m[I 2022-04-22 10:27:06,944]\u001b[0m Trial 18 finished with value: 0.02464461324977589 and parameters: {'num_leaves': 5}. Best is trial 18 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  60%|######    | 12/20 [01:22<00:54,  6.85s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214365\tValid's rmse: 0.0246646\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214587\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066337 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  65%|######5   | 13/20 [01:26<00:41,  5.99s/it]\u001b[32m[I 2022-04-22 10:27:10,968]\u001b[0m Trial 19 finished with value: 0.024644646606393223 and parameters: {'num_leaves': 16}. Best is trial 18 with value: 0.02464461324977589.\u001b[0m\nnum_leaves, val_score: 0.024645:  65%|######5   | 13/20 [01:26<00:41,  5.99s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214111\tValid's rmse: 0.0246654\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214585\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066882 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  70%|#######   | 14/20 [01:29<00:29,  4.91s/it]\u001b[32m[I 2022-04-22 10:27:13,370]\u001b[0m Trial 20 finished with value: 0.02464460660884138 and parameters: {'num_leaves': 2}. Best is trial 20 with value: 0.02464460660884138.\u001b[0m\nnum_leaves, val_score: 0.024645:  70%|#######   | 14/20 [01:29<00:29,  4.91s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214491\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067201 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  75%|#######5  | 15/20 [01:31<00:20,  4.14s/it]\u001b[32m[I 2022-04-22 10:27:15,730]\u001b[0m Trial 21 finished with value: 0.02464460660884138 and parameters: {'num_leaves': 2}. Best is trial 20 with value: 0.02464460660884138.\u001b[0m\nnum_leaves, val_score: 0.024645:  75%|#######5  | 15/20 [01:31<00:20,  4.14s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214491\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064628 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  80%|########  | 16/20 [01:37<00:18,  4.74s/it]\u001b[32m[I 2022-04-22 10:27:21,856]\u001b[0m Trial 22 finished with value: 0.02464475608548873 and parameters: {'num_leaves': 76}. Best is trial 20 with value: 0.02464460660884138.\u001b[0m\nnum_leaves, val_score: 0.024645:  80%|########  | 16/20 [01:37<00:18,  4.74s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021346\tValid's rmse: 0.0246693\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214577\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  85%|########5 | 17/20 [01:44<00:16,  5.43s/it]\u001b[32m[I 2022-04-22 10:27:28,887]\u001b[0m Trial 23 finished with value: 0.02464475171452222 and parameters: {'num_leaves': 75}. Best is trial 20 with value: 0.02464460660884138.\u001b[0m\nnum_leaves, val_score: 0.024645:  85%|########5 | 17/20 [01:44<00:16,  5.43s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213464\tValid's rmse: 0.0246693\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214577\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064638 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  90%|######### | 18/20 [01:47<00:09,  4.60s/it]\u001b[32m[I 2022-04-22 10:27:31,576]\u001b[0m Trial 24 finished with value: 0.0246448003182596 and parameters: {'num_leaves': 3}. Best is trial 20 with value: 0.02464460660884138.\u001b[0m\nnum_leaves, val_score: 0.024645:  90%|######### | 18/20 [01:47<00:09,  4.60s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.021444\tValid's rmse: 0.0246629\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214588\tValid's rmse: 0.0246448\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066835 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645:  95%|#########5| 19/20 [01:55<00:05,  5.76s/it]\u001b[32m[I 2022-04-22 10:27:40,037]\u001b[0m Trial 25 finished with value: 0.024644712009670312 and parameters: {'num_leaves': 219}. Best is trial 20 with value: 0.02464460660884138.\u001b[0m\nnum_leaves, val_score: 0.024645:  95%|#########5| 19/20 [01:55<00:05,  5.76s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0212602\tValid's rmse: 0.0246719\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214567\tValid's rmse: 0.0246447\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066366 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024645: 100%|##########| 20/20 [02:00<00:00,  5.57s/it]\u001b[32m[I 2022-04-22 10:27:45,157]\u001b[0m Trial 26 finished with value: 0.02464473311807478 and parameters: {'num_leaves': 39}. Best is trial 20 with value: 0.02464460660884138.\u001b[0m\nnum_leaves, val_score: 0.024645: 100%|##########| 20/20 [02:00<00:00,  6.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0213799\tValid's rmse: 0.0246676\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214581\tValid's rmse: 0.0246447\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068902 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  10%|#         | 1/10 [00:02<00:23,  2.59s/it]\u001b[32m[I 2022-04-22 10:27:47,753]\u001b[0m Trial 27 finished with value: 0.02464459571013833 and parameters: {'bagging_fraction': 0.5114002573808117, 'bagging_freq': 3}. Best is trial 27 with value: 0.02464459571013833.\u001b[0m\nbagging, val_score: 0.024645:  10%|#         | 1/10 [00:02<00:23,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214491\tValid's rmse: 0.024656\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078779 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  20%|##        | 2/10 [00:05<00:20,  2.61s/it]\u001b[32m[I 2022-04-22 10:27:50,373]\u001b[0m Trial 28 finished with value: 0.02464456458892424 and parameters: {'bagging_fraction': 0.6451385381339313, 'bagging_freq': 3}. Best is trial 28 with value: 0.02464456458892424.\u001b[0m\nbagging, val_score: 0.024645:  20%|##        | 2/10 [00:05<00:20,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0246556\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065644 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  30%|###       | 3/10 [00:07<00:17,  2.55s/it]\u001b[32m[I 2022-04-22 10:27:52,861]\u001b[0m Trial 29 finished with value: 0.024644630268866173 and parameters: {'bagging_fraction': 0.7168935061130917, 'bagging_freq': 7}. Best is trial 28 with value: 0.02464456458892424.\u001b[0m\nbagging, val_score: 0.024645:  30%|###       | 3/10 [00:07<00:17,  2.55s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214494\tValid's rmse: 0.0246551\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  40%|####      | 4/10 [00:10<00:14,  2.50s/it]\u001b[32m[I 2022-04-22 10:27:55,276]\u001b[0m Trial 30 finished with value: 0.024644569396373887 and parameters: {'bagging_fraction': 0.6493904786290938, 'bagging_freq': 7}. Best is trial 28 with value: 0.02464456458892424.\u001b[0m\nbagging, val_score: 0.024645:  40%|####      | 4/10 [00:10<00:14,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0246543\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  50%|#####     | 5/10 [00:13<00:14,  2.85s/it]\u001b[32m[I 2022-04-22 10:27:58,739]\u001b[0m Trial 31 finished with value: 0.02464463207439274 and parameters: {'bagging_fraction': 0.79562635660133, 'bagging_freq': 5}. Best is trial 28 with value: 0.02464456458892424.\u001b[0m\nbagging, val_score: 0.024645:  50%|#####     | 5/10 [00:13<00:14,  2.85s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0246557\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066469 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  60%|######    | 6/10 [00:16<00:11,  2.76s/it]\u001b[32m[I 2022-04-22 10:28:01,342]\u001b[0m Trial 32 finished with value: 0.0246445624769911 and parameters: {'bagging_fraction': 0.6187936823756897, 'bagging_freq': 1}. Best is trial 32 with value: 0.0246445624769911.\u001b[0m\nbagging, val_score: 0.024645:  60%|######    | 6/10 [00:16<00:11,  2.76s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246553\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067580 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  70%|#######   | 7/10 [00:18<00:07,  2.65s/it]\u001b[32m[I 2022-04-22 10:28:03,748]\u001b[0m Trial 33 finished with value: 0.0246445702775208 and parameters: {'bagging_fraction': 0.6571997848175954, 'bagging_freq': 7}. Best is trial 32 with value: 0.0246445624769911.\u001b[0m\nbagging, val_score: 0.024645:  70%|#######   | 7/10 [00:18<00:07,  2.65s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0246547\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065315 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  80%|########  | 8/10 [00:20<00:05,  2.52s/it]\u001b[32m[I 2022-04-22 10:28:05,998]\u001b[0m Trial 34 finished with value: 0.024644600118023288 and parameters: {'bagging_fraction': 0.4755232877488127, 'bagging_freq': 7}. Best is trial 32 with value: 0.0246445624769911.\u001b[0m\nbagging, val_score: 0.024645:  80%|########  | 8/10 [00:20<00:05,  2.52s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246544\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067384 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645:  90%|######### | 9/10 [00:23<00:02,  2.50s/it]\u001b[32m[I 2022-04-22 10:28:08,447]\u001b[0m Trial 35 finished with value: 0.02464459120060256 and parameters: {'bagging_fraction': 0.5714947364405978, 'bagging_freq': 4}. Best is trial 32 with value: 0.0246445624769911.\u001b[0m\nbagging, val_score: 0.024645:  90%|######### | 9/10 [00:23<00:02,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.024656\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066494 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024645: 100%|##########| 10/10 [00:25<00:00,  2.52s/it]\u001b[32m[I 2022-04-22 10:28:11,008]\u001b[0m Trial 36 finished with value: 0.024644623443368107 and parameters: {'bagging_fraction': 0.8451110090104641, 'bagging_freq': 6}. Best is trial 32 with value: 0.0246445624769911.\u001b[0m\nbagging, val_score: 0.024645: 100%|##########| 10/10 [00:25<00:00,  2.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214494\tValid's rmse: 0.0246558\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:   0%|          | 0/6 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065416 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  17%|#6        | 1/6 [00:02<00:13,  2.65s/it]\u001b[32m[I 2022-04-22 10:28:13,667]\u001b[0m Trial 37 finished with value: 0.0246445624769911 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 0.0246445624769911.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  17%|#6        | 1/6 [00:02<00:13,  2.65s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246551\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064749 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  33%|###3      | 2/6 [00:05<00:10,  2.63s/it]\u001b[32m[I 2022-04-22 10:28:16,285]\u001b[0m Trial 38 finished with value: 0.0246445624769911 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 37 with value: 0.0246445624769911.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  33%|###3      | 2/6 [00:05<00:10,  2.63s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0246552\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064411 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  50%|#####     | 3/6 [00:07<00:07,  2.65s/it]\u001b[32m[I 2022-04-22 10:28:18,954]\u001b[0m Trial 39 finished with value: 0.0246445624769911 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.0246445624769911.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  50%|#####     | 3/6 [00:07<00:07,  2.65s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0246552\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065389 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  67%|######6   | 4/6 [00:10<00:05,  2.62s/it]\u001b[32m[I 2022-04-22 10:28:21,541]\u001b[0m Trial 40 finished with value: 0.0246445624769911 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.0246445624769911.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  67%|######6   | 4/6 [00:10<00:05,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0246551\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065267 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645:  83%|########3 | 5/6 [00:13<00:02,  2.62s/it]\u001b[32m[I 2022-04-22 10:28:24,153]\u001b[0m Trial 41 finished with value: 0.0246445624769911 and parameters: {'feature_fraction': 0.716}. Best is trial 37 with value: 0.0246445624769911.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645:  83%|########3 | 5/6 [00:13<00:02,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246553\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024645: 100%|##########| 6/6 [00:15<00:00,  2.60s/it]\u001b[32m[I 2022-04-22 10:28:26,727]\u001b[0m Trial 42 finished with value: 0.0246445624769911 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 0.0246445624769911.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024645: 100%|##########| 6/6 [00:15<00:00,  2.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246551\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065735 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:   5%|5         | 1/20 [00:02<00:50,  2.65s/it]\u001b[32m[I 2022-04-22 10:28:29,387]\u001b[0m Trial 43 finished with value: 0.024644563811529633 and parameters: {'lambda_l1': 0.0004130630700983366, 'lambda_l2': 7.433641459109173e-06}. Best is trial 43 with value: 0.024644563811529633.\u001b[0m\nregularization_factors, val_score: 0.024645:   5%|5         | 1/20 [00:02<00:50,  2.65s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131707 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  10%|#         | 2/20 [00:05<00:51,  2.87s/it]\u001b[32m[I 2022-04-22 10:28:32,416]\u001b[0m Trial 44 finished with value: 0.024644563752843286 and parameters: {'lambda_l1': 0.02241479800381879, 'lambda_l2': 2.394188630515334e-05}. Best is trial 44 with value: 0.024644563752843286.\u001b[0m\nregularization_factors, val_score: 0.024645:  10%|#         | 2/20 [00:05<00:51,  2.87s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246554\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064923 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  15%|#5        | 3/20 [00:08<00:46,  2.74s/it]\u001b[32m[I 2022-04-22 10:28:35,003]\u001b[0m Trial 45 finished with value: 0.024644563812631068 and parameters: {'lambda_l1': 1.2104163190429043e-07, 'lambda_l2': 1.056951075520666e-06}. Best is trial 44 with value: 0.024644563752843286.\u001b[0m\nregularization_factors, val_score: 0.024645:  15%|#5        | 3/20 [00:08<00:46,  2.74s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064490 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  20%|##        | 4/20 [00:10<00:42,  2.68s/it]\u001b[32m[I 2022-04-22 10:28:37,594]\u001b[0m Trial 46 finished with value: 0.024644563792168103 and parameters: {'lambda_l1': 0.007660166657735787, 'lambda_l2': 0.007632986383679702}. Best is trial 44 with value: 0.024644563752843286.\u001b[0m\nregularization_factors, val_score: 0.024645:  20%|##        | 4/20 [00:10<00:42,  2.68s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064366 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  25%|##5       | 5/20 [00:13<00:40,  2.68s/it]\u001b[32m[I 2022-04-22 10:28:40,276]\u001b[0m Trial 47 finished with value: 0.024644563241769953 and parameters: {'lambda_l1': 0.21402076608099063, 'lambda_l2': 0.00025672830978093914}. Best is trial 47 with value: 0.024644563241769953.\u001b[0m\nregularization_factors, val_score: 0.024645:  25%|##5       | 5/20 [00:13<00:40,  2.68s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246554\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064575 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  30%|###       | 6/20 [00:16<00:37,  2.65s/it]\u001b[32m[I 2022-04-22 10:28:42,861]\u001b[0m Trial 48 finished with value: 0.024644563806646164 and parameters: {'lambda_l1': 0.0022438847745546975, 'lambda_l2': 1.8210634562222411e-06}. Best is trial 47 with value: 0.024644563241769953.\u001b[0m\nregularization_factors, val_score: 0.024645:  30%|###       | 6/20 [00:16<00:37,  2.65s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064769 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  35%|###5      | 7/20 [00:18<00:34,  2.63s/it]\u001b[32m[I 2022-04-22 10:28:45,454]\u001b[0m Trial 49 finished with value: 0.024644557606156876 and parameters: {'lambda_l1': 2.327121917716705, 'lambda_l2': 0.043007244952217576}. Best is trial 49 with value: 0.024644557606156876.\u001b[0m\nregularization_factors, val_score: 0.024645:  35%|###5      | 7/20 [00:18<00:34,  2.63s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214494\tValid's rmse: 0.0246547\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064885 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  40%|####      | 8/20 [00:21<00:31,  2.62s/it]\u001b[32m[I 2022-04-22 10:28:48,038]\u001b[0m Trial 50 finished with value: 0.02464456381263129 and parameters: {'lambda_l1': 3.7173964513995045e-08, 'lambda_l2': 5.288112505459096e-08}. Best is trial 49 with value: 0.024644557606156876.\u001b[0m\nregularization_factors, val_score: 0.024645:  40%|####      | 8/20 [00:21<00:31,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064448 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  45%|####5     | 9/20 [00:23<00:28,  2.61s/it]\u001b[32m[I 2022-04-22 10:28:50,638]\u001b[0m Trial 51 finished with value: 0.024644561391666653 and parameters: {'lambda_l1': 0.9076826163360023, 'lambda_l2': 3.6988108126404856e-05}. Best is trial 49 with value: 0.024644557606156876.\u001b[0m\nregularization_factors, val_score: 0.024645:  45%|####5     | 9/20 [00:23<00:28,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214493\tValid's rmse: 0.024655\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065758 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  50%|#####     | 10/20 [00:26<00:26,  2.62s/it]\u001b[32m[I 2022-04-22 10:28:53,284]\u001b[0m Trial 52 finished with value: 0.024644563812482114 and parameters: {'lambda_l1': 5.591804297715733e-05, 'lambda_l2': 1.7601254872426864e-05}. Best is trial 49 with value: 0.024644557606156876.\u001b[0m\nregularization_factors, val_score: 0.024645:  50%|#####     | 10/20 [00:26<00:26,  2.62s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064172 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  55%|#####5    | 11/20 [00:29<00:23,  2.61s/it]\u001b[32m[I 2022-04-22 10:28:55,871]\u001b[0m Trial 53 finished with value: 0.024644552631074495 and parameters: {'lambda_l1': 4.186154741710398, 'lambda_l2': 4.994072046099937}. Best is trial 53 with value: 0.024644552631074495.\u001b[0m\nregularization_factors, val_score: 0.024645:  55%|#####5    | 11/20 [00:29<00:23,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214496\tValid's rmse: 0.0246544\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065223 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  60%|######    | 12/20 [00:31<00:20,  2.61s/it]\u001b[32m[I 2022-04-22 10:28:58,468]\u001b[0m Trial 54 finished with value: 0.02464454588704492 and parameters: {'lambda_l1': 6.713960280961634, 'lambda_l2': 7.035497591616901}. Best is trial 54 with value: 0.02464454588704492.\u001b[0m\nregularization_factors, val_score: 0.024645:  60%|######    | 12/20 [00:31<00:20,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.02145\tValid's rmse: 0.024654\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064622 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  65%|######5   | 13/20 [00:34<00:18,  2.61s/it]\u001b[32m[I 2022-04-22 10:29:01,092]\u001b[0m Trial 55 finished with value: 0.024644552621941807 and parameters: {'lambda_l1': 4.191922681113618, 'lambda_l2': 3.3237091448926073}. Best is trial 54 with value: 0.02464454588704492.\u001b[0m\nregularization_factors, val_score: 0.024645:  65%|######5   | 13/20 [00:34<00:18,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214496\tValid's rmse: 0.0246544\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064308 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  70%|#######   | 14/20 [00:37<00:17,  2.90s/it]\u001b[32m[I 2022-04-22 10:29:04,654]\u001b[0m Trial 56 finished with value: 0.02464456378725999 and parameters: {'lambda_l1': 6.062185924465913e-06, 'lambda_l2': 6.254268848397663}. Best is trial 54 with value: 0.02464454588704492.\u001b[0m\nregularization_factors, val_score: 0.024645:  70%|#######   | 14/20 [00:37<00:17,  2.90s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066849 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  75%|#######5  | 15/20 [00:40<00:14,  2.82s/it]\u001b[32m[I 2022-04-22 10:29:07,276]\u001b[0m Trial 57 finished with value: 0.024644537238335564 and parameters: {'lambda_l1': 9.969082098531311, 'lambda_l2': 0.17053673445076165}. Best is trial 57 with value: 0.024644537238335564.\u001b[0m\nregularization_factors, val_score: 0.024645:  75%|#######5  | 15/20 [00:40<00:14,  2.82s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214503\tValid's rmse: 0.0246531\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066557 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  80%|########  | 16/20 [00:43<00:10,  2.74s/it]\u001b[32m[I 2022-04-22 10:29:09,852]\u001b[0m Trial 58 finished with value: 0.024644563582141985 and parameters: {'lambda_l1': 0.0862087212766845, 'lambda_l2': 0.13386289738754548}. Best is trial 57 with value: 0.024644537238335564.\u001b[0m\nregularization_factors, val_score: 0.024645:  80%|########  | 16/20 [00:43<00:10,  2.74s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246554\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064334 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  85%|########5 | 17/20 [00:45<00:08,  2.70s/it]\u001b[32m[I 2022-04-22 10:29:12,455]\u001b[0m Trial 59 finished with value: 0.024644563227650965 and parameters: {'lambda_l1': 0.2188721140748308, 'lambda_l2': 0.29224676650846954}. Best is trial 57 with value: 0.024644537238335564.\u001b[0m\nregularization_factors, val_score: 0.024645:  85%|########5 | 17/20 [00:45<00:08,  2.70s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246554\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  90%|######### | 18/20 [00:48<00:05,  2.78s/it]\u001b[32m[I 2022-04-22 10:29:15,416]\u001b[0m Trial 60 finished with value: 0.02464454322386934 and parameters: {'lambda_l1': 7.7226917823610775, 'lambda_l2': 0.005542402125597941}. Best is trial 57 with value: 0.024644537238335564.\u001b[0m\nregularization_factors, val_score: 0.024645:  90%|######### | 18/20 [00:48<00:05,  2.78s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214501\tValid's rmse: 0.0246537\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064431 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645:  95%|#########5| 19/20 [00:51<00:02,  2.74s/it]\u001b[32m[I 2022-04-22 10:29:18,059]\u001b[0m Trial 61 finished with value: 0.024644563812599957 and parameters: {'lambda_l1': 6.303506751725814e-06, 'lambda_l2': 0.0036016879557130015}. Best is trial 57 with value: 0.024644537238335564.\u001b[0m\nregularization_factors, val_score: 0.024645:  95%|#########5| 19/20 [00:51<00:02,  2.74s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246555\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024645: 100%|##########| 20/20 [00:53<00:00,  2.70s/it]\u001b[32m[I 2022-04-22 10:29:20,676]\u001b[0m Trial 62 finished with value: 0.02464456277930417 and parameters: {'lambda_l1': 0.38740500040298054, 'lambda_l2': 0.002057577906955475}. Best is trial 57 with value: 0.024644537238335564.\u001b[0m\nregularization_factors, val_score: 0.024645: 100%|##########| 20/20 [00:53<00:00,  2.70s/it]\n","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214492\tValid's rmse: 0.0246554\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246446\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066422 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  20%|##        | 1/5 [00:02<00:10,  2.61s/it]\u001b[32m[I 2022-04-22 10:29:23,289]\u001b[0m Trial 63 finished with value: 0.024644537238335564 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.024644537238335564.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  20%|##        | 1/5 [00:02<00:10,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214503\tValid's rmse: 0.0246531\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065733 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  40%|####      | 2/5 [00:05<00:07,  2.61s/it]\u001b[32m[I 2022-04-22 10:29:25,897]\u001b[0m Trial 64 finished with value: 0.024644537238335564 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.024644537238335564.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  40%|####      | 2/5 [00:05<00:07,  2.61s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214503\tValid's rmse: 0.0246531\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065130 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  60%|######    | 3/5 [00:07<00:05,  2.60s/it]\u001b[32m[I 2022-04-22 10:29:28,478]\u001b[0m Trial 65 finished with value: 0.024644537238335564 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.024644537238335564.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  60%|######    | 3/5 [00:07<00:05,  2.60s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214503\tValid's rmse: 0.0246531\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645:  80%|########  | 4/5 [00:10<00:02,  2.59s/it]\u001b[32m[I 2022-04-22 10:29:31,070]\u001b[0m Trial 66 finished with value: 0.024644537238335564 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.024644537238335564.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645:  80%|########  | 4/5 [00:10<00:02,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214503\tValid's rmse: 0.0246531\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416216, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000742\nTraining until validation scores don't improve for 100 rounds\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024645: 100%|##########| 5/5 [00:12<00:00,  2.59s/it]\u001b[32m[I 2022-04-22 10:29:33,653]\u001b[0m Trial 67 finished with value: 0.024644537238335564 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.024644537238335564.\u001b[0m\nmin_data_in_leaf, val_score: 0.024645: 100%|##########| 5/5 [00:12<00:00,  2.59s/it]","output_type":"stream"},{"name":"stdout","text":"[100]\tTrain's rmse: 0.0214503\tValid's rmse: 0.0246531\nEarly stopping, best iteration is:\n[1]\tTrain's rmse: 0.0214589\tValid's rmse: 0.0246445\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"sharpe_ratio: -0.23873907750834863\nscore 0: -0.23873907750834863\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-04-22 10:29:34,763]\u001b[0m A new study created in memory with name: no-name-68673aa1-7c9a-483e-b4d7-c7b920017883\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060167 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217852\tValid's rmse: 0.0222319\n[200]\tTrain's rmse: 0.0217624\tValid's rmse: 0.0222186\n[300]\tTrain's rmse: 0.0217442\tValid's rmse: 0.022214\n[400]\tTrain's rmse: 0.0217283\tValid's rmse: 0.0222098\n[500]\tTrain's rmse: 0.0217154\tValid's rmse: 0.0222068\n[600]\tTrain's rmse: 0.0217015\tValid's rmse: 0.0222059\n[700]\tTrain's rmse: 0.0216902\tValid's rmse: 0.0222074\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022205:  14%|#4        | 1/7 [00:15<01:31, 15.25s/it]\u001b[32m[I 2022-04-22 10:29:50,018]\u001b[0m Trial 0 finished with value: 0.022204817766049826 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.022204817766049826.\u001b[0m\nfeature_fraction, val_score: 0.022205:  14%|#4        | 1/7 [00:15<01:31, 15.25s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[615]\tTrain's rmse: 0.0216997\tValid's rmse: 0.0222048\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007375 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217884\tValid's rmse: 0.0222347\n[200]\tTrain's rmse: 0.0217667\tValid's rmse: 0.0222209\n[300]\tTrain's rmse: 0.0217496\tValid's rmse: 0.0222173\n[400]\tTrain's rmse: 0.0217346\tValid's rmse: 0.0222124\n[500]\tTrain's rmse: 0.0217221\tValid's rmse: 0.0222094\n[600]\tTrain's rmse: 0.0217098\tValid's rmse: 0.0222082\n[700]\tTrain's rmse: 0.021699\tValid's rmse: 0.0222082\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022205:  29%|##8       | 2/7 [00:30<01:17, 15.45s/it]\u001b[32m[I 2022-04-22 10:30:05,607]\u001b[0m Trial 1 finished with value: 0.022206435416118445 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.022204817766049826.\u001b[0m\nfeature_fraction, val_score: 0.022205:  29%|##8       | 2/7 [00:30<01:17, 15.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[640]\tTrain's rmse: 0.0217051\tValid's rmse: 0.0222064\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061479 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217865\tValid's rmse: 0.0222314\n[200]\tTrain's rmse: 0.021764\tValid's rmse: 0.0222184\n[300]\tTrain's rmse: 0.0217463\tValid's rmse: 0.0222158\n[400]\tTrain's rmse: 0.0217306\tValid's rmse: 0.0222103\n[500]\tTrain's rmse: 0.0217182\tValid's rmse: 0.0222076\n[600]\tTrain's rmse: 0.0217051\tValid's rmse: 0.0222077\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022205:  43%|####2     | 3/7 [00:46<01:01, 15.36s/it]\u001b[32m[I 2022-04-22 10:30:20,867]\u001b[0m Trial 2 finished with value: 0.02220665002658414 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.022204817766049826.\u001b[0m\nfeature_fraction, val_score: 0.022205:  43%|####2     | 3/7 [00:46<01:01, 15.36s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[592]\tTrain's rmse: 0.021706\tValid's rmse: 0.0222067\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064995 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217827\tValid's rmse: 0.0222294\n[200]\tTrain's rmse: 0.0217587\tValid's rmse: 0.0222156\n[300]\tTrain's rmse: 0.0217397\tValid's rmse: 0.0222131\n[400]\tTrain's rmse: 0.0217231\tValid's rmse: 0.0222082\n[500]\tTrain's rmse: 0.0217091\tValid's rmse: 0.0222043\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022204:  57%|#####7    | 4/7 [00:59<00:43, 14.47s/it]\u001b[32m[I 2022-04-22 10:30:33,979]\u001b[0m Trial 3 finished with value: 0.02220394426166143 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.02220394426166143.\u001b[0m\nfeature_fraction, val_score: 0.022204:  57%|#####7    | 4/7 [00:59<00:43, 14.47s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0217147\tValid's rmse: 0.0222039\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065876 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217825\tValid's rmse: 0.0222296\n[200]\tTrain's rmse: 0.0217581\tValid's rmse: 0.0222158\n[300]\tTrain's rmse: 0.0217389\tValid's rmse: 0.0222136\n[400]\tTrain's rmse: 0.0217219\tValid's rmse: 0.0222084\n[500]\tTrain's rmse: 0.0217072\tValid's rmse: 0.0222055\n[600]\tTrain's rmse: 0.0216931\tValid's rmse: 0.0222052\n[700]\tTrain's rmse: 0.0216812\tValid's rmse: 0.0222042\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022204:  71%|#######1  | 5/7 [01:16<00:31, 15.50s/it]\u001b[32m[I 2022-04-22 10:30:51,310]\u001b[0m Trial 4 finished with value: 0.022203791174335248 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.022203791174335248.\u001b[0m\nfeature_fraction, val_score: 0.022204:  71%|#######1  | 5/7 [01:16<00:31, 15.50s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[627]\tTrain's rmse: 0.0216896\tValid's rmse: 0.0222038\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065797 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217841\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217603\tValid's rmse: 0.022215\n[300]\tTrain's rmse: 0.0217418\tValid's rmse: 0.0222126\n[400]\tTrain's rmse: 0.0217253\tValid's rmse: 0.022207\n[500]\tTrain's rmse: 0.0217113\tValid's rmse: 0.0222046\n[600]\tTrain's rmse: 0.0216971\tValid's rmse: 0.0222042\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022203:  86%|########5 | 6/7 [01:30<00:15, 15.06s/it]\u001b[32m[I 2022-04-22 10:31:05,498]\u001b[0m Trial 5 finished with value: 0.022203108817092025 and parameters: {'feature_fraction': 0.7}. Best is trial 5 with value: 0.022203108817092025.\u001b[0m\nfeature_fraction, val_score: 0.022203:  86%|########5 | 6/7 [01:30<00:15, 15.06s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[534]\tTrain's rmse: 0.0217066\tValid's rmse: 0.0222031\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072594 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217822\tValid's rmse: 0.0222299\n[200]\tTrain's rmse: 0.0217586\tValid's rmse: 0.0222166\n[300]\tTrain's rmse: 0.0217392\tValid's rmse: 0.0222129\n[400]\tTrain's rmse: 0.0217219\tValid's rmse: 0.022208\n[500]\tTrain's rmse: 0.0217069\tValid's rmse: 0.0222033\n[600]\tTrain's rmse: 0.0216923\tValid's rmse: 0.0222049\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.022201: 100%|##########| 7/7 [01:46<00:00, 15.33s/it]\u001b[32m[I 2022-04-22 10:31:21,377]\u001b[0m Trial 6 finished with value: 0.02220132591417371 and parameters: {'feature_fraction': 1.0}. Best is trial 6 with value: 0.02220132591417371.\u001b[0m\nfeature_fraction, val_score: 0.022201: 100%|##########| 7/7 [01:46<00:00, 15.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[525]\tTrain's rmse: 0.0217033\tValid's rmse: 0.0222013\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215859\tValid's rmse: 0.0222297\n[200]\tTrain's rmse: 0.0213987\tValid's rmse: 0.0222306\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:   5%|5         | 1/20 [00:18<05:50, 18.46s/it]\u001b[32m[I 2022-04-22 10:31:39,840]\u001b[0m Trial 7 finished with value: 0.02222725025745653 and parameters: {'num_leaves': 244}. Best is trial 7 with value: 0.02222725025745653.\u001b[0m\nnum_leaves, val_score: 0.022201:   5%|5         | 1/20 [00:18<05:50, 18.46s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[104]\tTrain's rmse: 0.0215776\tValid's rmse: 0.0222273\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066545 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216772\tValid's rmse: 0.0222208\n[200]\tTrain's rmse: 0.0215695\tValid's rmse: 0.0222147\n[300]\tTrain's rmse: 0.0214801\tValid's rmse: 0.0222195\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  10%|#         | 2/20 [00:38<05:50, 19.45s/it]\u001b[32m[I 2022-04-22 10:31:59,979]\u001b[0m Trial 8 finished with value: 0.02221338519719115 and parameters: {'num_leaves': 97}. Best is trial 8 with value: 0.02221338519719115.\u001b[0m\nnum_leaves, val_score: 0.022201:  10%|#         | 2/20 [00:38<05:50, 19.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[206]\tTrain's rmse: 0.0215636\tValid's rmse: 0.0222134\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068841 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216436\tValid's rmse: 0.0222291\n[200]\tTrain's rmse: 0.0215061\tValid's rmse: 0.0222238\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  15%|#5        | 3/20 [01:00<05:51, 20.67s/it]\u001b[32m[I 2022-04-22 10:32:22,103]\u001b[0m Trial 9 finished with value: 0.022223439915722835 and parameters: {'num_leaves': 142}. Best is trial 8 with value: 0.02221338519719115.\u001b[0m\nnum_leaves, val_score: 0.022201:  15%|#5        | 3/20 [01:00<05:51, 20.67s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[195]\tTrain's rmse: 0.0215119\tValid's rmse: 0.0222234\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067306 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216044\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0214319\tValid's rmse: 0.0222255\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  20%|##        | 4/20 [01:25<05:56, 22.30s/it]\u001b[32m[I 2022-04-22 10:32:46,913]\u001b[0m Trial 10 finished with value: 0.022225543511949032 and parameters: {'num_leaves': 210}. Best is trial 8 with value: 0.02221338519719115.\u001b[0m\nnum_leaves, val_score: 0.022201:  20%|##        | 4/20 [01:25<05:56, 22.30s/it]","output_type":"stream"},{"name":"stdout","text":"[300]\tTrain's rmse: 0.0212824\tValid's rmse: 0.0222403\nEarly stopping, best iteration is:\n[200]\tTrain's rmse: 0.0214319\tValid's rmse: 0.0222255\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216572\tValid's rmse: 0.0222258\n[200]\tTrain's rmse: 0.0215328\tValid's rmse: 0.0222179\n[300]\tTrain's rmse: 0.0214289\tValid's rmse: 0.0222239\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  25%|##5       | 5/20 [01:47<05:30, 22.02s/it]\u001b[32m[I 2022-04-22 10:33:08,428]\u001b[0m Trial 11 finished with value: 0.022216585287855906 and parameters: {'num_leaves': 123}. Best is trial 8 with value: 0.02221338519719115.\u001b[0m\nnum_leaves, val_score: 0.022201:  25%|##5       | 5/20 [01:47<05:30, 22.02s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[205]\tTrain's rmse: 0.0215271\tValid's rmse: 0.0222166\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066786 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215948\tValid's rmse: 0.0222313\n[200]\tTrain's rmse: 0.0214143\tValid's rmse: 0.0222296\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  30%|###       | 6/20 [02:09<05:09, 22.10s/it]\u001b[32m[I 2022-04-22 10:33:30,697]\u001b[0m Trial 12 finished with value: 0.022228029838797556 and parameters: {'num_leaves': 227}. Best is trial 8 with value: 0.02221338519719115.\u001b[0m\nnum_leaves, val_score: 0.022201:  30%|###       | 6/20 [02:09<05:09, 22.10s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[147]\tTrain's rmse: 0.0215069\tValid's rmse: 0.022228\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066949 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215935\tValid's rmse: 0.0222295\n[200]\tTrain's rmse: 0.0214133\tValid's rmse: 0.0222281\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  35%|###5      | 7/20 [02:27<04:30, 20.79s/it]\u001b[32m[I 2022-04-22 10:33:48,795]\u001b[0m Trial 13 finished with value: 0.022226124654717655 and parameters: {'num_leaves': 229}. Best is trial 8 with value: 0.02221338519719115.\u001b[0m\nnum_leaves, val_score: 0.022201:  35%|###5      | 7/20 [02:27<04:30, 20.79s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[105]\tTrain's rmse: 0.0215835\tValid's rmse: 0.0222261\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069885 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217652\tValid's rmse: 0.0222219\n[200]\tTrain's rmse: 0.0217285\tValid's rmse: 0.0222114\n[300]\tTrain's rmse: 0.0217009\tValid's rmse: 0.0222125\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  40%|####      | 8/20 [02:38<03:32, 17.69s/it]\u001b[32m[I 2022-04-22 10:33:59,824]\u001b[0m Trial 14 finished with value: 0.022209699147808036 and parameters: {'num_leaves': 18}. Best is trial 14 with value: 0.022209699147808036.\u001b[0m\nnum_leaves, val_score: 0.022201:  40%|####      | 8/20 [02:38<03:32, 17.69s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[225]\tTrain's rmse: 0.0217206\tValid's rmse: 0.0222097\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114692 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217017\tValid's rmse: 0.0222238\n[200]\tTrain's rmse: 0.0216155\tValid's rmse: 0.0222157\n[300]\tTrain's rmse: 0.0215448\tValid's rmse: 0.0222152\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  45%|####5     | 9/20 [02:58<03:22, 18.45s/it]\u001b[32m[I 2022-04-22 10:34:19,964]\u001b[0m Trial 15 finished with value: 0.022213637072721573 and parameters: {'num_leaves': 69}. Best is trial 14 with value: 0.022209699147808036.\u001b[0m\nnum_leaves, val_score: 0.022201:  45%|####5     | 9/20 [02:58<03:22, 18.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[275]\tTrain's rmse: 0.0215603\tValid's rmse: 0.0222136\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021731\tValid's rmse: 0.0222211\n[200]\tTrain's rmse: 0.0216674\tValid's rmse: 0.0222114\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  50%|#####     | 10/20 [03:13<02:53, 17.39s/it]\u001b[32m[I 2022-04-22 10:34:34,966]\u001b[0m Trial 16 finished with value: 0.02221130589622575 and parameters: {'num_leaves': 42}. Best is trial 14 with value: 0.022209699147808036.\u001b[0m\nnum_leaves, val_score: 0.022201:  50%|#####     | 10/20 [03:13<02:53, 17.39s/it]","output_type":"stream"},{"name":"stdout","text":"[300]\tTrain's rmse: 0.0216169\tValid's rmse: 0.0222158\nEarly stopping, best iteration is:\n[203]\tTrain's rmse: 0.0216655\tValid's rmse: 0.0222113\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067183 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0218017\tValid's rmse: 0.022239\n[200]\tTrain's rmse: 0.0217896\tValid's rmse: 0.022224\n[300]\tTrain's rmse: 0.0217814\tValid's rmse: 0.0222177\n[400]\tTrain's rmse: 0.0217735\tValid's rmse: 0.022213\n[500]\tTrain's rmse: 0.0217672\tValid's rmse: 0.0222088\n[600]\tTrain's rmse: 0.0217606\tValid's rmse: 0.0222074\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  55%|#####5    | 11/20 [03:25<02:22, 15.82s/it]\u001b[32m[I 2022-04-22 10:34:47,233]\u001b[0m Trial 17 finished with value: 0.022206524231411874 and parameters: {'num_leaves': 4}. Best is trial 17 with value: 0.022206524231411874.\u001b[0m\nnum_leaves, val_score: 0.022201:  55%|#####5    | 11/20 [03:25<02:22, 15.82s/it]","output_type":"stream"},{"name":"stdout","text":"[700]\tTrain's rmse: 0.021755\tValid's rmse: 0.0222082\nEarly stopping, best iteration is:\n[605]\tTrain's rmse: 0.0217603\tValid's rmse: 0.0222065\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068448 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217849\tValid's rmse: 0.02223\n[200]\tTrain's rmse: 0.021763\tValid's rmse: 0.0222175\n[300]\tTrain's rmse: 0.021745\tValid's rmse: 0.022213\n[400]\tTrain's rmse: 0.0217293\tValid's rmse: 0.0222079\n[500]\tTrain's rmse: 0.0217157\tValid's rmse: 0.022204\n[600]\tTrain's rmse: 0.0217021\tValid's rmse: 0.0222052\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  60%|######    | 12/20 [03:40<02:03, 15.45s/it]\u001b[32m[I 2022-04-22 10:35:01,846]\u001b[0m Trial 18 finished with value: 0.022201760611949842 and parameters: {'num_leaves': 9}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  60%|######    | 12/20 [03:40<02:03, 15.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[528]\tTrain's rmse: 0.0217118\tValid's rmse: 0.0222018\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067341 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0218059\tValid's rmse: 0.02224\n[200]\tTrain's rmse: 0.021797\tValid's rmse: 0.0222272\n[300]\tTrain's rmse: 0.021791\tValid's rmse: 0.022223\n[400]\tTrain's rmse: 0.0217854\tValid's rmse: 0.0222172\n[500]\tTrain's rmse: 0.0217806\tValid's rmse: 0.0222114\n[600]\tTrain's rmse: 0.021776\tValid's rmse: 0.0222101\n[700]\tTrain's rmse: 0.0217718\tValid's rmse: 0.0222099\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  65%|######5   | 13/20 [03:52<01:41, 14.53s/it]\u001b[32m[I 2022-04-22 10:35:14,266]\u001b[0m Trial 19 finished with value: 0.02220899882386018 and parameters: {'num_leaves': 3}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  65%|######5   | 13/20 [03:52<01:41, 14.53s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[615]\tTrain's rmse: 0.0217753\tValid's rmse: 0.022209\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066764 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217238\tValid's rmse: 0.0222202\n[200]\tTrain's rmse: 0.0216549\tValid's rmse: 0.0222085\n[300]\tTrain's rmse: 0.0215995\tValid's rmse: 0.0222113\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  70%|#######   | 14/20 [04:09<01:30, 15.11s/it]\u001b[32m[I 2022-04-22 10:35:30,707]\u001b[0m Trial 20 finished with value: 0.022206856041182912 and parameters: {'num_leaves': 48}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  70%|#######   | 14/20 [04:09<01:30, 15.11s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[246]\tTrain's rmse: 0.0216275\tValid's rmse: 0.0222069\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066960 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0218112\tValid's rmse: 0.0222434\n[200]\tTrain's rmse: 0.0218057\tValid's rmse: 0.0222312\n[300]\tTrain's rmse: 0.0218018\tValid's rmse: 0.0222227\n[400]\tTrain's rmse: 0.0217988\tValid's rmse: 0.0222175\n[500]\tTrain's rmse: 0.0217962\tValid's rmse: 0.0222132\n[600]\tTrain's rmse: 0.0217937\tValid's rmse: 0.022213\n[700]\tTrain's rmse: 0.0217916\tValid's rmse: 0.0222109\n[800]\tTrain's rmse: 0.0217895\tValid's rmse: 0.0222088\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  75%|#######5  | 15/20 [04:20<01:09, 13.98s/it]\u001b[32m[I 2022-04-22 10:35:42,074]\u001b[0m Trial 21 finished with value: 0.022208506147889984 and parameters: {'num_leaves': 2}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  75%|#######5  | 15/20 [04:20<01:09, 13.98s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[760]\tTrain's rmse: 0.0217903\tValid's rmse: 0.0222085\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067436 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216217\tValid's rmse: 0.0222321\n[200]\tTrain's rmse: 0.0214651\tValid's rmse: 0.0222296\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  80%|########  | 16/20 [04:40<01:03, 15.87s/it]\u001b[32m[I 2022-04-22 10:36:02,326]\u001b[0m Trial 22 finished with value: 0.022227817321245083 and parameters: {'num_leaves': 178}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  80%|########  | 16/20 [04:40<01:03, 15.87s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[155]\tTrain's rmse: 0.0215329\tValid's rmse: 0.0222278\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068491 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216891\tValid's rmse: 0.0222233\n[200]\tTrain's rmse: 0.0215931\tValid's rmse: 0.0222175\n[300]\tTrain's rmse: 0.0215125\tValid's rmse: 0.0222218\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  85%|########5 | 17/20 [04:59<00:50, 16.74s/it]\u001b[32m[I 2022-04-22 10:36:21,079]\u001b[0m Trial 23 finished with value: 0.022216023469653484 and parameters: {'num_leaves': 82}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  85%|########5 | 17/20 [04:59<00:50, 16.74s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[208]\tTrain's rmse: 0.0215859\tValid's rmse: 0.022216\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068368 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217356\tValid's rmse: 0.0222215\n[200]\tTrain's rmse: 0.0216761\tValid's rmse: 0.0222106\n[300]\tTrain's rmse: 0.0216293\tValid's rmse: 0.0222149\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  90%|######### | 18/20 [05:13<00:31, 15.90s/it]\u001b[32m[I 2022-04-22 10:36:35,039]\u001b[0m Trial 24 finished with value: 0.022209740420230065 and parameters: {'num_leaves': 38}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  90%|######### | 18/20 [05:13<00:31, 15.90s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[210]\tTrain's rmse: 0.0216706\tValid's rmse: 0.0222097\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070305 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216661\tValid's rmse: 0.022224\n[200]\tTrain's rmse: 0.0215504\tValid's rmse: 0.0222159\n[300]\tTrain's rmse: 0.0214531\tValid's rmse: 0.0222197\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201:  95%|#########5| 19/20 [05:34<00:17, 17.39s/it]\u001b[32m[I 2022-04-22 10:36:55,891]\u001b[0m Trial 25 finished with value: 0.02221449202273497 and parameters: {'num_leaves': 110}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201:  95%|#########5| 19/20 [05:34<00:17, 17.39s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[207]\tTrain's rmse: 0.021543\tValid's rmse: 0.0222145\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067842 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0216379\tValid's rmse: 0.0222273\n[200]\tTrain's rmse: 0.0214956\tValid's rmse: 0.0222227\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.022201: 100%|##########| 20/20 [05:54<00:00, 18.17s/it]\u001b[32m[I 2022-04-22 10:37:15,897]\u001b[0m Trial 26 finished with value: 0.022221552015530506 and parameters: {'num_leaves': 151}. Best is trial 18 with value: 0.022201760611949842.\u001b[0m\nnum_leaves, val_score: 0.022201: 100%|##########| 20/20 [05:54<00:00, 17.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[155]\tTrain's rmse: 0.0215565\tValid's rmse: 0.0222216\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211712 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217821\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217571\tValid's rmse: 0.0222191\n[300]\tTrain's rmse: 0.0217379\tValid's rmse: 0.0222158\n[400]\tTrain's rmse: 0.0217195\tValid's rmse: 0.0222136\n[500]\tTrain's rmse: 0.0217054\tValid's rmse: 0.0222162\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  10%|#         | 1/10 [00:15<02:22, 15.88s/it]\u001b[32m[I 2022-04-22 10:37:31,788]\u001b[0m Trial 27 finished with value: 0.02221204816312547 and parameters: {'bagging_fraction': 0.5786439321071689, 'bagging_freq': 5}. Best is trial 27 with value: 0.02221204816312547.\u001b[0m\nbagging, val_score: 0.022201:  10%|#         | 1/10 [00:15<02:22, 15.88s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[440]\tTrain's rmse: 0.0217134\tValid's rmse: 0.022212\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071821 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217824\tValid's rmse: 0.0222296\n[200]\tTrain's rmse: 0.0217571\tValid's rmse: 0.0222212\n[300]\tTrain's rmse: 0.0217369\tValid's rmse: 0.0222162\n[400]\tTrain's rmse: 0.0217203\tValid's rmse: 0.0222151\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  20%|##        | 2/10 [00:29<01:54, 14.30s/it]\u001b[32m[I 2022-04-22 10:37:44,974]\u001b[0m Trial 28 finished with value: 0.02221138830267062 and parameters: {'bagging_fraction': 0.6315727727795992, 'bagging_freq': 4}. Best is trial 28 with value: 0.02221138830267062.\u001b[0m\nbagging, val_score: 0.022201:  20%|##        | 2/10 [00:29<01:54, 14.30s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[358]\tTrain's rmse: 0.021727\tValid's rmse: 0.0222114\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217821\tValid's rmse: 0.0222304\n[200]\tTrain's rmse: 0.0217573\tValid's rmse: 0.0222171\n[300]\tTrain's rmse: 0.0217364\tValid's rmse: 0.0222124\n[400]\tTrain's rmse: 0.0217191\tValid's rmse: 0.0222062\n[500]\tTrain's rmse: 0.0217035\tValid's rmse: 0.0222058\n[600]\tTrain's rmse: 0.0216893\tValid's rmse: 0.0222057\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  30%|###       | 3/10 [00:48<01:57, 16.85s/it]\u001b[32m[I 2022-04-22 10:38:04,866]\u001b[0m Trial 29 finished with value: 0.022204383482357565 and parameters: {'bagging_fraction': 0.7138160861434889, 'bagging_freq': 3}. Best is trial 29 with value: 0.022204383482357565.\u001b[0m\nbagging, val_score: 0.022201:  30%|###       | 3/10 [00:48<01:57, 16.85s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[557]\tTrain's rmse: 0.0216952\tValid's rmse: 0.0222044\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067727 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217821\tValid's rmse: 0.022232\n[200]\tTrain's rmse: 0.0217575\tValid's rmse: 0.022221\n[300]\tTrain's rmse: 0.0217377\tValid's rmse: 0.0222135\n[400]\tTrain's rmse: 0.0217207\tValid's rmse: 0.0222105\n[500]\tTrain's rmse: 0.0217058\tValid's rmse: 0.0222075\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  40%|####      | 4/10 [01:04<01:38, 16.42s/it]\u001b[32m[I 2022-04-22 10:38:20,612]\u001b[0m Trial 30 finished with value: 0.022205537623079353 and parameters: {'bagging_fraction': 0.6554017056110104, 'bagging_freq': 4}. Best is trial 29 with value: 0.022204383482357565.\u001b[0m\nbagging, val_score: 0.022201:  40%|####      | 4/10 [01:04<01:38, 16.42s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[476]\tTrain's rmse: 0.0217096\tValid's rmse: 0.0222055\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068596 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021782\tValid's rmse: 0.0222299\n[200]\tTrain's rmse: 0.0217571\tValid's rmse: 0.0222194\n[300]\tTrain's rmse: 0.0217374\tValid's rmse: 0.0222166\n[400]\tTrain's rmse: 0.0217205\tValid's rmse: 0.0222145\n[500]\tTrain's rmse: 0.0217055\tValid's rmse: 0.0222124\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  50%|#####     | 5/10 [01:21<01:22, 16.49s/it]\u001b[32m[I 2022-04-22 10:38:37,227]\u001b[0m Trial 31 finished with value: 0.022210632298885546 and parameters: {'bagging_fraction': 0.6244835385378925, 'bagging_freq': 5}. Best is trial 29 with value: 0.022204383482357565.\u001b[0m\nbagging, val_score: 0.022201:  50%|#####     | 5/10 [01:21<01:22, 16.49s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[450]\tTrain's rmse: 0.0217126\tValid's rmse: 0.0222106\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067738 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217821\tValid's rmse: 0.022229\n[200]\tTrain's rmse: 0.0217576\tValid's rmse: 0.0222154\n[300]\tTrain's rmse: 0.0217361\tValid's rmse: 0.022214\n[400]\tTrain's rmse: 0.0217196\tValid's rmse: 0.0222096\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  60%|######    | 6/10 [01:35<01:02, 15.74s/it]\u001b[32m[I 2022-04-22 10:38:51,521]\u001b[0m Trial 32 finished with value: 0.02220885331896211 and parameters: {'bagging_fraction': 0.6845940904499811, 'bagging_freq': 7}. Best is trial 29 with value: 0.022204383482357565.\u001b[0m\nbagging, val_score: 0.022201:  60%|######    | 6/10 [01:35<01:02, 15.74s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[385]\tTrain's rmse: 0.0217219\tValid's rmse: 0.0222089\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217827\tValid's rmse: 0.0222315\n[200]\tTrain's rmse: 0.021758\tValid's rmse: 0.0222218\n[300]\tTrain's rmse: 0.0217378\tValid's rmse: 0.022214\n[400]\tTrain's rmse: 0.0217217\tValid's rmse: 0.0222158\n[500]\tTrain's rmse: 0.021706\tValid's rmse: 0.0222102\n[600]\tTrain's rmse: 0.0216923\tValid's rmse: 0.0222104\n[700]\tTrain's rmse: 0.0216794\tValid's rmse: 0.02221\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  70%|#######   | 7/10 [01:55<00:51, 17.07s/it]\u001b[32m[I 2022-04-22 10:39:11,322]\u001b[0m Trial 33 finished with value: 0.02220960963229783 and parameters: {'bagging_fraction': 0.647022544159327, 'bagging_freq': 4}. Best is trial 29 with value: 0.022204383482357565.\u001b[0m\nbagging, val_score: 0.022201:  70%|#######   | 7/10 [01:55<00:51, 17.07s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[620]\tTrain's rmse: 0.0216895\tValid's rmse: 0.0222096\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069521 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217822\tValid's rmse: 0.0222282\n[200]\tTrain's rmse: 0.0217574\tValid's rmse: 0.0222175\n[300]\tTrain's rmse: 0.0217395\tValid's rmse: 0.0222112\n[400]\tTrain's rmse: 0.0217228\tValid's rmse: 0.0222089\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  80%|########  | 8/10 [02:07<00:30, 15.37s/it]\u001b[32m[I 2022-04-22 10:39:23,053]\u001b[0m Trial 34 finished with value: 0.022207601398126765 and parameters: {'bagging_fraction': 0.40778061064838594, 'bagging_freq': 3}. Best is trial 29 with value: 0.022204383482357565.\u001b[0m\nbagging, val_score: 0.022201:  80%|########  | 8/10 [02:07<00:30, 15.37s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[387]\tTrain's rmse: 0.0217247\tValid's rmse: 0.0222076\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068168 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217835\tValid's rmse: 0.0222325\n[200]\tTrain's rmse: 0.0217592\tValid's rmse: 0.0222182\n[300]\tTrain's rmse: 0.0217394\tValid's rmse: 0.0222141\n[400]\tTrain's rmse: 0.021723\tValid's rmse: 0.0222119\n[500]\tTrain's rmse: 0.0217071\tValid's rmse: 0.0222104\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201:  90%|######### | 9/10 [02:24<00:15, 15.95s/it]\u001b[32m[I 2022-04-22 10:39:40,274]\u001b[0m Trial 35 finished with value: 0.0222096323607633 and parameters: {'bagging_fraction': 0.46158374943653047, 'bagging_freq': 1}. Best is trial 29 with value: 0.022204383482357565.\u001b[0m\nbagging, val_score: 0.022201:  90%|######### | 9/10 [02:24<00:15, 15.95s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[494]\tTrain's rmse: 0.021708\tValid's rmse: 0.0222096\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068841 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217837\tValid's rmse: 0.0222298\n[200]\tTrain's rmse: 0.0217574\tValid's rmse: 0.0222123\n[300]\tTrain's rmse: 0.021737\tValid's rmse: 0.0222057\n[400]\tTrain's rmse: 0.0217197\tValid's rmse: 0.0222037\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.022201: 100%|##########| 10/10 [02:39<00:00, 15.61s/it]\u001b[32m[I 2022-04-22 10:39:55,132]\u001b[0m Trial 36 finished with value: 0.02220316403790621 and parameters: {'bagging_fraction': 0.7926865670653207, 'bagging_freq': 4}. Best is trial 36 with value: 0.02220316403790621.\u001b[0m\nbagging, val_score: 0.022201: 100%|##########| 10/10 [02:39<00:00, 15.92s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[362]\tTrain's rmse: 0.0217259\tValid's rmse: 0.0222032\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022201:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068671 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021782\tValid's rmse: 0.0222299\n[200]\tTrain's rmse: 0.0217579\tValid's rmse: 0.0222152\n[300]\tTrain's rmse: 0.0217387\tValid's rmse: 0.0222133\n[400]\tTrain's rmse: 0.0217212\tValid's rmse: 0.0222095\n[500]\tTrain's rmse: 0.0217063\tValid's rmse: 0.022205\n[600]\tTrain's rmse: 0.0216919\tValid's rmse: 0.0222047\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022201:  33%|###3      | 1/3 [00:16<00:32, 16.32s/it]\u001b[32m[I 2022-04-22 10:40:11,462]\u001b[0m Trial 37 finished with value: 0.022202421292583065 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.022202421292583065.\u001b[0m\nfeature_fraction_stage2, val_score: 0.022201:  33%|###3      | 1/3 [00:16<00:32, 16.32s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[535]\tTrain's rmse: 0.0217013\tValid's rmse: 0.0222024\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072948 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217821\tValid's rmse: 0.0222291\n[200]\tTrain's rmse: 0.0217578\tValid's rmse: 0.0222158\n[300]\tTrain's rmse: 0.0217384\tValid's rmse: 0.0222139\n[400]\tTrain's rmse: 0.0217214\tValid's rmse: 0.0222097\n[500]\tTrain's rmse: 0.0217065\tValid's rmse: 0.0222064\n[600]\tTrain's rmse: 0.0216925\tValid's rmse: 0.022205\n[700]\tTrain's rmse: 0.0216806\tValid's rmse: 0.0222057\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022201:  67%|######6   | 2/3 [00:33<00:16, 16.77s/it]\u001b[32m[I 2022-04-22 10:40:28,541]\u001b[0m Trial 38 finished with value: 0.022203944901307712 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.022202421292583065.\u001b[0m\nfeature_fraction_stage2, val_score: 0.022201:  67%|######6   | 2/3 [00:33<00:16, 16.77s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[627]\tTrain's rmse: 0.0216891\tValid's rmse: 0.0222039\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068918 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217822\tValid's rmse: 0.0222299\n[200]\tTrain's rmse: 0.0217586\tValid's rmse: 0.0222166\n[300]\tTrain's rmse: 0.0217392\tValid's rmse: 0.0222129\n[400]\tTrain's rmse: 0.0217219\tValid's rmse: 0.022208\n[500]\tTrain's rmse: 0.0217069\tValid's rmse: 0.0222033\n[600]\tTrain's rmse: 0.0216923\tValid's rmse: 0.0222049\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.022201: 100%|##########| 3/3 [00:49<00:00, 16.42s/it]\u001b[32m[I 2022-04-22 10:40:44,552]\u001b[0m Trial 39 finished with value: 0.02220132591417371 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 39 with value: 0.02220132591417371.\u001b[0m\nfeature_fraction_stage2, val_score: 0.022201: 100%|##########| 3/3 [00:49<00:00, 16.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[525]\tTrain's rmse: 0.0217033\tValid's rmse: 0.0222013\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067257 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217786\tValid's rmse: 0.0222285\n[200]\tTrain's rmse: 0.0217509\tValid's rmse: 0.0222188\n[300]\tTrain's rmse: 0.0217286\tValid's rmse: 0.0222123\n[400]\tTrain's rmse: 0.021707\tValid's rmse: 0.0222106\n[500]\tTrain's rmse: 0.0216894\tValid's rmse: 0.0222086\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:   5%|5         | 1/20 [00:12<03:48, 12.05s/it]\u001b[32m[I 2022-04-22 10:40:56,611]\u001b[0m Trial 40 finished with value: 0.022207464411589013 and parameters: {'lambda_l1': 0.01926842253161211, 'lambda_l2': 4.295636565164261e-07}. Best is trial 40 with value: 0.022207464411589013.\u001b[0m\nregularization_factors, val_score: 0.022201:   5%|5         | 1/20 [00:12<03:48, 12.05s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0216957\tValid's rmse: 0.0222075\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069995 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021791\tValid's rmse: 0.022236\n[200]\tTrain's rmse: 0.0217745\tValid's rmse: 0.0222268\n[300]\tTrain's rmse: 0.0217619\tValid's rmse: 0.022223\n[400]\tTrain's rmse: 0.0217518\tValid's rmse: 0.0222229\n[500]\tTrain's rmse: 0.0217437\tValid's rmse: 0.0222221\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  10%|#         | 2/20 [00:28<04:26, 14.79s/it]\u001b[32m[I 2022-04-22 10:41:13,323]\u001b[0m Trial 41 finished with value: 0.022220627790951773 and parameters: {'lambda_l1': 4.611044981606478, 'lambda_l2': 6.174525963204246e-08}. Best is trial 40 with value: 0.022207464411589013.\u001b[0m\nregularization_factors, val_score: 0.022201:  10%|#         | 2/20 [00:28<04:26, 14.79s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0217467\tValid's rmse: 0.0222206\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067663 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217786\tValid's rmse: 0.0222302\n[200]\tTrain's rmse: 0.0217511\tValid's rmse: 0.022222\n[300]\tTrain's rmse: 0.0217289\tValid's rmse: 0.0222158\n[400]\tTrain's rmse: 0.0217071\tValid's rmse: 0.022213\n[500]\tTrain's rmse: 0.0216894\tValid's rmse: 0.0222085\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  15%|#5        | 3/20 [00:41<03:51, 13.63s/it]\u001b[32m[I 2022-04-22 10:41:25,568]\u001b[0m Trial 42 finished with value: 0.02220767720749928 and parameters: {'lambda_l1': 0.001669979062652276, 'lambda_l2': 2.5412422908461874e-06}. Best is trial 40 with value: 0.022207464411589013.\u001b[0m\nregularization_factors, val_score: 0.022201:  15%|#5        | 3/20 [00:41<03:51, 13.63s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[459]\tTrain's rmse: 0.0216961\tValid's rmse: 0.0222077\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069817 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217786\tValid's rmse: 0.0222285\n[200]\tTrain's rmse: 0.0217514\tValid's rmse: 0.0222204\n[300]\tTrain's rmse: 0.021729\tValid's rmse: 0.0222147\n[400]\tTrain's rmse: 0.0217074\tValid's rmse: 0.0222122\n[500]\tTrain's rmse: 0.0216897\tValid's rmse: 0.0222081\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  20%|##        | 4/20 [00:52<03:27, 12.94s/it]\u001b[32m[I 2022-04-22 10:41:37,452]\u001b[0m Trial 43 finished with value: 0.022206987764303833 and parameters: {'lambda_l1': 0.010088476913011207, 'lambda_l2': 1.2961473807618442e-06}. Best is trial 43 with value: 0.022206987764303833.\u001b[0m\nregularization_factors, val_score: 0.022201:  20%|##        | 4/20 [00:52<03:27, 12.94s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0216963\tValid's rmse: 0.022207\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217785\tValid's rmse: 0.0222285\n[200]\tTrain's rmse: 0.0217509\tValid's rmse: 0.0222185\n[300]\tTrain's rmse: 0.0217286\tValid's rmse: 0.0222123\n[400]\tTrain's rmse: 0.0217069\tValid's rmse: 0.0222106\n[500]\tTrain's rmse: 0.0216894\tValid's rmse: 0.0222072\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  25%|##5       | 5/20 [01:05<03:12, 12.85s/it]\u001b[32m[I 2022-04-22 10:41:50,132]\u001b[0m Trial 44 finished with value: 0.022206391849442186 and parameters: {'lambda_l1': 0.01714762320387637, 'lambda_l2': 4.80091744574403e-06}. Best is trial 44 with value: 0.022206391849442186.\u001b[0m\nregularization_factors, val_score: 0.022201:  25%|##5       | 5/20 [01:05<03:12, 12.85s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[452]\tTrain's rmse: 0.0216971\tValid's rmse: 0.0222064\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068638 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217785\tValid's rmse: 0.0222296\n[200]\tTrain's rmse: 0.0217508\tValid's rmse: 0.0222199\n[300]\tTrain's rmse: 0.0217285\tValid's rmse: 0.0222154\n[400]\tTrain's rmse: 0.021707\tValid's rmse: 0.0222113\n[500]\tTrain's rmse: 0.0216896\tValid's rmse: 0.0222075\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  30%|###       | 6/20 [01:17<02:55, 12.54s/it]\u001b[32m[I 2022-04-22 10:42:02,093]\u001b[0m Trial 45 finished with value: 0.022206528056148016 and parameters: {'lambda_l1': 1.1834499996177576e-05, 'lambda_l2': 0.0504436061075967}. Best is trial 44 with value: 0.022206391849442186.\u001b[0m\nregularization_factors, val_score: 0.022201:  30%|###       | 6/20 [01:17<02:55, 12.54s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[459]\tTrain's rmse: 0.0216961\tValid's rmse: 0.0222065\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071103 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217787\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217506\tValid's rmse: 0.0222205\n[400]\tTrain's rmse: 0.0217071\tValid's rmse: 0.0222103\n[500]\tTrain's rmse: 0.0216897\tValid's rmse: 0.022207\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  35%|###5      | 7/20 [01:30<02:43, 12.61s/it]\u001b[32m[I 2022-04-22 10:42:14,848]\u001b[0m Trial 46 finished with value: 0.022205861695264947 and parameters: {'lambda_l1': 3.786301445783774e-06, 'lambda_l2': 1.2154370259230145e-05}. Best is trial 46 with value: 0.022205861695264947.\u001b[0m\nregularization_factors, val_score: 0.022201:  35%|###5      | 7/20 [01:30<02:43, 12.61s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0216963\tValid's rmse: 0.0222059\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067236 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217787\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217507\tValid's rmse: 0.0222205\n[300]\tTrain's rmse: 0.0217284\tValid's rmse: 0.0222142\n[400]\tTrain's rmse: 0.021707\tValid's rmse: 0.0222099\n[500]\tTrain's rmse: 0.0216895\tValid's rmse: 0.0222058\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  40%|####      | 8/20 [01:42<02:29, 12.45s/it]\u001b[32m[I 2022-04-22 10:42:26,937]\u001b[0m Trial 47 finished with value: 0.022204490048962723 and parameters: {'lambda_l1': 0.0007053404638006531, 'lambda_l2': 7.133685355485699e-07}. Best is trial 47 with value: 0.022204490048962723.\u001b[0m\nregularization_factors, val_score: 0.022201:  40%|####      | 8/20 [01:42<02:29, 12.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[459]\tTrain's rmse: 0.0216962\tValid's rmse: 0.0222045\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081740 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217786\tValid's rmse: 0.02223\n[200]\tTrain's rmse: 0.0217507\tValid's rmse: 0.022221\n[300]\tTrain's rmse: 0.0217287\tValid's rmse: 0.022214\n[400]\tTrain's rmse: 0.0217072\tValid's rmse: 0.0222108\n[500]\tTrain's rmse: 0.0216891\tValid's rmse: 0.0222074\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  45%|####5     | 9/20 [01:54<02:15, 12.34s/it]\u001b[32m[I 2022-04-22 10:42:39,026]\u001b[0m Trial 48 finished with value: 0.02220620119164974 and parameters: {'lambda_l1': 5.62236751809506e-07, 'lambda_l2': 0.02811101607380289}. Best is trial 47 with value: 0.022204490048962723.\u001b[0m\nregularization_factors, val_score: 0.022201:  45%|####5     | 9/20 [01:54<02:15, 12.34s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0216963\tValid's rmse: 0.0222062\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217787\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217507\tValid's rmse: 0.0222205\n[300]\tTrain's rmse: 0.0217284\tValid's rmse: 0.0222143\n[400]\tTrain's rmse: 0.0217071\tValid's rmse: 0.0222104\n[500]\tTrain's rmse: 0.0216896\tValid's rmse: 0.0222064\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  50%|#####     | 10/20 [02:07<02:04, 12.45s/it]\u001b[32m[I 2022-04-22 10:42:51,739]\u001b[0m Trial 49 finished with value: 0.022204989170281023 and parameters: {'lambda_l1': 0.0009283157390180719, 'lambda_l2': 1.0187270706490128e-05}. Best is trial 47 with value: 0.022204490048962723.\u001b[0m\nregularization_factors, val_score: 0.022201:  50%|#####     | 10/20 [02:07<02:04, 12.45s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[453]\tTrain's rmse: 0.0216973\tValid's rmse: 0.022205\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068262 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217923\tValid's rmse: 0.0222361\n[200]\tTrain's rmse: 0.0217764\tValid's rmse: 0.0222273\n[300]\tTrain's rmse: 0.0217643\tValid's rmse: 0.0222236\n[400]\tTrain's rmse: 0.0217548\tValid's rmse: 0.0222227\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  55%|#####5    | 11/20 [02:20<01:53, 12.61s/it]\u001b[32m[I 2022-04-22 10:43:04,692]\u001b[0m Trial 50 finished with value: 0.022221747480258056 and parameters: {'lambda_l1': 5.591018679759782, 'lambda_l2': 4.6948696076066945}. Best is trial 47 with value: 0.022204490048962723.\u001b[0m\nregularization_factors, val_score: 0.022201:  55%|#####5    | 11/20 [02:20<01:53, 12.61s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[345]\tTrain's rmse: 0.0217595\tValid's rmse: 0.0222217\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069511 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217787\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217507\tValid's rmse: 0.0222205\n[300]\tTrain's rmse: 0.0217283\tValid's rmse: 0.022214\n[400]\tTrain's rmse: 0.0217069\tValid's rmse: 0.0222106\n[500]\tTrain's rmse: 0.0216891\tValid's rmse: 0.0222078\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  60%|######    | 12/20 [02:31<01:38, 12.37s/it]\u001b[32m[I 2022-04-22 10:43:16,534]\u001b[0m Trial 51 finished with value: 0.02220613590243794 and parameters: {'lambda_l1': 0.0001472292470414943, 'lambda_l2': 0.0001701735423642618}. Best is trial 47 with value: 0.022204490048962723.\u001b[0m\nregularization_factors, val_score: 0.022201:  60%|######    | 12/20 [02:31<01:38, 12.37s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[459]\tTrain's rmse: 0.0216959\tValid's rmse: 0.0222061\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069491 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217787\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217507\tValid's rmse: 0.0222204\n[300]\tTrain's rmse: 0.0217285\tValid's rmse: 0.0222138\n[400]\tTrain's rmse: 0.0217068\tValid's rmse: 0.02221\n[500]\tTrain's rmse: 0.021689\tValid's rmse: 0.0222073\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  65%|######5   | 13/20 [02:45<01:28, 12.58s/it]\u001b[32m[I 2022-04-22 10:43:29,607]\u001b[0m Trial 52 finished with value: 0.022205103792348736 and parameters: {'lambda_l1': 0.00036701052434444696, 'lambda_l2': 1.347536671716603e-08}. Best is trial 47 with value: 0.022204490048962723.\u001b[0m\nregularization_factors, val_score: 0.022201:  65%|######5   | 13/20 [02:45<01:28, 12.58s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0216959\tValid's rmse: 0.0222051\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217787\tValid's rmse: 0.0222301\n[200]\tTrain's rmse: 0.0217506\tValid's rmse: 0.0222205\n[300]\tTrain's rmse: 0.0217285\tValid's rmse: 0.0222139\n[400]\tTrain's rmse: 0.0217071\tValid's rmse: 0.0222103\n[500]\tTrain's rmse: 0.0216897\tValid's rmse: 0.022207\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022201:  70%|#######   | 14/20 [02:56<01:14, 12.39s/it]\u001b[32m[I 2022-04-22 10:43:41,553]\u001b[0m Trial 53 finished with value: 0.022205861717860702 and parameters: {'lambda_l1': 2.7969335031264844e-08, 'lambda_l2': 0.00015146533687738164}. Best is trial 47 with value: 0.022204490048962723.\u001b[0m\nregularization_factors, val_score: 0.022201:  70%|#######   | 14/20 [02:56<01:14, 12.39s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0216963\tValid's rmse: 0.0222059\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103384 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217815\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217571\tValid's rmse: 0.0222161\n[300]\tTrain's rmse: 0.0217359\tValid's rmse: 0.0222112\n[400]\tTrain's rmse: 0.0217175\tValid's rmse: 0.0222064\n[500]\tTrain's rmse: 0.0217013\tValid's rmse: 0.0222029\n[600]\tTrain's rmse: 0.0216861\tValid's rmse: 0.0222014\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022200:  75%|#######5  | 15/20 [03:12<01:07, 13.40s/it]\u001b[32m[I 2022-04-22 10:43:57,290]\u001b[0m Trial 54 finished with value: 0.02220009491196133 and parameters: {'lambda_l1': 0.34784102407241985, 'lambda_l2': 0.0024685787925258014}. Best is trial 54 with value: 0.02220009491196133.\u001b[0m\nregularization_factors, val_score: 0.022200:  75%|#######5  | 15/20 [03:12<01:07, 13.40s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[527]\tTrain's rmse: 0.0216972\tValid's rmse: 0.0222001\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068069 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217561\tValid's rmse: 0.0222136\n[300]\tTrain's rmse: 0.0217344\tValid's rmse: 0.0222091\n[400]\tTrain's rmse: 0.0217152\tValid's rmse: 0.0222032\n[500]\tTrain's rmse: 0.0216984\tValid's rmse: 0.0221995\n[600]\tTrain's rmse: 0.0216828\tValid's rmse: 0.0221959\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022195:  80%|########  | 16/20 [03:28<00:56, 14.01s/it]\u001b[32m[I 2022-04-22 10:44:12,708]\u001b[0m Trial 55 finished with value: 0.022195265224984623 and parameters: {'lambda_l1': 0.2946795819074304, 'lambda_l2': 0.008751211238935437}. Best is trial 55 with value: 0.022195265224984623.\u001b[0m\nregularization_factors, val_score: 0.022195:  80%|########  | 16/20 [03:28<00:56, 14.01s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[590]\tTrain's rmse: 0.021684\tValid's rmse: 0.0221953\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217815\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217572\tValid's rmse: 0.0222156\n[300]\tTrain's rmse: 0.0217359\tValid's rmse: 0.0222115\n[400]\tTrain's rmse: 0.0217177\tValid's rmse: 0.0222086\n[500]\tTrain's rmse: 0.0217016\tValid's rmse: 0.0222042\n[600]\tTrain's rmse: 0.0216862\tValid's rmse: 0.0222022\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022195:  85%|########5 | 17/20 [03:43<00:43, 14.52s/it]\u001b[32m[I 2022-04-22 10:44:28,436]\u001b[0m Trial 56 finished with value: 0.022200489313463356 and parameters: {'lambda_l1': 0.358221206659432, 'lambda_l2': 0.008786587847008377}. Best is trial 55 with value: 0.022195265224984623.\u001b[0m\nregularization_factors, val_score: 0.022195:  85%|########5 | 17/20 [03:43<00:43, 14.52s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[527]\tTrain's rmse: 0.0216973\tValid's rmse: 0.0222005\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068086 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217817\tValid's rmse: 0.0222288\n[200]\tTrain's rmse: 0.0217572\tValid's rmse: 0.0222167\n[300]\tTrain's rmse: 0.0217364\tValid's rmse: 0.0222124\n[400]\tTrain's rmse: 0.0217182\tValid's rmse: 0.0222095\n[500]\tTrain's rmse: 0.0217025\tValid's rmse: 0.0222055\n[600]\tTrain's rmse: 0.0216873\tValid's rmse: 0.0222037\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022195:  90%|######### | 18/20 [03:58<00:29, 14.63s/it]\u001b[32m[I 2022-04-22 10:44:43,311]\u001b[0m Trial 57 finished with value: 0.022202469269494075 and parameters: {'lambda_l1': 0.39765411385007693, 'lambda_l2': 0.003025135164240443}. Best is trial 55 with value: 0.022195265224984623.\u001b[0m\nregularization_factors, val_score: 0.022195:  90%|######### | 18/20 [03:58<00:29, 14.63s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[527]\tTrain's rmse: 0.0216982\tValid's rmse: 0.0222025\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217811\tValid's rmse: 0.0222288\n[200]\tTrain's rmse: 0.0217565\tValid's rmse: 0.0222146\n[300]\tTrain's rmse: 0.0217349\tValid's rmse: 0.0222096\n[400]\tTrain's rmse: 0.021716\tValid's rmse: 0.0222056\n[500]\tTrain's rmse: 0.0216995\tValid's rmse: 0.0222022\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022195:  95%|#########5| 19/20 [04:11<00:14, 14.13s/it]\u001b[32m[I 2022-04-22 10:44:56,278]\u001b[0m Trial 58 finished with value: 0.02219976405798411 and parameters: {'lambda_l1': 0.2981124511854113, 'lambda_l2': 0.3341139366885709}. Best is trial 55 with value: 0.022195265224984623.\u001b[0m\nregularization_factors, val_score: 0.022195:  95%|#########5| 19/20 [04:11<00:14, 14.13s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[450]\tTrain's rmse: 0.0217077\tValid's rmse: 0.0221998\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181691 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0217793\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217533\tValid's rmse: 0.0222176\n[300]\tTrain's rmse: 0.0217309\tValid's rmse: 0.0222127\n[400]\tTrain's rmse: 0.02171\tValid's rmse: 0.0222101\n[500]\tTrain's rmse: 0.0216922\tValid's rmse: 0.0222064\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.022195: 100%|##########| 20/20 [04:24<00:00, 13.71s/it]\u001b[32m[I 2022-04-22 10:45:08,998]\u001b[0m Trial 59 finished with value: 0.02220508731283914 and parameters: {'lambda_l1': 0.0895294816767439, 'lambda_l2': 0.8109054983072618}. Best is trial 55 with value: 0.022195265224984623.\u001b[0m\nregularization_factors, val_score: 0.022195: 100%|##########| 20/20 [04:24<00:00, 13.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[460]\tTrain's rmse: 0.0216994\tValid's rmse: 0.0222051\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022195:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217561\tValid's rmse: 0.0222136\n[300]\tTrain's rmse: 0.0217344\tValid's rmse: 0.0222091\n[400]\tTrain's rmse: 0.0217152\tValid's rmse: 0.0222032\n[500]\tTrain's rmse: 0.0216984\tValid's rmse: 0.0221995\n[600]\tTrain's rmse: 0.0216828\tValid's rmse: 0.0221959\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022195:  20%|##        | 1/5 [00:15<01:02, 15.61s/it]\u001b[32m[I 2022-04-22 10:45:24,615]\u001b[0m Trial 60 finished with value: 0.022195265224984623 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.022195265224984623.\u001b[0m\nmin_data_in_leaf, val_score: 0.022195:  20%|##        | 1/5 [00:15<01:02, 15.61s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[590]\tTrain's rmse: 0.021684\tValid's rmse: 0.0221953\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067454 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217561\tValid's rmse: 0.0222136\n[300]\tTrain's rmse: 0.0217344\tValid's rmse: 0.0222091\n[400]\tTrain's rmse: 0.0217152\tValid's rmse: 0.0222032\n[500]\tTrain's rmse: 0.0216984\tValid's rmse: 0.0221995\n[600]\tTrain's rmse: 0.0216828\tValid's rmse: 0.0221959\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022195:  40%|####      | 2/5 [00:32<00:48, 16.07s/it]\u001b[32m[I 2022-04-22 10:45:41,017]\u001b[0m Trial 61 finished with value: 0.022195265224984623 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.022195265224984623.\u001b[0m\nmin_data_in_leaf, val_score: 0.022195:  40%|####      | 2/5 [00:32<00:48, 16.07s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[590]\tTrain's rmse: 0.021684\tValid's rmse: 0.0221953\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066858 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217561\tValid's rmse: 0.0222136\n[300]\tTrain's rmse: 0.0217344\tValid's rmse: 0.0222091\n[400]\tTrain's rmse: 0.0217152\tValid's rmse: 0.0222032\n[500]\tTrain's rmse: 0.0216984\tValid's rmse: 0.0221995\n[600]\tTrain's rmse: 0.0216828\tValid's rmse: 0.0221959\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022195:  60%|######    | 3/5 [00:47<00:31, 15.82s/it]\u001b[32m[I 2022-04-22 10:45:56,534]\u001b[0m Trial 62 finished with value: 0.022195265224984623 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.022195265224984623.\u001b[0m\nmin_data_in_leaf, val_score: 0.022195:  60%|######    | 3/5 [00:47<00:31, 15.82s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[590]\tTrain's rmse: 0.021684\tValid's rmse: 0.0221953\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067213 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217561\tValid's rmse: 0.0222136\n[300]\tTrain's rmse: 0.0217344\tValid's rmse: 0.0222091\n[400]\tTrain's rmse: 0.0217152\tValid's rmse: 0.0222032\n[500]\tTrain's rmse: 0.0216984\tValid's rmse: 0.0221995\n[600]\tTrain's rmse: 0.0216828\tValid's rmse: 0.0221959\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022195:  80%|########  | 4/5 [01:03<00:16, 16.08s/it]\u001b[32m[I 2022-04-22 10:46:13,002]\u001b[0m Trial 63 finished with value: 0.022195265224984623 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.022195265224984623.\u001b[0m\nmin_data_in_leaf, val_score: 0.022195:  80%|########  | 4/5 [01:03<00:16, 16.08s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[590]\tTrain's rmse: 0.021684\tValid's rmse: 0.0221953\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067583 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 416522, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000230\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021781\tValid's rmse: 0.0222287\n[200]\tTrain's rmse: 0.0217561\tValid's rmse: 0.0222136\n[300]\tTrain's rmse: 0.0217344\tValid's rmse: 0.0222091\n[400]\tTrain's rmse: 0.0217152\tValid's rmse: 0.0222032\n[500]\tTrain's rmse: 0.0216984\tValid's rmse: 0.0221995\n[600]\tTrain's rmse: 0.0216828\tValid's rmse: 0.0221959\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.022195: 100%|##########| 5/5 [01:19<00:00, 15.89s/it]\u001b[32m[I 2022-04-22 10:46:28,564]\u001b[0m Trial 64 finished with value: 0.022195265224984623 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.022195265224984623.\u001b[0m\nmin_data_in_leaf, val_score: 0.022195: 100%|##########| 5/5 [01:19<00:00, 15.91s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[590]\tTrain's rmse: 0.021684\tValid's rmse: 0.0221953\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADP00lEQVR4nOydd7wU5fX/3x8BBQTBgh1ExQoiChIbCrHE3g0QS1BjxBr1p5HEEjUm1kSDJUT9KrYgiiW2iA0EjUqTKnYwIrGggiIWhPP745zhzt27e+/eC1cQnvfrdV/szs4888zssnvmzDmfj8yMRCKRSCQSiUQi4ay0tCeQSCQSiUQikUgsS6QAOZFIJBKJRCKRyJEC5EQikUgkEolEIkcKkBOJRCKRSCQSiRwpQE4kEolEIpFIJHI0XNoTWJqstdZa1rZt26U9jUTiB2Xs2LGzzKzV0p5HIpFYdki/h4kVlVK/iSt0gNy2bVvGjBmztKeRSPygSHpvac8hkUgsW2y46mr8+4Qzl/Y0EoklSquTj65xnVK/ianEIpFIJBLLHZIaSxolaYKkKZIuieX/F8smShoiqVks30LScEnjJU2VdHMd99tH0vp13PYcSa/HHEZLOrYW23aX9Fhd9ptIJKqSAuREIpFILI98C/zUzLYFOgH7SNoROMvMtjWzjsB/gdNi/f7AtWbWycy2Aq6v4377ALUKkCU1kNQX2AvoamadgD0A1XEOiURiMUkBciKRSCSWO8yZG08bxZ+Z2RcAkgQ0ATI72fWAGbntJ8V6DSRdHRndiZJOytaRdJ6kSZGRvkLSEUAX4J7IAjeRtIekV2O92yStEttOl3SlpHHAkcDvgZOz+ZnZF2Z2R6xbaox9IuM8DjgsN69VY71Rsd3BS/j0JhLLPSlATiQSicRySQS344GPgafN7JVYfjvwIbAlFZnia4HnJP1b0lmSWsbyE4A5ZrYDsANwoqSNJe0LHAz8JLLUV5nZEGAMcFRkgQ0YCPQ0s23wvp+Tc1P81My2B54AmpvZu0WOoXGxMWL5LcCBQGdg3dxm5wPPmVlXoAdwtaRVi4z9a0ljJI35dO4XZZzRRGLFIQXIiUQikVguMbMFEahuCHSV1CGWH4eXQUwFesay24GtgPuB7sDLkandGzg2Au1XgDWBzYA9gdvNbF5s/1mRKWwBTDOzN+P5HcBuudcHl3EYpcbYMpa/ZWYG3J3bZm+gX8x5ONAYaFM4sJndbGZdzKzLms1WK2MqicSKQwqQE4lEIrFcY2azgWHAPrllC4B7gcNzy2aa2W1mdjDwPdABrwM+PWqTO5nZxmb21BKa2lex3y+AuZI2WULjCjg8N+c2ZjZ1CY2dSKwQrNAyb4lEIpFYPpHUCphvZrMlNcEb4K6S1M7M3o4a5IOA12P9fYBnzWy+pHXxTPEHwFC8pOG5eG3zWP40cJGke8xsnqQ1Iov8JdA8pvEG0DbbJ3AM8HyJKV8O3Cipp5l9EeoahwH3lRjj9Vi+qZm9A/TOjTUUOF3S6WZmkrYzs1erO18NW61RliRWIrGikALkRCKRSCyPrAfcIakBfrf0PuBxYKSk1fAs6wQqaoL3Bv4m6Zt4fq6ZfSjpVqAtMC6C6k+AQ8zsSUmdgDGSvsPriH+P1wsPkPQ1sBNwHHC/pIbAaGBAifn+HWgGjJY0H5gP/MXMvpFUZQwz+1bSr4HHJc0DRlIRmP8RuA6YKGklYBpwQJ3OYiKxgiIvXVox6dKli5U0CjGD+38J7faEjj2h4So/7OQSiXpC0lgz67K055FIJJYdOm3U2p763dlLexrLPGv3PWtpTyGxhCn1m5hqkEsx92OY9TY8cjrceTB8/fnSnlEikUgkljEkXRwGH5dK2jOWdQtzkkzq7ep4fvVi7quTpP3KWG9NScMkzZV0w+LsM5FYUUkBcimarwMnvwiH3QIfjIXb9oHPpy/tWSUSiURiGcTMLjKzZ+LpUcDl0SD3NfBroKOZnVvTOFFGUYpOQI0BMvANcCFwThnrJhKJIqQAuTok6PhzOPpB+OJ/8Pdd4MX+MP+bmrdNJBKJxHKJpPMlvSnpBVyGDUkDJR0h6VfAz4E/SrpH0iN4bfFYST1LjDdQ0gBJr+CNhF0lvRQmH/+R22CvDFwK9IzMdM9ShiBm9pWZvYAHytUdR04H+asldn4SieWB1KRXDht3g5NfgMfOhqcvhFfvhkMHwAbbL+2ZJRKJROIHRFJnoBeezW0IjAPGZq+b2a2SdgUeC+MQJM0NPebq2BDY2cwWRBNhNzP7Pso2/mxmh0u6COhiZqfFuH/GDUGOD2OTUZKeMbOyol0zuxm4GbwGucxTkEisEKQMcrm0bANHD4GjHoBvv4T/2xvGDlzas0okEonED0s34CEzmxf6xY8soXHvD21mgBa4asVk3OGvfYltyjIESSQStScFyLVlsz3hlP/AJrvDo7+Bf58HC75f2rNKJBKJxI+bfNb3j8AwM+uAW0k3LrFNMgRJJOqJVGJRF5qsDr+4D566EF6+EebMgCNuS1JwiUQisfwzAhgo6XL8N/RA4B9LeB8tcDMSgD655XkTEqiDIUgpGrZaJ0mYJRI5Uga5rqzUAPb5M+x7Fbz+GNz3S1gwf2nPKpFIJBL1iJmNAwbjJiP/xo07ljRXAZdLepXKiaxhwNZZkx6eaW6EG4JMiecASJoO/BXoI2mGpK3rYZ6JxHJLyiAvLj85CbQSPHEO3L4f7H8NrLft0p5VIpFYyoRd8XXADsBs4CPgYeAgM6tXVzNJTwC/MLPZddi2O/Av3H2tMd5sVq1cmKRDgDfN7LV4fikwIid7Vmq7tYD/AaebWVGHOUkXA3PN7Jpyxy0yRlu8Ae6ftdxuIPAYXgPc2Mx+B2Bmf5L0ODDIzHYt3M7M+oQyBWY2xMyaVbcfM+tT8PwlYPPcogti+Wf45ymb39XA7sB3wJu4a192vOvgVtcAL2fvTSm++/g9ZtxwUnWrLBdseNqSTvYnlldSBnlJ0PVE10v+7F24uTsMPgbeeDJllBOJFZSwJH4IGG5mm5pZZ+B3eNBS75jZfnUJjnOMDNWF7YADJO1Sw/qHAIsylAWawNVxJPAy0LucSdVi3ELaAr+ow3YZg4BCibZesXxp8jTQwcw64gHy73KvvZOrTe67dKaXSPx4SQHykqLjz+H0sbDz6fDeizCoJ1zRBl64bmnPLJFI/PD0AObns6JmNgEYCTSTNETS66GTKwBJF0kaLWmypJtzy4dLujK0bt+U1C2WN5V0n6TXJD0k6RVJXeK16ZLWktRW0lRJt4ST21OSmsQ6O0iaGLfrrw7FhEqEycV4YIPY5sSY4wRJD8QcdgYOAq6OsTbNNIFjmz1Co3dSaPbmmzV6A/8P2EDShtnCYjrDsTw/7vTIQCOpi6Th8Xj3mMf42G9z4AqgWyw7S1KDOObRcQ5Oim0l6QZJb0h6Blg7zsObwOeSfpKb+8+BQXJ3u5djnIckrV54HnPvx/kx9tyYy4eSxkkaKek9SYdJuirO1ZOSGsX2nSU9L2mspKGS1ot5PWVmWZf4y7hUXCKRWAKkAHlJ0qQl7HUp/L83oPe90HZXeOYPMPR8t61OJBIrCh3IaeMWsB1wJp5x3QTIsrM3mNkOoVzQBMiXYTQ0s66x3R9i2SnA52a2Ne6a1rnE/jYDbjSz9nipx+Gx/HbgpMgULyi2YQR7m+GNaQAPxhy3BaYCJ5jZf3Cps3MjW/lObvvGwECgp5ltg5f1nRyvtQbWM7NRwH1EhlaVdYb3I1dSUCbnAKfGcXUDvgb6EVlxM7sWOAGYY2Y7xPgnStoYOBQPyLcGjgV2zo07KOaFpB2Bz8zsLeBO4LzI4k6i4v2pgpn9CXfZGxPzGwDMA36KX2TcjatXbBPz3j+C5OuBI+JOxG3An4oMfzxeE52xcVwgPJ9dVBWinFHIZ3OTAVYikScFyPVBg0awxb4eJHfsCS/dADd0hht3hGcvhekvwMKFS3uWiURi6TDKzGaY2UI8O9s2lveILPAkPGDKa98+GP+Oza2/K3AvgJlNBiaW2N80Mxuf315uKtE8al0BCmtzu0magCspDDWzD2N5h8h2TsIDvVL6vBlbxP7fjOd3ALvF4554YEwcR1Zmsbg6wy8Cf5V0BtAyl2HNszdwrFw/+BVgTfxCYDe8rniBmc0EnsttMxg4QtJKRHmFpBaxj+eLHF+5/NvM5uPBdQPgyVg+CX+vt8AvuJ6O+V5AQaZY0vnA98A9seh/QBsz2w44G/in3HykEmZ2s5l1MbMuazQrpSSXSKyYpCa9+mSlBnDYzfDTC+H1x2Hqo/DCtTDyL7BOB9jjItikBzRceWnPNJFILFmmAEeUeO3b3OMFQMPItN6Eu6S9L29Ma1xkmwXU/nu7cH9NythmpJkdEFnVlyXdF0H2QOAQM5sgqQ/QvZZzydMbWFfSUfF8fUmb1WL776lI8iw6V2Z2hbyBbj/gRUk/K7Kt8MbAoZUWSvuV2lm8L9PwprjDgZ0Wd67BtzH+QknzzSxztFuIv9cCpphZ0f3F+3AAsEe2rZl9mxt3rKR38Ka/MbWYcyKxQpMyyD8ELVvDjn3huMeh33/h0H/At1/AP38OV7aFu4+AsXfAV7Pg+29rHC6RSCzzPAesIunX2QJJHfHsaDGyoGmWpGaUDq7zvIjXwSKX8Nqm3MlFA9+XuZraXiXWm4bX754Xi5oD/4vb/kflVi3U5814A89Yt4vnxwDPS9ocaGZmG5hZWzNrC1yOB80jgEMkNYn64QNLHMZ0KspKsrIRJG1qZpPM7Epcgm3LIvMbCpycq/HdXNKqse+eUaO8Hl5LnmcQ7mz3btwFmIPXJmfv6zHA81Sl6FzL5A2glaSdYq6NJLWPx/sAv8WVUeblzkErSQ3i8SZ4dvzdWu43kVihSRnkH5pVmsO2vaD9ofDmUJj2PLz1NDx6hv+pAay7DWzaA9rtBa27eslGIpH40RCmDYcC10k6D/gGD5IeLrH+bEm3AJOBDylPW/cm4A5JrwGv41nrObWY5gnALZIW4kFdqW0HAOfIpcMuxEsSPol/s6Dz3hjrDHLBvZl9I+k43Da5YRzXALwm+KGC/TwADDazSyVlOsMfU/VcZBnWS4D/k/RH3GY540xJPfAM7BS8LnchsCDKRgYCf8PLF8ZJUhzPITGnnwKvAf8FXqIy9wP9gdNzy34JDJDUFA9Cj6MqpeZaI2b2nbwxsX+UdDTE5QOnADcAq+DlF+Bybn3xMo9LJc2PY+8bEnElWXntjZIEWiKRQxV3c1Y8unTpYmPGLAN3nBYu8ED5oynw9efw35fh/Vdg4fewymqwSXfYbG9otyestp5v8908aLAyNEjXOInaIWmsmXVZ2vNILB6RIWwUQeimwDPAFmb2XZnbNzOzufG4H94w95v6m/HiI+lR4K9mNmxpz2V5o/1GLW1Qv9qWT/+46HhybcvZEysCpX4TU3S1LLBSA9j0p/6X8c0cePd5ePtpzzBPjf/YKzcHDL6bCw0bQ6stoNVWsMbGsGY72HJ/aFROiWEikfihkWTAPWZ2dDxviDdUvVIH85CmwOTIgM4GTik3OA72l/Q7oBmwKSXKLJYFJHUCXsWbGl8osc5A3NRkiKRb8UC6WnOMEvtZ38yeqOV2w4FzzGxMlMj8BdgTf1++xFUuXpE0tybTkFrudyQVWfy18QbQQ1TZ7AVcfeTSJbXfRGJFIAXIyyqNW8DWB/mfmWeX334G5n4MGKzaCr7+zJdPHwkTB1cs3+ZIaLMTtNkRmq29tI8kkUhU8BWuBNEkNIb3wpUiao2ZfQlsVNeJmNlgYLCkK3E5s/1wpYbFQlLDEsoRi0NvPDB+NxQfqsXMflXH/XQCugC1CpALuBUPTDeLxruNyZmoLEnMbFFNu6QH8KA4Y2QdLroSiUSQAuQfAxKs28H/SvH9t16W8Z8bYMxt8PJNvnzj3aFlG880r74xNF0T5n7otdBrbOLLwJsGG7eo/2NJJBJPAPsDQ/DAbxDRvCdpDVzndhNcH/fXeF3yu0CnzB1P0lu4zNvJVNgwD8frgnsALXGN4pFRGzsQlwp7A1gf1wkeE9nnI/FAfWSoabQF7gzd5cy2+FEz2yY0iv+KZ51nAX3M7H+x7/Exp0GS3sTlyFYGPgWOMrOPJLXCJeXWx+t79wI6m9ksSUcDZ8Q2r+AZ8QXF5hhlJcL1gfcC3sftlok5D6cio7soaxu1vAeYW0EfiWsWL8Drr/cELgWaSNoVbxp8LPbRAWgEXGxm/5KbrdwObIvXf2fmK5sCP4njXQiLGh2zTG42PwFXAfviNdWXmdngaAwcDKxGaEbHe7g3Xse8CvAOcFxWHhPjrYbXTherf04kEnUgBcjLCw1XgY1387/vv4X/TfCM85SH4aPJ8Opdxbdr3NItsed/5aUabXaEhfPhq09BK8FKK/nrH06Grz6Gpmt5sL3WZr7tmu3cRdAbRBKJRM3cC1wk6TGgIx4QZ5nAS4BX4zb5T/FAtZOkf+EmFreH8sR7EXAWjt3QzLqGXNkf8KBvkaGIpA54IJuxM65T/E4Elfub2QOSVpa0cQR3PfFMc2ZYcbCZfSKpJ25YcXyMtXJWxyc3GNkxmhV/hSst/L+Y03NmdnkoMJwQ628V+9nFzOZLuglXybiz2Bzxhr68qcc6eGPdbbV4Hy4CfmZmH0hqGc1wF+FSe6fFvP4c8z1erh09Su6wdxIwz8y2CnWScTFme2C8mRU1XslxGJ6t3hZYCxgtaQRuhz3UzP4UNeZN5W6BFwB7mtlX0fR5Nh7MZxwCPBu60Rk7RVPiTPxiYUrhJOQqK78GWG+NVJqXSORJAfLySMNVXP2idVfo8Xsv0fjsXfh6tmePW7aB776CDyfBJ697s1+TNeC9F2DKg66k0WID327hAsCgzU9gtQ28xGPWGzBhMHwbTe9PnudB9MrNPGBev5Nnqr//FlbfCDbaGZqv5/NKJFZwzGxiZGV7U/VW/q6EDJiZPSdpzcgODsYDutvxWuFSpRClDEX+FmNOlpQ3FOlNmI3Ev8fiwWfmbHdF/NuTyoYV4KYW/8uNlZ/ThnhQvR6eEc4yqLvigS1m9qSkz2P5HrgM2ugYuwmuYFHdHBeZegAzJeVNPcrhRWCgpPuoOG+F7A0cJOmceN4YaBP77h/HMbHgnJbDrrm5fyTpedzRbzRwW1yMPGxm4yXtjl8EvBjnZmWqqmv0xks7MsYBG5nZ3LhYehiXequEmd0M3AzepFfLY0gklmvqNUCODMHf8C/SW83sioLXV8EzBJ3x23A9zWy6pL3wL+aV8dtm58aPRVNcZmdT/LbYo2bWL8Y6G/gVLsj+CXC8mb1Xn8f3o0GCNTeturzNjgULzq3duAsXwpj/g7efhRYbwvx58MkbMOoWWFCg56yVvKmwUZOKzPPqbT0bvXABzHoTbAGsvbWPM/8b3+b7rz3QXn87N1VZdc3azTGRWDZ5BLgGN9oo50P9EtAuShQOAS4rsV7ZhiKRoTwcOFjuxCZgTbn28GBcmu1BXLXuLUnbUI1hBV5fnXE93iT3SDSMXVz94SHgDjP7XS3mWC75wC9vKNI3svH7A2OjfKTYvA43szcK5lVqX1OAbSU1KCOLXHWiZiMk7RZzGijpr8DnwNNm1rvYNpFh7kpceMQ4X+QePyHpJklrmdms2s4pkVhRqbcAOb7YbsTrw2bgmYFHCrqKT8Bv/bWT1Au4Es9UzAIONLOZcUtwKLBBbHONmQ2TtDLwrKR9zezfeIdzFzObJ+lkvL6rZ30dXwIvv+h6ov/lWTDf/xqsDB+/BjPHwRf/c+WN77+Brz6BT9+B9/4D333p26yyGiD4tuAOqRrASg0j4Bas1xFatPbsNuZBd5PV/W/Ndq4E0nydH+DgE4nF4jZgtplNigAyYyReWvDHWD4rC3YkPYTX/041s09rsa/MUGSYKhuK7AFMNLNFTnOS7gAONbM7JS3AdY+zzPAiwwozeymynJsXu3UPtKCi+fCXReZyZdTVrh7LnwX+JelaM/s4arGb41nronPETT1Oiudr47XXhZbZ4BnarWL+h+KqEpmhyCvAK5L2BVpT3FDkdEmnR7nIdmb2auz7F8Bz8RvVESDKQMYAl0i6MLZpC7Q3s8dz447MzX0NPCN9rqSNgBlmdkskkLbHy1hulNTOzN6WG5psYBX23Ufg6h3f5M7RusBHsf+uuClYtZ+ZJq3aJRm0RCJHfWaQuwJvm9m7AJLuBQ7G68QyDqYiszAEuEGS4gsoYwreNLGKuVPQMFgknj6O8KS3yrqYLwNHL/lDSpRFg0YV5ibrdfS/YpjB7P96IN18XV/2xQceLK+8qmeWG67s/84c7zXV770In02Lmmd5tvmb2V4+Ygt82Ua7QPtDYOtDoFkrH3fhQteYnvM+zHrLy0Q+f8/rqud/A03X8Hk0WxvW3Axa7wDN1/fa7ObrQ6NCd9gcC753Wb5vv/DmxyZr+MXDkmDB9358X83yc/PFBzDnA/j0LT/W776CL2d66UvzdV3FpMvxsMW+S2b/iXrBzGYQt+gLuBi/xT4Rb9LLB5eD8VvwfWq5u1KGIqdS3KzjZPzO3mDgamDjmHN1hhXFjuP+KKF4LhsDr7EeJOkYPCv+IfBlNOldADwlaSVgfsyvdzVz3I/qTT2yzHE/vNnuE9xqOZNZu1pubS08QJ8Q4/STNB5v0vtjHOPEmNc03Nb573g9+FRgKl7SkvErXObtbUlf4wmfwttzD+FW1RNinr81sw8l/RIPlOcDc4Fjo967T5y3rE7tAiALkHvhd1zzHIE7BX4PfA30MluBTQ8SiTpQb0Yh8UW6Tya3E1+IP8maH2LZ5FhnRjx/J9aZVTBOXzPbs2D8lnid1Z5ZEJ577QbgQzOrchsy35TQpk2bzu+9l6owlgsWfA+fTIWpj3kd9az47Vi5GYsC6fwdT63kwWTLjTz4/WoWfPtlRaCbp1FTaLWlB9FNVgdb6OvO+xTmfQZzZnhjY37sDTrDettGHfd8WH97aP0TD8LnfghffujbfvEBfD7d/778n68veea82dow+z0P7Cshty9fqaHPbbX1veb7yw9d+m/nM2Cb0k7F+hEahWjJ6gcjqS/eZHXnYsypE37nal8ze7Ku49QnuTkeZGaPqoihiH5A/eAI8BaY2fdy6+Snge7mahMt8NKMnfGg9UXgdHM751ohaRJ+zNOKvNadEhrBktbBraR3xEsbvgOuMrPCIL3ceUzHs9KGXwwca2Yf1mWsulLue7NF2xZ28/m7/jCTqmd2P/HxmldKJIJSv4nLdJOe3G/+SrxRIr+8IS6N1L9IcHw0rmO5e7Ex800JXbp0SVfUywsNGrpF97rbQPd+8OFEmDYCvpgJyBsEm63jToRrbe4Sd6WaBmf/F2a+6lnZhqt4M+On71SUhkieKW66psvkbX2QNzCu0tyD5jkzfPtJ93ugi8G4EnHYSo28aXKNjT3TrpU8SF4w3/e3Tns/plVbeSC82gbR8LhyfZ3JZZUlph8MYGYDlsCcMm3e3sBiB8iqP/3gl/Bs5wd44FnSUMTqXz+4DXBfZGO/w8seMv4PmGxmxwJIugRvPDuyNhOR9DQwqVhwnKOKRrC8sPhhvBb6F7FsI+Cg2uy/CD0iQ/5n4Pe4lF21LOHPQicWX9s5kVjhqM8A+QO8pitjQ6r+oGXrzIigtwVRJyVpQ/w21LFm9k7BdjcDb5nZdfmFkvYEzgd2N7OCLrHECoPk2dv1tq3b9i3b+N+SIlMRmTHanzdbx4Pcpmt6VnqlBktuX8s3ST94MfSD8btz38i5gaWgH4z3o7yBy5u9G8eDpHZ4s3a+b+RSvExhU/x34lI8G9sOL7U7xdyIo1Aj+NBQb5gO3AEcGHM40sxepzQ/Bb7LXzxFo/f1uffzLmDVePk0M/tPZKSLzq1g/BHAGfL+nCvwBs1VgBvN7B8xzh/xzPWWUTd9JbAPsBC4xcyur+GzVOlzHM8rvTfmBjGJRKIGllChZFFGA5tJ2ljeUNcL79zO8wgVNXZH4HqTFuUTjwP9zOzF/AaSLsMD6TMLlm8H/AO/rfYxicSyQqYism0v/9u0B6y9pddHp+C4NtwL9IpgtCP+45+R6Qd3xLN0d0aAkukHo5x+cJGxG0ZgeyYe/EFOPxhvVsurHCzS5gWG4/rBrwMry53ToKp+8BFm1hkP5P+UG2tlM+tiZn/BM9I7mtl2cby/jXUy/eD2+AVCmzimvH5wJzxoParUHGN5Xj/42FivNmT6wdvi37ffxbLBZtYpArDzY75d8YDt6mguO5nQD45jys7p1hToB8fj8bi2MHhfy+mx7qbAYaqsEbw9XmN8dm6us2L534Fzcst3kjRB0r/jTiWxn3GU5mNgrxivJ5VryKvMrcj2BwCT8MB1jpntgEu7nZj7zGwP/MbMNscv8triF3gdgXvK+CxV+hyXeG8SiUQZ1FsGOWrMTsO7gBsAt5nZFEmXAmPM7BH8ltpdkt4GPsODaIDT8Cvxi+TC7eBlFivjX7yvA+M8QcINZnYr3kzSDG8MAfivmS3urbFEIrGMYEk/eEXXDx5lFU3fg/Bz8g3VawTn39csaC1LI1jSjbGP7yKYbYQ3knfCL0Q2r2FuQ+K1YXJFkIl4MH8r0DGy8uAJn83wTP6oXGnInsCArNTCzD6TK2ZU91kq9jkuSb4nZ501qmlETiRWQOq1BjmaAp4oWHZR7vE3FKkvi+a6UjqfRQUoraCJL5FILJck/eCC6bB86Ae/BnSStFJWmhB1yp3itQ0L5pPNT1SjEUyR99VKaATjahyH5147NZaPiUVnAR/h5SEr4cF5fi6Fc8voYZUbz4U3Hw7NbxDvd/6zUAxR/Wep7M8xVO7J2aJti9STk0jkqM8Si0QikVjS3AZcYmaTCpZn+sFZoDHLzL4wM8N7GRZHPxgV1w9ubWZtzWwjwvo4yhlK6gfHWI1yt/ULqUk/GFXVDz5C0trx2hrRWFZyjngtbE9JDSJT3aPEXD6StFUEqotMKBT6wZHs+ITq9YMV22wXyzP9YFRZP/htXG3jgtwYFwDj4jWArlGytxKemX8Bl/TcJWqYkbSqpHxmtwqS1s3NK68R/BzQWK6jn9E097gF8L8I4I/Bs7cZxeZWiqG4BFujmMPmUX5SyNO4VnLDWG8NavdZyih8bxKJRBks0yoWiUQikceSfvDyrB98AnC9XO6TmNcJuddHAzdQ0Qj3UDTp9aG0RnAxSmoESzoEuFbSb+O4vwLOi+1uAh6QdCyuWpLP9laZWzX7vxUvfxgXgfon+N2NYuttjp/D+XiT3g21+CxlDCP33pSqQ26+1mZJHi2RyFFvOsg/Brp06WJjxoypecVEYjlCP0Id5KVBlCk0CuWHKvrBP/BcCvWD/x5NeUt6PyX1g5cmcVfgHKuD5nV9syzPrTak38PEikqp38SUQU4kEoniNMUbrBpRg37wD0ChfvCJcjvh63AlhNl4fezDeIBbF/OUcvSDs3WfAH5hIZ9Xy/10p8KoozFuUnJOddvgTW9ZBht5s/cIM3umhn2thTexnW4ltK8lXUyF5F9Z4xahiaRfmFkxq+vq5jeQCpOW4YTEXi33XWzctniGPqsBf9nM+la3zexZb/HIbcuHA+dBx/97aU8hsRyQAuREIpEogpl9iRssLHXM7C0gq+PNGr3+gzfo9Ypl27IYphZmtlct1t2vrvsJRprZAZKaAK9KesgKJD0LaIeXMGT7v6iadfMcidcp9wZqNIepxbj5bYZHSfM5uFb1ssI79XGXIZFYUUhNeolEIvHjowcw3yqbWkzAmxWbSRoi6XVJ9+Qa0i6SNFrSZEk355YPl3SlpFGS3pSUma80lXSfpNckPSTpFUld4rXpktaS1FbSVEm3SJoi6akIepG0g6SJksZLulrS5MKDMHdFHA9sENucGHOcIOmBmMPOeOB/dYy1qaSBUYuLpD0kvSppkqTbcrXI4IHx/wM2kJtPEducH8f6Ai7Dly3Pjzs9MtBI6hIZXiTtHvMYH/ttjsv6dYtlZ8kbIK+OY5ko6aTYVpJukPSGpGeAtat7k+VNlw/HGC9L6hjLJ0lqGeN9Kq+LRtKdksq+0EkkEqVJAXIikUj8+OhA5Qa3PNvhRhFb486Cu8TyG8xsBzPrgOsl58swamuUkmcz3A2uPV7qkUml3Q6cZBUGJlWQtHpsPyIWPRhz3BYvETjBzP6Dy/udG2YX7+S2b4y7HfY0s23wu6Inx2utgfXMbBQV+tTIZel64RJy++ElKrXhHNxRsRPu5Pg13tA4MuZ3LaXNQGpr0lLFACeWv4i/r+1xR8JusXwn/M4CwMYRwD+fXfQUIunXksZIGvPF3KVVPZRILJukADmRSCSWL0aZ2YyQIxtPhWFEj8gCT8JVLPLyYKWMUu4FN0rBjS6KMc3Mxue3l7uhNjezTCGjsPSgm6QJuKTdUDP7MJZ3kDQy5nhUwRyLsUXsP1OtuAM3IwEPiO+Lx/fi2WTwYPIhM5sXmsiFDq818SLwV0lnAC0zI48C9gaOlStHvIJrdm9GzqTFzGbiSiXVsStub42ZPYdrWa+G3ynYLf7+DmwjaQP8guYrvO66jbkj49nAP2O7SpjZzeYujl1Wa7Zy7c5CIrGckwLkRCKR+PExhdIZ3W9zjxcADSPTehNuUbwNcAs58w9qaTBR0/7K2GZkZInbAyfI3enAs8GnxRwvKZhjbekN9JE0HQ+CO8rl6crleyp+I/NGKVcAv8Kz8C9K2rLItpkZSKf429jMnqrLQZRgBB7od8NtxD/B5etGxhy/zTS/zWws8A6Vnf8SiUQNpAA5kUgkfnw8B6witwoGIOpTi95KpyLAmyWpGR5M1UQpo5QaCXWLL+WOe+AlDcXWm4bX72Zaw82B/8mVQ47KrVrK7OINPGPdLp4fAzwvNwtpZmYbhFFKW1yfuTceXB4iqUnUDx9Y4jCmU3ERsshhT26UMsnMrsT1j7csMr9SZiDlmrRklDLAeR9YC9jM3OL6Bbz0Y0Ss20ouU4ikTfDs9bs17CuRSORIKhaJRCLxI8PMTNKhwHWSzsNtj6fjMm/F1p8t6RZgMm4yMrqM3ZQySimXE4BbJC0Enq9m2wHAOXJpsgvxkoRP4t8s6Lw3xjqDXHAfGtXH4eYqDeO4BuA1wcWMUgab2aWSBuMGJx9T9Vxk5gCXAP8n6Y94ljbjTEk9gIX4Ofl3PF4QZSMDgb9R3AzkIao3aXlcbgpCvHYSpQ1wXqHCzW8kfgGQOfjtBlwaYy0E+prZZ1RDy7U2S/JoiUSOZBSShNETKxhKRiGJMtBiGqVIamZmc+NxP7xh7jf1N+PFR9KjwF/NbNjSnssPTfo9TKyolPpNTBnkRCKRWMaRNNfM8kYZfYAuZnaapL7APDO7s8S23YHvQg2iNhwB/EXSp9TSKCXqfi+TdC3wKZ5p7ROvnYk3112Jm2R0kHQYrgyxR6yzK6573CVrgpP0MLCume1YYp9tc+N1AY41szPKPVhJt+HmMNtJesXM5tVi2+7k3PTkltWXAo3wWuYLzezhcscrc5/NiZrjYEPgbjM7Mz4fV+NNkOAKJrdWN96nn77FXQN/tiSn+INyTJ+hS3sKieWMFCAnEonEj5hSDnE5ugNzqZD/qhFJDc1sMDB4Mab2MN7nspOZHZdb3gv4bX5FM3tQ0q8k/QK4Hy/v6JsLjlvi9cBzJW0SdbclCTe6WqVDzez42Nd0XE6t7AA5j9yw5RpgLzObFvJuT0t618xKKYHUmjCy6ZTb71gq1EjAy0lOW1L7SyRWNFKTXiKRSPyIkXSxpHPi8RlyY4+Jku6NrGpf4Cy5iUU3ubnHc7HOs5LaxLYDJQ2Q9ApwlaQ+km6I19aRm4VMiL+dY/nDksbKTUJ+XWR6Q4D9Ja0c67cF1qdy5jPjNOAy4GJgdEHG+zDgUbwWeVHDn6TO2ZyAU3PLu0t6rPD8xPPJcQ5WlfR4bD9ZUs+ocV4ftxgfFuvvLeklSeMk3S9vckTSPnIzlnExv4xzgD9HA2LWiHg5cG5sN1zS3+L9mCypayxfVW50MkquX3xwLO8j6UFJT0p6S9JVhSdO3pS4donzmkgk6kAKkBOJRGLZp4kq3NvG47fvi9EP2C6MJfqa2XS8ae3akBsbCVyPW1R3BO4B+ue23xDY2czOLhi3P/B8SLNtj5dMABxvZp1xS+4zJK2Z3ygaw0YB+8aiXsB9VqT5JbLCg/FA+byCl3sDg+Kvd2757bic2rYlzkd17APMNLNtwzzlSTPrD8wEephZD7mT3gXAnma2PZ6VPlsum3cLroDRGVg3N257qpq4jKGypnPTMBo5Bbgtlp0PPBeGLT1w58BV47VOuK7zNrgKRuuC8XvhGeP8eT08LoKGFFkfqGwU8uWXySgkkciTAuREIpFY9vk6p6nbCbioxHoTgXskHY3XvhZjJyqMO+7CzSgy7jezYq53P8UNKQiTi0yR4ozI3r4MtMblxAoZREXWt1c8r4K8KXAvvBxko9zydWLcF8IQZL6kDlF20dLMMhe+u0ocbykmAXvJbba75Y4pz464692LcWHyy5jblrhByVsRlN5dy30PAoi5rxbHsjfQL/YzHJfmaxPrP2tmc8zsG1wBY6OC8QrP66NA27gIeho3UKlC3iikefNkFJJI5EkBciKRSCw/7A/ciGd5R8ulz2rDV+WuGI1pe+I1xtsCr1Lc2ONfwB6Stsczp6Ussk/Bg9YTgBslKZb/HFgdmBb1wW2pnEWuibzhB9kcI9jePvZ5maRiFx0Cns5dnGxtZifUsL/XqGri0pmKrDtUSMnlnws4PLevNmY2NV4vacYSNc8N8+fVzD41s2ybW4vMJ5FI1EAKkBOJRGI5QNJKQOuQKDsPaAE0o6qJxX+oyOgeRXl1q88CJ8d+GkhqEeN/bmbz5G5yRdUlQuptGF5KUCp7vC5uifxbM3sSV1/4VbzcG9gnZ/jRGegVZiSz5YoX2bEUYzoeCBNB+sbxeH1c/eNuXPFh+1g/f75eBnZRGJFEnfDmuC50W7n8XTbHjGuA30W9dVZ3/XvgL7l1esZruwJzIns9FDg9uzCQtF2J4ykkKz9ZhNyEJOMgYCqJRKJWJBWLRCKRWD5oANwdwauA/mEQ8igwJJq+To+/2yWdixtYHFdyxAp+A9ws6QQ8g3ky8CTQV9JU3NHu5Wq2H4SbZBR11AP+ClxlZp/E8zOBkXJlho3yY4cyxBy5S99xuJGGAYVWzlmW9gHgWElTcHONN2P5Nnid70JgfhwTwM3Ak5JmRh1yH2CQpFXi9QvM7M1oSnxc0jz8IqN5zG+83LzlUbmT3nw88B+fm9s3kl7FZeCOj2V/BK4DJsbFzjTggBLnK8/Pgf0Klp0h6SA8e/4ZIbFXHWuuuVmSSkskciSjkCSMnljBUDIKSSznSDocOMjMflnjyj8wkobjmsnL1I9Pm01a2HmXFr0JsExz6tEpqE8sHqV+E1MGOZFIJBLLDZE5/RMVmdn63t/FeGPhasAIM3tGUjdcPWQ+3hR5KZ7lfWIx99UJWN/Mqh1H0l7AFcDKwHfAuWb23OLsO5FY0UgBciKRSCSWG8zsEeCRpbDffJPfUcDlUd9MlGOsUUIhpBJyk5ZSCiSdcEm9mgLtWcCBZjZTUge8vnmDmvadSCQqSAFyIpFIJBK1QNL5uOTbx8D7wFhJA4HHgJZ4XfDPJO2L1yY3i3UuD4fCwvEGAt8A2+GScvcCf8MVN77Ga62n4ZnoJtHcd3ns73qgA17PfLGZ/cvMXs0NPyW2WSWnbJFIJGogBciJRCKRSJSJpM54s2En/Dd0HDljEDO7NQLYx8xsSGwzN/SrqyMzaVkgaTWgm5l9L2lP3Jnv8JCi65JZSEv6M24ucnxoKY+S9IyZ5eX6DgfGFQuOI7P9a4DV1yym0JdIrLikADmRSCQSifLpBjxkZvMAJC2pco68SUsL4A5Jm+FqHI1KbLM3cJAqrLQzc5GpMbf2wJWxXhXM7GZctYM2m7RYcTv2E4kipAA5kUgkEomlTz7r+0dgmJkdGjrKw0tsk5mLvFHlBWlDXFrvWDN7ZwnPNZFY7qnXAFnSPngdVQPgVjO7ouD1VYA7ceH3T4GeZja9VAeupKbA/cCmuBbno2bWL8baDdeQ7IiLyA+pz2NLJBKJxArJCGCgpMvx39ADgX8s4X20wM1SoLKGcaHpS2YucrqZmaTtzOzVKLd4HOhnZi+Ws8O119gsSaYlEjnqzUlPUgPc8nRf3Mu+t6StC1Y7AXdiagdci98KgooO3G3wRoi7cttcY2Zb4s0Mu0QTBMB/8S+Sf9bD4SQSiUQigZmNAwYDE4B/A6PrYTdXAZeHmUg+kTUM2FrSeEk98UxzI9xcZEo8BzgNaAdcFOuOl7R2PcwzkVhuqc8MclfgbTN7FyC6cg/GfeozDgYujsdDgBskqZoO3Hn4FwRm9p2kcXhjA2Y2PfazsN6OKJFIJH5ERHNYs9zzPkSTl6S+uNXynSW27Q58Z2b/qeU+DwK2LrxjWOa203EZs/uBK8xsaO61M4Et8ETKY2bWQdJhwKlmtkessytwA36M38eyh4F1zayoC0aUMGTjdcFLEs6obp5m9idcazk/zpmE/JqZ9SlYvxlFiHN8jpkdIKmPpBvM7DQzewnYPLfqBTHOZ8AOBcOcVGR+l0Vz33q4CkaN/O/zt/jj4J+Vs+oyw4U9U8Y7UX/UWwYZ11x8P/d8BlV1GBetE19mc4A1C9Yp2oEbt5AOBJ6tzaQk/VrSGEljPvnkk5o3SCQSieUQMxtQKjgOugM712bM0PB9pC7BcQGDqGpL3SuWL8LMHgS+lfSLsHW+CTglFxy3xEv4WkjapKadmtmYmoLjajgTaFrHbeuLo8ysU/x9vLQnk0j8mKjPAHmxyXXgnlSwvCH+Rdk/y1CXi5ndbGZdzKxLq1atltxkE4lE4keEpIsz9QNJZ0h6TdJESfdGVrUvcFbcnu8mqa2k52KdZyW1iW0HShog6RXgqiwTGq+tI+khSRPib+dY/rCksZKmhNRYIUOA/SWtHOu3BdYHRhZZ9zTgMvxu5OiCjPdhwKPAveQCbkmdszkBp+aWd5f0WOH5ieeT4xysKunx2H6ypJ6Szoj5DZM0LNbfW9JLksZJul9SM0nnS3pH0jeS5uGZ8nY1vE9nx34mR5YaSefGPpF0raTn4vFPJd1T3XiJRKI86jNA/gBonXu+IRVNB1XWiaC3Bd6sV1MH7s3AW2Z23ZKfdiKRSCw3NMnVoI7HjSaK0Q/Yzsw6An2jZG0AcG1kH0fihhR3xDr3AP1z22cavmcXjNsfeN7MtgW2x0vmAI43s854OcUZkirdOYxSglF4Dwt4cHufmVWRIoskyWA8UD6v4OXeeDJlUDzOuB04PeZVW/YBZprZtmbWAXjSzPoDM4EeZtZD0lp4WcSeZrY9MAY4G/gL3ny+DbAqXjL4dqkdyTWXjwN+AuwInChpO/xCoVus1gVoFhn0bngT4aLjjPf+Qkmqw7EmEiss9RkgjwY2k7RxZAF6UdX+8xG8CQ/gCFzw3FRNB66ky/BA+sx6nHsikUgsD3ydu8XeCbioxHoTgXskHQ2UsjneiYom6LuAXXOv5TV88/wU+DuAmS0wszmx/IzI3r6MJ0k2K7JtvsyiSnlFhrwhfC9gLrBRbvk6Me4LZvYmMF9Sh/h9aWlmWSB5F7VjErCXpCsldcsdU54d8eb0F+PC5Jcxty2BaWb2VgT7d9ewr11xzeWvzGwu8CAeBI8FOssNRb4FXsID5W5UZNmPikb3bvF3TOHg+ZLDr774rhanIJFY/qm3ADlqwE7DZWim4lf/UyRdGk0cAP8HrCnpbfzqul8sL9qBG1nl8/EvnnGx/FcAknaQNAM4EviHvKM3kUgkEjWzP646tD0wOu7o1Yaval7FkTem7QnsFBncV3GDi0L+BewhaXugqZmNLbIOwCl40HoCcGMuU/pzYHVgmrz5ry2Vs8g18T2VfyMbA0SwvX3s8zK5u10hAp7OXZxsbWYn1GLf1WJm83Hr6T7Af/CguAf+uzk11vkg/v0Sv7DpWmScRSWHq6628pKaXiKxXFCvOshm9gTR1ZtbdlHu8Td4QFu43WV4TVkxit4mMrPRhKJFIpFIJMpD0kpAazMbJukFPFvbDNfcXS236n/itbuAoyheD1zIs8DJwHWR6W2G3wH83MzmSdoSz7ZWwczmRj3vbZTOHq+LJ1e6mtknkk4EfgXcggfD+4QiBJI2Bp4xs/MlzZa0q5m9EMdSjOnAAbHt9sDG8Xh94DMzu1vS7NgfVGgUz8Iz4zdKamdmb0taFW9Kfx1oK2nTKB2sKWAfiWsuX4H/9h1KRSZ4JHAOcDwerP8VGBt3YRviWfJZUXpxAPBMDftKJBI5kpNeIpFIrNg0AO6W1AIPwvqb2WxJjwJDJB0MnB5/t0s6F/gEr42tid8AN0s6ATd3Ohl4EugraSrwBh5MlmIQ3otSqGiR8VfgKjPLJInOBEZKGouXNCwa28ymSZoj6Scx99skGfBUwZhZnfMDwLFxN/IV4M1Yvg1wtVxSdH4cE3hvzJOSZkYdch9gkNwQC+ACM3szmhIfjya9kVQ2/ugj6ZDc8x2BgXg9NrjhViaDOhK/o/qSmX0l6RsqLlpWAYZGcNwAD45vKX4KnfVW3yzJpiUSOVSk52GFoUuXLjZmzJilPY1E4gdF0lgz67K055FILGtIOhw4yMx+WePKyxnp9zCxolLqNzFlkBOJROIHJMoCrsMNH2YDHwEP44HZAfW87yeAX5jZ7Dps2x2vC56G1+M+Zmbn1LDNIcCbZvZaPL8UGGFm1d7uDxWI/+FKEwNKrHMxMNfMril33CJjtMXVN/4ZvTF/wksWatpuIPAY0B5obGa/y73WCRhkZltVt62ZDanNXGtDnJsT8Uw/wO+j5LEk02e/xXEP7VNfU1ri3H7ok0t7ConlnGVaBzmRSCSWJ6KB7CFguJltGlJnvwPW+SH2b2b71SU4zjEy1DC2Aw6QtEsN6x+CN1Vn+7+ozCD2SLw8oqymulqMW0hb4BcxxiNmtqXVzjlwENCzYFlJxY0fmEyir1NNwXEikahKCpATiUTih6MHMD+fFTWzCXjtaDNJQyS9LumeTI1B0kWSRodRxM255cNDamyUpDcldYvlTSXdJzf+eEjSK3ILZSRNl7SW3PBiqqRb5GYdT0lqEuvsIDcDGS/pakmTCw/CzL4GxhPuqJJOjDlOkPRAzGFn4CC8Xne8pE3lpiJHxDZ7SHpV0iRJt+VqdcED4/8HbBDqRcQ258exvoDbTmfL8+NOjww0krpIGh6Pd1eFKtKrkpoDVwDdYtlZkhrEMY+Oc3BSbCtJN0h6Q9IzwNpxHt4EPo+65oyf47XHnSS9HOM8JGn1wvNYzVwvlnSHpJGS3pN0mKSr4lw9GbXFmeHJ83LTlaGS1qv6kUskEnUhBciJRCLxw9EB17AtxnZ4k9nWwCZAlp29wcx2CFOKJoSyQtDQzLrGdn+IZafgKhFbAxfiVsvF2Ay40cza46Ueh8fy24GTIlNcTNuYCPY2o8KU4sGY47a4zNgJkYl9BDg3spjv5LZvjDef9Qyt3oZEs5uk1sB6ZjYKuI/I0MpNM3oBnYD98BKV2nAOcGocVzfga1xadGTM71pcKm6Ome0Q458oV784FA/ItwaOpbIF9yK9Zkk74goXbwF3AueZG6tMouL9KZdNcR3pg3C95GFxrr7GXQYb4eYtR8SdiNvwEpGM0yI4v61YcB7zXaSD/E3SQU4kKpEC5EQikVg2GGVmM8xsIZ6dbRvLe0QWeBIeMLXPbfNg/Ds2t/6uuLUyZjYZNwEpxjQzG5/fXm6i0TyTRqPCGCSjm9zg4wNgqJl9GMs7RLZzEi6b1p7q2SL2nylD3AHsFo974oExcRxZmUU33DRjnpl9QVXjqZp4Efir3KK5ZWj1F7I3rlwxHleuWBO/ENgNryteYGYzgedy2wwGjpDL5fXCs8ctYh/PFzm+cvl36B1PwpUosqLbSfh7vQV+wfV0zPcCKqRO/44H2J3wWu6/FNtBXge5cdJBTiQqkZr0EolE4odjCu4aWoxvc48XAA0j03oT0MXM3pc3XzUuss0Cav99Xri/JmVsM9LMDois6suS7osgeyBwiJlNkMubda/lXPL0BtaVlOkTry+pmNNeKfIGH4vOlZldIelxPPv8oqSfFdlWeGNgJb0zSfuV2lm8L9OA3fEs/E6LO9fg2xh/oaT5ViE5tRB/rwVMMbMq+zOzj3JzvwVvKEwkErUgZZATiUTih+M5YBW5Fi4Akjri2dFiZEHTLEnNKB1c53kRr4NF0ta4bm9ZRAPfl7ma2qL6w2Y2Da/fPS8WNQf+F7f988YbmXlGIW/gGet28fwY4HlJmwPNzGwDM2trZm2By/GgeQRwiKQmUT98YInDmE5FWUlWNoLcnGOSmV0JjMZtnwvnNxQ4OVfju7nc5GME0DNqlNfDa8nzDAKuBd6NuwBz8Nrk7H09BnieqhSda5m8AbSStFPMtZGk9vE4X4t8KFCljjyRSFRPyiAnEonED0S4nB2KO8udB3yDB0kPl1h/dmQAJwMf4oFdTdwE3CHpNdy5bQowpxbTPAG4RW6E8Xw12w4AzpFLpV2IlyR8Ev9mQee9MdYZ5IJ7M/tG0nHA/XLXt9ExXj9c5SPPA8BgM7tU0mBgAvAxVc9FlmG9BPg/SX8EhudeP1NSDzwDOwX4dzxeEGUjA4G/4eUL4yQpjueQmNNPgdeA/wIvUZn7gf64mUrGL4EBkpoC71LcWKXUXGvEzL6TNyb2j5KOhrh84BTgKrncnOGfr5NqGq9ty82SdFoikSMZhSRh9MQKhpJRyHKN3NK5UQShm+IualuYWVldWJKamdnceNwPb5j7Tf3NePGRu/791cyGLe25/Fhp0W4d2/maUoaFS59/H/K3pT2FxHJKqd/EVGKRSCQSyziS5hY87yPphnjcV9KxuZebAi9EVvQhvGGrNhdE+8tlz94D+gCX1WG+mZzcsMJaX0lnSvq7XGpuciw7TNKzuXV2jTk0zC17WFIVW2pJt+HH/H5uvC6S+td23rn5Na3lNt0lPZZ7fkgoSEyVS7MdUpe51LDPppIel8sCTpF0Re61PpI+UYWs3a+W9P4TieWdFCAnEonEjxgzG2Bmd+aefxnKBNuGxFhTKsuS1TTeYLwpcKMwzvikxo1Ks0gCLUcVIw0zexD4VtIvov73JuCUTGki1DU6Ay0kbVKw7fFmtgfe8JYtG2NmZ9Rxzmfi56xOSNoWuAY4ONz0DgKuiVrzJc01ZrYlLhG4i6R9c68NzhmF3FoP+04klmtSgJxIJBI/YuSmEufE4zPkBiETJd0b9cF9gbMik9gtMrfPxTrPSmoT2w6UNEDSK3gNaz5LvY7c7GJC/O0cyx+Wm1RMUa7xMMcQPCO9cqzfFlgfN0Yp5DQ8W30xMLrA0e4w4FG8pnlRwC03ypgQ2fJTc8sXZXTz5yeeT45zsGpkYCfEsp5RK70+MEzSsFh/b0kvSRon6X55sySS9ons7biYX8Y5wJ+jkTFraLwcODe2Gy7pb/F+TJbUNZavKtcsHiU3Mjk4lveR9KDcIOQtSVfFuPOykpIonxlHhcxbIpFYTFKAnEgkEss+TXK3y8cDl5ZYrx+wXWSO+5rZdLz5LbMdHombS9wR69yDN5dlbAjsbGZnF4zbH3g+jEC2xxvBAI4Pk4ouwBmS1sxvZGafAaOALLPZC7gvJ1mWX/ddXFP4NCrUMTJ641nnQVS2n74dl2XbtsT5qI59gJmRae8APGlm/YGZQA8z6yF3ubsA2NPMtgfGAGfL5fduwZU0OgPr5sZtT1UzmDFU1oZuGoYlp+AGHwDnA8+F8UsP3IFw1XitE64PvQ2uptE6P3hk2A8Ens0tPjwugoYUrp/bbpFRyHdffF3yRCUSKyIpQE4kEolln69zt8s7AReVWG8icI+ko8mVHBSwExUGIHfhxiIZ95tZMfe8n+K1zIRZRqZscUZkb18GWuOmGoXkyyyqlFdkyJsL9wLmAhvllq8T474QxiLzJXWIoLClmWVufneVON5STAL2ktt1d8sdU54dcfe8F+PC5Jcxty1xo5O3Iti/u5b7HgQQc18tjmVvoF/sZzgu8dcm1n/WzOaY2Te4kkb+/DSM8frHRQZ4tr1tXAQ9jRuVVCFvFLLyauXIYCcSKw4pQE4kEonlh/2BG/Es72jlmtzK5KtyV5TUHdgT2CkyuK9S1ewC4F/AHpK2xzOnpay2T8GD1hOAGyUplv8cWB2YJmk6LsPWu9gAJcibcZDNMYLt7WOfl0kqdtEh4OncxcnWZnZCDft7jar23p2pyLpDhSRd/rmAw3P7amNmU+P1KiYyuec3A2+Z2XWLBjP71MyybW4tMp9EIlEDSQc5kUgklgPkVsetzWyYpBfwbG0z3Axjtdyq/4nX7sJNPYrVAxfyLHAyrt/cIMZtAXxuZvMkbYlnW6tgZnOjnvc2SmeP1wXOBrqa2SeSTgR+hZcx9Ab2sbC/lrv4PWNm50uaLWlXM3uBygYleaYDB8S22wMbx+P1gc/M7G5Js2N/UGEeMgvPjN8oqZ2ZvR0lDxvg+tJt5eYj71A5YL8G13d+zsymR93176ls8tITr3PeFZhjZnMkDQVOl3R66GVvZ2avljim7Lxdhr8PvypYvp6Z/S+eHgRMLdy2kM1atk5SaolEjhQgJxKJxPJBA+BuuWmE8Fvus+UawUOi6ev0+Ltd0rm4EUYxA4tCfgPcLOkEPIN5MvAk0FfSVNzVrYoEW45BuORcKaHdvwJX5RQzzgRGShqLlxMsGtvMpkmaI3f7Ow64TZIBTxWMmWVpHwCOlTQFNzF5M5Zvg9f5LgTmxzGBZ2SflDQz6pD7AIMkrRKvX2Bmb0ZT4uOS5uEXGc1jfuPlJjCPyhU55gO/NbfkzvhG0qtAI+D4WPZH3OhjYlzsTCMC+2JI2hCvW34dNzYBuCEUK86QdBCePf8Ml+tLJBK1IBmFJKOQxAqGllGjkAhy7jGzo+N5Q+B/wCtmVjJQqGa8vsC8vARaHcbohJcO7Gtmy6TNWDlzlDQQeMzMhki6FTfVeK0O+1nfzJ6o5XbDgXPMbEwoQPwFL82YjWdrzzOzVyTNNbNmtRm7mn0ejkvFZVnUtYFRZnZIlIb8Cw9AAR40s0tju3Vwy+gdgc+B7/DAvdDdr9x5TMeP0XAnxGNxJY5zzOwH+fEp931r0W5D2+XqU6tbZanyxKG/W9pTSCynlPpNTBnkRCKxrPAV0EFSEzP7Gm/Y+qCug5nZgCUwp97AC/HvYgfIkhpm2r5LkFrN0czqahrRCVerqFWAXMCteGC6mZktjHKJrRdjvCpE5vRPwKGZVJykB/CgOGNk4UVX1Dw/jCt8/CKWbYSXKCwOPcxslqQ/46UW5RzDkvycdGLx37dEYoUjNeklEolliSfwRjOokPYCQNIact3diZJeltRR0kpy17aWufXekuv25vWBh4dawShJb0rqFsubSrpPrh38kKRXJHWJ1wQcid+e3ktSY0lbShqV21dbSZPicWdJz8t1gYdKWi+37+skjQF+I+nA2M+rkp6JrCWSWkl6Wq4pfKuk9+QyY0g6OuY+XtI/5HXAReeYLZd0g6Q3JD2DZ1DJzSc7xrm55UdEphlJR8o1eidIGiHXMb4UlxgbL9cMLqXb20SuwTxV0kNAk1i+KfATvERhIXi5hJk9nv8AxNyvjv1PktQzlq8Xc8n0g7P3sJJOMS6VtmUuOF4NV+F4uLoPXqzzXf7CyszeM7Prc+/1yNjPOFVoQXePeT0e53uAvESikBFAO2CPOI+j47N8Um6ckZIeAV6T1EDSNXGsEyWdHutV9zmr9Bkv9r7VcA4SiUSQAuREIrEscS/QKwK9jnjNaMYlwKshXfV74M4ItP4FHAogr0t9z8w+KjJ2w9CYPRP4Qyw7BW802xq4kMrd/jvjUl7v4LJb+5vZ68DK8swneLPVYHmt6fXAEaELfBuexcxYOeS0/oJne3c0s+3ieH8b6/wBD+7a4wYbmYHHVrGfXULibQEVDWlV5hjLDwW2wLOzx1ILJ73gIuBnoU5xkLkRxUVUuLMNprRu78l4actWcUzZOW0PjC8hI5fnMDzruS1einF1BIG/AIbGOdgWGK8SOsUF4x2Cy6R9kVu2UwT//5aU6RO3x802SvExsFfspyeV9aO74rXdWwObUtk4JOMAKlQ65pjZDsAOwIm5z9P2wG/MbHPg17hiR6f4zN9Txues0me8xPuWSCTKIJVYJBKJZQYzmyjv+u9N1VvCuwKHx3rPSVozsoOD8SDgdrwJrFQQ8GD8OxYPPLIx/xZjTpY0Mbd+bzyAJf49Fm/4ug8PkK6If3viwWgH4GlP6tKAivpXCua0IR5UrwesTEUt7K5EoG9mT0r6PJbvgQeZo2PsJniwVt0cdwMGRTA6U9JzJc5JKV4EBkq6j4rzVsjewEGqcKnLdHt3I4LHeD8nlti+FLvm5v6RpOfxQHI03pDXCHg4muF2p0KnGPx8vlQwXm+8tCNjHLBRqGvsh2eWq+g3S7ox5vJdBLONgBvkNb0LgM1zq4+y0CCWNCi2GxKvDZO0ANeoviDm0lFSpmrRIvb/XYyTfR72BAZkpRZm9pmkDlT/OSv2GS+JvNHw1wCNW7WsafVEYoUiBciJZZL58+czY8YMvvnmm6U9lR8tjRs3ZsMNN6RRo0ZLeyq15RFcKqs7sGb1qwIeELWT1ArPFl5WYr1MF7ZQR7YKUcJwOHCwpPNxVYg1JTXHg937JT0ImJm9JWkbYIqZ7VRiyLy+8PV4k9wj8oaxi6s/PITXxVbqUqphjuWS79JepGFsZn0jG78/MFZSMR3dTLf3jYJ5ldrXFGBbSQ3KyCJXnajZCEm7xZwGSvor3kj3tJkV1UWODHNX4sIjxvki9/gJSTfFelOIC7B47dRYnjXTnQV8hGevVwLyX07FdI0zepjZrNychLv/DS2Ya3dq1qEW1X/Oyv6MgxuF4KodtGi34YrbsZ9IFKHWAXLUVjUruF2VSCxRZsyYQfPmzWnbtm11P7iJEpgZn376KTNmzGDjjTeueYMyiB/2o4BNzOxSSW2Adc1sVA2b1pbbgNlmNimChoyRsf8/xvJZ2fdQ1Lr+FZhqZp/WYl8v4kYUwyRtjUt/gWdtJ5rZz7IVJd2BN37dGRnBC6nIDL8BtJK0k5m9FFnOzc0sbw6R0YKK5sNfFpnLlZL2xs0xwDWI/yXpWjP7WNIauKTYFqXmiNe7nhTP18ZLIP5JVT6KEo43YrsvY5xNzewV4BVJ++IueZk+cEYp3d4ReDnEc5Hx7AhgZu/I67AvkXRhbNMWaF9QhzwyN/c18Iz0ufKGuRlmdotccm17vLygik6xuQkIuPbwY+YOdNk5Whf4KPbfFQ92PwWeA/4s6WQz+3us3jQ3rxax/4WSfolnbzO6RpnEe/gdhZuLnOv8eTtZrpM8X9LmFG9GfTrOwzAz+z7e99p8zjIK37dEIlEGZQXIkv4J9MWvSkfj1ph/M7Ora9huH/z2ZQPgVjO7ouD1VYA78duHnwI9zYXV98JvX66M33Y6N26pNgXux2u8FgCPmlm/6sYq5/gSyx7ffPNNCo4XA0msueaafPLJJzWvXD43AQvxZqZL8R/eB/Db30sMM5tB5frOjIvxW+wTgXlUDi4H499NfWq5u5uAOyS9huvJTgHmAKfiur15HsDra++M/V1NmE6Y2Xdxy7y/XIe4Ia5pWyxwuRjPQH+OB2XZFcwluN7uMXhW/EPgy1BAuAB4KhIU82N+vauZ4374+/Qa8F+qlh1k2cJ+wGO4HvIY3AAEvO53Mzxj+SwwIcbJrJAvp7Ru799xneWpuEFF3jnvV7jM29uSvsbNOM4tmNtDuB32hJjnb83swwhKz5U0H7ejPtbcVKQPBTrFVGgd98J/S/IcgQeo3wNfA73MXO9U0iHAtZJ+G+fkK+C82O4m4AFJx+JqIfls72jgBrwJbxhV35c8t+LlD+PiovMT/M5HsfU2x8/vfOAWM7uhFp+zjGHk3rdSdcibtVw3SaklEjnK0kGWNN7MOkk6Cr9q7weMjcaBUts0wL+k9gJm4F8gvS2nvSnpFKBj3M7rhWdnekraDr/CnxkZiKFmtkEEyD8xd4paGf/i/rOZ/bvUWNUdV9JBXnaZOnUqW2211dKexo+eYudRddRBljTOzLaX9Go0mCFpQjRy/SiJ76lGZvaNXGXhGWCLaG76oeeyCrAgsoU7AX+PhrQlvZ9JeOPdtBpXTtRI3M04x+qg1b0skX4PEysqpX4Tyy2xaBS3cg7BnXrmy0X9q6Mr8HauceFe4GA8o5FxMBX1d0PwBghZZXvNKUATSauY2Tz8ajjL2IzDG16qGyvVVSVqzezZs/nnP//JKaecUutt99tvP/75z3/SsmXLsta/+OKLadasGeecc07NKy9d5kdAmWXbWuEZ5XpF9Wsg0hQvr2iEZ0tPKSc4Vv0YiLQB7ots7HfAiYszWLE5SnoamJQFx1rBDERivwOB3fE7BQB9LFzu4q7npbg19zd4ScO5ZvbfOuynOxWGJKsA95rZJYs3+9oTGfanzGxmdeu9NfsT9n/wph9mUnXg8cNq/12cSCwO5QbI/8D97CcAI6IWrKYa5A2A93PPZ+AamEXXiazJHLwpZ1ZuncOBcWb2bX5Due7pgUQHepljVerabdOmTQ2HkFhRmT17NjfddFPRAPn777+nYcPS/3WeeGK51ePvj986XlvSn/Bb1Rf8APutNwMRM/sSN1GoLfVhIPIWsN3ijpWjyhzNbK9SK9tybiBSwLlmNiS/IO5WXo9n16fGsoPwcoiSAbKZDccl9oox0swOiNro8ZIeNbPqpOSyuSxJo5A+wGSg2gA5kUhUpiwdZDPrb2YbmNl+5ryHN33UK3J9yiuBkwqWN8QNBPpnGepyMbObzfVIu7Rq1WrJTTaxXNGvXz/eeecdOnXqxLnnnsvw4cPp1q0bBx10EFtv7b/bhxxyCJ07d6Z9+/bcfHNFT07btm2ZNWsW06dPZ6uttuLEE0+kffv27L333nz99dfV7nf8+PHsuOOOdOzYkUMPPZTPP3elr/79+7P11lvTsWNHevXqBcDzzz9Pp06d6NSpE9tttx1ffvllPZ2NRc2503DN3svxDO4hZnZ/ve20MslAJBmISIthICLPUlfHeXjJ3tRsgZk9YmYjYrwT5eYeEyQ9IC/5Q9JAuTnImPgMVbmrYWZf4bXY7SRtKunJ+DyMlLRlwTivAFdJahefgwlxDJvGeueqwmTkktznbaqkW+Jz8lSc7yPwi5d74vw0qeEcJBKJoNwmvd/gGqNf4lf62+F1yE9Vs9kHeOdzxoZUzfpk68yQB70t8AY7JG2IZ6uONRfBz3Mz8JaZXVfOWIkfN5c8OoXXZi5Z0ZSt11+NPxzYvuTrV1xxBZMnT2b8+PEADB8+nHHjxjF58uRFqhC33XYba6yxBl9//TU77LADhx9+OGuuWVmV7K233mLQoEHccsst/PznP+eBBx7g6KOPLrnfY489luuvv57dd9+diy66iEsuuYTrrruOK664gmnTprHKKqswe/ZsAK655hpuvPFGdtllF+bOnUvjxo1Ljru4RFbvxqg9fr3edlSae4GLJD2GqyLcBnSL1zIDkUMk/RQ3EOkkKTMQuV05AxFVbfxsaGZd5Zq4f8Bv8y8yEJFnFsfn1l9kziEvE9jfzB6QtLKkjaN8odBA5OBoKOuJKy8cH2OtnNW+SVodNxAxSb/CL0b+HxUGIpfLSwBOiPXzBiLzJd2Eq3zcWWyOeANf3kBkHbzk7bZavA+ZgcgHklpGqdtFQBczOy3m9eeY7/HyC5RREYyfRBiISOpIhSlHXQxE1sJ1oTPFjKFm9qe4QGiqygYiX0k6DzcQuTTG+lPM+1mgX9yhbI/LC5biQTO7JY7xMvx9uD5ea4uXFW6Kl+y0y28oaU1gR7yx8Wagr7k84E/w5r+fxqobAjub2YIIlK8ws4fiAmclubrJZrEvAY/Ipe/+G8t7m9mJcv3qw83sbkmnEaUshQekvA7yWmtUc+iJxIpHuU56x5vLKWXSQ8dQtTO4kNHAZpI2jixDL1zfNM8jVHSiH4F/qVp8qT6Of3G9mN8gvpha4E5BNY5V3uElEjXTtWvXSpJp/fv3Z9ttt2XHHXfk/fff56233qqyzcYbb0ynTp0A6Ny5M9OnTy85/pw5c5g9eza77747AL/85S8ZMWIEAB07duSoo47i7rvvXlTescsuu3D22WfTv39/Zs+eXW3ZxxLiWUmHq0iEWd+Y2UQ8CCllIHJXrPccrgWcGYhkjbp1MRC5N8acjJs8ZBSac2QavJmBCPHvYCobiIzHg7YNqaDQQGSoPPN8Lh6wFc7lSVz7FyobiIyP55vUMMdFBiJRk1pXA5ETqSxzlmdvKlQThlPZQOTuOI6JVD6n5bDIQMTcKTFvIHKcpIuBbaJsZkcqDETG478NG8U4vwO2jG3XoEKlYhFyE5rxkRHOmgM6RMZ3En4hkr/Cvs/MFkaZzLsxPkA3Sa/iyaQrcBm4nXEVk/F4+eJ6uXHuj+C4OS5X91Ccr2+iB2fv+HsVv8DYkgqTk2lZLTVlGoXk76iu3GKJlXknEssF5f6iZj+I+wF3mdmUmn4kow74NFzzsQFwW2x3KTDGzB4B/g+4S9LbwGf4jxjAabhczkVxlQ/+pbAybm/6Oi6RA940eGs1YyV+5FSX6f0hWXXVVRc9Hj58OM888wwvvfQSTZs2pXv37kVNTVZZZZVFjxs0aFBjiUUpHn/8cUaMGMGjjz7Kn/70JyZNmkS/fv3Yf//9eeKJJ9hll10YOnQoW265Zc2D1Z2T8Czc95K+wb8XzMxWq8+d5kgGIgXTIRmI1NpAxMwy57lvJd0OZAHwFFylaYK5lnanCI6zyHEgXlY0Qd741j0/bOFu4t+RlmskjQu32VZanaQco5DLzewflRa6nnS+T2cBUcKSSCTqRrkZ5LGSnsID5KHxRVtj97qZPWFmm5vZpmb2p1h2UQTH2VXxkWbWzsy6ZvXEZnaZma1q7h2f/X1sZjPMTGa2VW75rdWNlUjUhebNm1db0ztnzhxWX311mjZtyuuvv87LL7+82Pts0aIFq6++OiNHjgTgrrvuYvfdd2fhwoW8//779OjRgyuvvJI5c+Ywd+5c3nnnHbbZZhvOO+88dthhB15/vX4rH8ysuZmtZGYrm9lq8fyHCo7BSwEuMbNJBcszA5FMOWCWmX0Rd5AW10AEFTcQaW1mbc1sI6J0wbwUrKSBSIzVSN5bUYyaDERQVQORIyStHa+tIW+gLjlH3MSjp6QG8lroUr0kH0naSl57vsiFTmEgYmYX4fq91RmIKLbJGg+zcoisIW6RgQiuwXxJbpu2kvanMiNzc2+FZ6RHxTF/FOUPt+JB7svALlmpg7wuevN4nNWAC79wmhzjXwWcH6UrGXmjkObA/6Js5qiCuR0pr3vfFM/iv0ER4k7sNElHZnOQVEUmMbLgM+S6zEhaRV7zPBQ4XlFPLWmD7P2vhmQUkkjUgXIzyCfgtV/vmtm8qKc6rt5mlUgsZdZcc0122WUXOnTowL777sv++1f+rd5nn30YMGAAW221FVtssQU77rjjEtnvHXfcQd++fZk3bx6bbLIJt99+OwsWLODoo49mzpw5mBlnnHEGLVu25MILL2TYsGGstNJKtG/fnn333XeJzKEUkaWrgkUTU31jyUAkGYgsGQOReyLAFl5b3hfA3LnxN8CdkemdFcf2h9j+QuCVOCevUDno/C8wCpeH62uuq00JjgL+Hu9dI7wEZkKR9Y4B/hF3XecDR5rZUxHAvxTjzwWOxi/MSjEQGBDndSdzJZgqbNayVZJSSyRylGUUAovkbrIfyOfN7NF6m9UPRBJGX3ZJRiFLhiVsFJL/P98YbxQaa2Y/LbHJjxYlA5FEmSinJb2057I4pN/DxIpKqd/EclUsrsAbGu6JRWfIveB/vwTnmEgklmHM7MD8c0mt8Uzh8kidDERqiwpMMCLr2cXMTlMYmuBZ3ioGIlFO8p2Z/aeW+zwI2NrMrsgtq2QgUs2203HZsPtxhYWhudfOxJsSr8QDxg6SDgNONbM9Yp1dcUvmLhY6v5IeBtY1s6K3YaK+NhuvC54hPqM2x5yb383R7FbuNt3xGuXTcE3pNhZSdPH6eFzjv+S2Vo8Oe3J323ymvSOwvZmNl6uXrIfbaQPsbWYflxrr7c8/5YAHBtbXVOvMY4f3WdpTSKyglFtisR/QKftikHQH3kWbAuREYsVlBrBcpvmt7gYiS3IOA3JPixmIdMdvsZcdIMsNKB6hQFHIqjEQKcEgvBF6aG5ZL1yaLj/ug5J+JekXeFB9E16CkAXHLXEljrmSNqmpd8Rcqqyuac4zcRWNsgPk3H6nS/ovLi34PIBcv7h5fQbAZczrHiJxJW8IfdgqlCwAjrIi8m6JRKJmym3SA2iZe9xiCc8jkUgs40i6XlL/+LsBb5qq0RUsUTdU2dDkDLlpyUS52UZbvHb2LLkcWbdobHsu1nlWUpvYttCAok+8f8iNUx6Sm1FMkLRzLH9YbmQxRa6VW8gQYH+5hGeW5V0f/0wUchquIHIxMLog430Y8Cheh7tIeUhurjJB0gS8rjpb3l2uhV3p/MTzyXEOVpX0eGw/WW5eckbMb5ikYbF+USMRSftIel3SuJhfRnZRkNELuFduFHO73LzkVUlVGh+rmWvb2NdAuaTcPZL2lPSi3Nima6xf1HylgLy0XyKRWEzKzSBfDrwaXyzCa5H71dusEonEskg+E/U9rkn7YqmVE2XRJG7TZ6xBVb148O/bjc3sW7lBx2xJA4C5ZnYNLKoRv8PM7pB0PN7QeEhsnzeg6JMbtz/eU3KovO46K/c43sw+kzuvjZb0QF4FJF4bBewL/AsPFu8zM1NBc5qZvStpMB4ob1pwXL1x846P8EbCP8fy24HTzCXcri518kqwDzDTzPaP89LCzOZIOhvoEc2NRY1EJF0F3II3Mr5NZZ3q+3C76NMjA94Tdys81Q/Ttoms8lMKxYwyaRfjHI83lP4C13w+CL9Lewgub1rFfMXcoS+jJ1AYON8uaQF+bi+zgqYj5YxCmqxVjnJiIrHiUK7V9CBceP1B/D/aTmZWSnQ/kUgsn7Q0szvi7x4ze1He9Z+oO1/nJCs74U51xZiIqy8cjV+cFGMn4J/x+C48yMq434prDP8UV5fA3IBjTiw/I7K3L+NSbpsV2TafUe1Fzv47TwTee+HlIBvllq8T475gZm8C8yV1iACwZU4d5a4Sx1uKSbi99pWSuuWOKU8pI5EtccONtyKYvDvbwNycZDKwh6ROwPfmJjK7UmGA8jpuBlKbAHmamU2KEsYpwLOx70lUmH2UMl8BQK5NPS/mk3GUmW2Dl4V0w1UxKmF5o5DVkhJcIpGn2gBZ0vbZH17sPyP+1o9liURixeGXRZb1+aEnsYKyP3AjrvE7WlJtbRNrMqBYhLy5bE88EbIt3m9SzMf8X3iwuD3Q1MzGFlkH3LZ7Ei4XeqMqUsw/xzWdp8mb/9pS4fhXDt9T+TesMUAE29vHPi9ThdlUHuFGItnFydZmdkIZ+8wuCkpeENRmrkHe4GNh7vlCKu7yZuYr2XzbmNnU3HZV5mNmH8S/X+IXTl1rMd9EYoWnpgzyX6r5q86zPpFY4WjWzO9Oz5w5kyOOOKLoOt27d6eYlFKp5csCknrH7fuNJT2S+xuGu1Ym6hG5ekVrMxuG2yK3wEshCg0g/kNFRvcoitcDF/Isro+M3ICjRYz/ubnm/ZZ4trUKZjYXGIYbuJTKHq+Luy/+1twm+wNc8xg8GN7H3MykLd6s18vMZgOz5YoX2bEUYzoeCBNB+sbxeH08m3o3rkmdJXPy56uUkcjrQFu5tF82xzwP4k3rPamo980b1WyOZ3YLjUKKzrUWlDJfyT4fP8/NB0kNo4wEuRLLAVQYoiQSiTKoNgthZqVclhKJRAnWX399hgz5UUuiFvIf4H/AWvjFccaX+K3/RP3SALg7glcB/aMG+VFgSDRsnR5/t0s6FzezKMfM6TfAzZJOwM0mTgaeBPrKDT3ewIPJUgzCDTx6lXj9r8BVZvZJPD8TGClpLF7SsGhsM5smaU6UCxyHm78Y8FTBmFkd7QPAsZKm4MYdb8bybXBDk4W4wcbJsfxm4ElJM82sh4oYiZjZm1GX+7ikeXjwu+giJM77S7gsXaa4cRNu/DEJzxT3iVrx/JxLzbVcSpmvgPcEvV+gALIK7nrbCP/8PIPXVpek3eprJkm1RCJHWUYhci3LQubgupkldRWXdZIw+rLL0jYK6devH61bt+bUU72B/uKLL6ZZs2b07duXgw8+mM8//5z58+dz2WWXcfDB3hfTrFkz5s6dy/Tp0znggAOYPHkyX3/9NccddxwTJkxgyy23ZObMmdx444106VJZQax79+5cc801dOnShUGDBvHnP/8ZM2P//ffnyiuvZMGCBZxwwgmMGTMGSRx//PGcddZZ9O/fnwEDBtCwYUO23npr7r23chP7kjQKSSSWNpIOx81MipX7JBaDlptuarteefnSnkYlHjvi50t7CokVgFK/ibWxmt4Jv50Grr85Fr/leqmZ1baJIpEon3/3gw8nLdkx190G9r2i5Ms9e/bkzDPPXBQg33fffQwdOpTGjRvz0EMPsdpqqzFr1ix23HFHDjroIAo79zP+/ve/07RpU6ZOncrEiRPZfvvqS/dnzpzJeeedx9ixY1l99dXZe++9efjhh2ndujUffPABkyf7XdLZs2cDcMUVVzBt2jRWWWWVRcvqC0k7Atfj2scr45mpr8xstXrd8QqIyjAQMbM7S2zbnSVkIFKLbadTzwYiMb8/4WoPPwYDkZPM7JVS29anfnKcm+wOAMDLZta3vvaXSCyPlKuD3BDYyswON7PD8e5fA36C18QlEssV2223HR9//DEzZ85kwoQJrL766rRu3Roz4/e//z0dO3Zkzz335IMPPuCjjz4qOc6IESM4+uijAejYsSMdO3asdr+jR4+me/futGrVioYNG3LUUUcxYsQINtlkE959911OP/10nnzySVZbbbVFYx511FHcfffdNGxY276tWnMDXpP5FtAEryW9sb53mqiMmQ0oFRwH3YGdazOmwkCkLsFxAYVawVC8gexB4FtJv4gygJtwt8JCA5EWkjaJbR4xsy2LBf5mNqYuwXFwJu6cWGvMbDqQGYgAlQxEqgTHPzDv5Jr6UnCcSNSScn9RW4fETcbHsewzSfPrYV6JRAXVZHrrkyOPPJIhQ4bw4Ycf0rNnTwDuuecePvnkE8aOHUujRo1o27Yt33zzTb3PZfXVV2fChAkMHTqUAQMGcN9993Hbbbfx+OOPM2LECB599FH+9Kc/MWnSpHoNlM3sbUkNQjLsdkmvAr+rtx0mqiDpYkL/WG6A0RevfX0N10vuCywISbjTgffxRrq1iNpkM/uvpIHAN7hL34uSJlKRpV4HGABsErs92cz+E1nd1rgKw9/M7OaC6Q3BlSNWNrPvVNlAZKOCdU/Da2PbU9pA5CM8wP5zHHvnOBbI1Sbns7L58xOvTcbrdT/BtYw3xO9+/BFYhwoDkVlRm7w3cAlex/tOnK+5kvbB64Dn4VnjjOyi4Pl4vshABJfQ64K/P2dHo+UiqpkreC34y/jFzmhcG/oSYG1cwm2UpFXxuzodgEbAxWb2LxKJxGJTbgZ5uKTHJP1S0i9xIfvh8Z9zdr3NLpFYivTs2ZN7772XIUOGcOSRRwIwZ84c1l57bRo1asSwYcN47733qh1jt91245//dGnayZMnM3Fi9T1tXbt25fnnn2fWrFksWLCAQYMGsfvuuzNr1iwWLlzI4YcfzmWXXca4ceNYuHAh77//Pj169ODKK69kzpw5zJ07d8kcfHHmyZ3Txku6StJZ1M6NM1E+TeQOeePjdv2lJdbrB2xnZh1xC+fpeGB7bWQOR+IB1B2xzj24OUhGZiBydsG4mYHItrj6wpRYfryZdcaDvjMkVXKXMLPPgMxABHIGIoUTj6ayzECk8E5kbzzwHERlJYnbgdNjXrUlMxDZ1sw6AE+aWX9gJm4g0kOVDUS2x81xzo5g9xbgQDyzvW5u3PuAQ1Qhvdcz5r3IQCSO4Y4Yp1za4U2xW8ZfZiByDm4gAhUGIl2BHnhz4qrx2sZy173nJXWjCJJ+LWmMpDHfffFFLaaWSCz/lJtqOhW/os9kd+4AHogvvaR0kVguad++PV9++SUbbLAB6623HgBHHXUUBx54INtssw1dunRhyy23rHaMk08+meOOO46tttqKrbbais6dO1e7/nrrrccVV1xBjx49FjXpHXzwwUyYMIHjjjuOhQu9zPHyyy9nwYIFHH300cyZMwcz44wzzqBly5ZL5NhLcAweEJ8GnIVnEg+vzx2uwHxtbhwCVNQgF1kvMxB5GHi4xFg7UWGZfBdwVe616gxEjgU3EMGbssGD4kPjcWYg8mnBtllGNXPYK6ovrKoGIrNied5AxCTNl9QB1+AvNBDZt+rIJZkE/EVSVgtdTAYvbyACXmv/EjkDkZjj3YQDnZl9FJnfPSR9RBiISPojfnGCmb0uqU4GIrG/RQYioZbRNtbZGzhIFTbWmYHIu3hd9KeRdX9YUnszqxQFxx2Am8Gb9Goxt0RiuaesADn+U74AfIfXHo8qlhFIJJY3Jk2q3By41lpr8dJLLxVdN8vetm3bdlEzXZMmTaooSxRj+PDhix737t2b3r0ry69uu+22jBs3rsp2L7zwQpVl9YWZvSe3Hl7PzC75wXacqI79cZmvA4HzJW1Ty+3raiAyT9JwShuIXKvyDUQuwA1EdorflbyBCMBqeAa2XMvpkgYiMaf98DKQZ82sMDOfGYhU+g8od86rjuyi4COWjoFIoe7you3NbKykd/DgPMk2JRJlUlaALOnn+JfTcPw/5PWSzjWz5UrsNZFIlEbSgbhB0Mr47dtOwKVmdtBSndgKinIGIpHA6EWFgUheWSQzELmL2huIXBeZ3mbUwkBEbiJTjoFIVzP7RNKJeNPnLVQYiLwU624MPGNm50uaLWlXM3uB6g1EDohtCw1EPjOzuyXNpsKwJDMQmYXX/N4oqV3U268KbEDOQMTM3qG4gcjleH3yHrEsMxB5TpUNRHaqaa61IDMQOT0SWduZ2auSWsWxLogmx83wrHJJ2q2+epJVSyRylFticT6wg4XmcfznewZvyEgkEisGF+N2tcMBzGx8BC+JpUMyEKlMMhCpMBDZDbhU3kS/EK9PT66XiUQtKNcoZFI0GmTPVwIm5Jf9GElGIcsuS9soZHlhSRqFSHrZzHaU9KqZbRfLJkbzV6KORDb1OmAHvOn5I7ye+CCrR63c2PcTwC/M7Z1ru213vJxiGl4a8JiZnVPDNocAb5rZa/H8UmCEmT1Tw3Zr4W6Op5vZgCKvHw5cCNwd6h5ljVtknLZ40+I/a7ndQPz4h0Qj61V4oGq4usipZjajNmOWsc+9gCvwOzrfAeea2XPx2nBgPeDrWH1vq8HUq+Wmm9luV167JKe4WDxyRL1+9BOJRZT6TSw3g/ykpKFU3C7rCTyxpCaXSBTDzEoacCRqph7aBKZI+gXQQNJmwBn47ftEHZF/wB/CVSZ6xbJtgR+kbMXM9lvMIUaGtFoT4FVJD5nZi9WsfwjwGB40YmYXlbmfI/Gscm9cpWMRqjAQWbTfWoxbSFtcLaJWAXIBf8azy1tEicNxwIOSfrKEe3dmAQea2cxoYhyKl4NkHGVmKQOUSNSRsiSazOxc/DZUx/i72cySQUii3mjcuDGffvppfQR5KwRmxqeffkrjxrVRlSqOpMwp8x1cs/Zb/GL5C/zWeKLu9ADm57OiZjYBv4XfTNIQSa9LuieCaSRdJGm0pMmSbs4tHy7pSkmjJL2pkPaS1FTSfZJek/SQpFfkznNImi5pLUltJU2VdIukKZKeiqAXSTtImiiXnLtarthQCTP7GhhPBGiSTow5TpD0QMxhZzzwvzrG2lTSQElHxDZ7yGXJJkm6LVfiAB4Y/z9gA0kbZgslnY/Xxc8iZ/ZRMO70yEAjqUtkV5G0uyqk9F6V1BzPyHaLZWdJahDHPDrOwUmxrSTdIOkNSc/g2sRIaoqXgZyVqYOY2e34/5mfxnnO3s+p8f42jW07yyXZxkoaKmm96t5XM3vVzGbGIU/BpQHz5yyRSCwGZTsKmNkDeL1UIlHvbLjhhsyYMYNPPvmk5pUTRWncuDEbbrhhzSvWTGd5g1NPPKD7S+61prjZRKJudABKqTxsh1+QzMSzo7vgBhU3ZOoLcfFyAG6qAdDQzLpK2g/4A646cQreXLd1ZBrHl9jfZkBvMztR0n24hN/duPbwiWb2kqSirj2SVo/tMwm2B83slnjtMuAEM7te0iNEKUK8lm3fGBgI7BH1vndS0STYGldOGRXz6onLtXXGa5w74b9l46o5l8U4By99eFFSM/xz3I+cDbS87niOme0QweeLkp7C35stcEm4dfCM+G24dvF/C+XUcPWI9vhF5hZxPl6UdBtwiqS/4ZJwB0fTYk9yttoUf1/zHA6MM7O88sXtkhbgv9uXJeWpRKJ2VBsgS/qSisaHSi/h6m+rFXktkVhsGjVqxMYbp/6vZYQBuKrBJlSWiRL+/bBJsY0Si82orG5VbhbSFg+Qe0j6LX5xsgaePcwC5Afj37FUaOXuCvwNIPR5S7nVTDOz8fnt5ZbPzTNFCbz0IF8c2k3SBDw4vs7MPozlHSIwbokrYAyt4Vi3iP1nTWp34Pr71+EB8X2x/F48EP0Lbu/8kJnNA4jguza8CPxV0j14QD9DVUu69gY6ZtloXMljM7wJblBkiWdKeq4W+30/V4ZyN16q9CR+sfR0zKEBXnOdUex9BUBSe+DKmGvGUWb2QWTFH8A1zKvYk8cFwK8BmqzVqhaHkEgs/1QbIJtZ8+peTyQSyz/mbmP9Jf3dzE6ucYNEbZgCHFHitXw2cAHQMDKtN+GW0O/LrYqLaecuoBZ3CEvsr0kZ22Q1yBsDL0u6L4LsgcAhZjZBrgrRvZZzydMbWFdSJuu2vrwGvlzyWsOLzpWZXSHpcVwX+UVJPyuyrfDGwEoBfmRyi/EO0EZSczP7Mre8M157DVWTThb7mWJmO1Gcou9rlJs8BBwb8nPZsX0Q/34p6Z+4+kyVANkqGYVsljLMiUSOZBObSCTKIgXH9cJzwCqRyQNAUkc8O1qMLMCbFWUBpYLrPC/i5htI2hqXOyuLULf4Ui6xBiVk28xsGl6/m/WmNAf+J6kRlfWKM83hQt7AM9bt4vkxwPNy/eBmZraBmbU1s7a43nBvvJzjEElNIlN6YInDmI4HqJBzfpRrGk8ysyuB0bhbXuH8hgInx3EgaXO5NvIIoGfUKK9HOMqa2Vd49vuvcv1oJB2LZ/uzLHMbSVkg/Av8rsAbQKtsuaRGkRkuSWT3Hwf65RsjJTXM1Vw3wjP+VerGE4lE9dQ2w5BIJBKJJUSYOxyK19qeh9fBTqeEbXTo7d6CBzwf4oFdTdwE3CHpNdzwYgoV1tHlcAJwi1w/+Plqth0AnCOXSrsQ1/X9JP7Ngs57Y6wzyAX3ZvaNXO3hfkkN47gG4DXBDxXs5wFgsJldKmkwMAH4mKrnIsuIXgL8n9z6eXju9TMl9cB1gqcA/47HC6JsZCBemtIWGCevffgEV+J4CLfjfg34L25HnfE7vHHwzThnrwOHxnsNHgyfGvXHrwF/N7Pvooyjv1zXuiFeXjKl8CTnOA2veb5IUqbasTfujjg0guMGuGfBLdWMA0C71VskabVEIkdZOsh1HlzaB/+CaQDcamZXFLy+Cn7bpzPwKdDTzKaren3HPwHHAqubWbPcWBvhtWmtgM+Ao2vSnUw6yIkVEdVRBznx4yQymY0iCN0UD5i2MLPvyty+mZnNjcf98Ia539TfjBcfuVnKX81s2NKeS564eHjMzDos7bkUkn4PEysqpX4T6y2DHF/KNwJ7ATOA0ZIeyQTigxPw7up2knrhjQY9qV7f8VHgBuCtgl1eA9xpZndI+il+G+6Yejq8RCKxjCB3VbvHzI6O5w3xBqdXrA5GG5L6AvPMrErNZi3G6AS8CuxrZk/WdZwlRFNgWGQUBZwSGctO1DBHuQHGZ/Gd2gaYRHllHfkxOgHrm1mttPPlcmznmNkYSdPxuutZZWx3G37ML5R4vTsVBifgDXqZKsg6wLW4jfbneILmKjMrzGKXewzT8bINwzP+59dlnMWh3PP/zudfcugDz/8wkyqDhw7ffWlPIbGCU58lFl2Bty1sNyXdCxxMCMQHB+P2teC21TdIkpm9mltnkb6jmX1rZi/HeIX72xo4Ox4Po8QtykQisdzxFa6a0CT0ePcCPqjrYFbEqa0O9MYDtN64QsFiIamhmX1fl22jWazYHYNy5/gfMzu7mtdrolPs/wcxlzKz42tey5sL8wuihOJh3LTlF7FsIxbftKWHmc2S9GfgmHKyx4vzfhehEz/g+U8klhfqs0lvA+D93PMZVHb5qbROfBnMAdYsWKeYvmMxJgCHxeNDgeaSCsdC0q8ljZE0JmnsJhLLDU8A+8fj3lS4fiJpDUkPy40eXpbUUdJKcgOJlrn13pK0jqSLJZ0Ty+piviHc+a0PsJekxpK2lDQqt6+2kibF4+oMIq6TNAb4jaQDYz+vSnomsp1IaiXpabnBx62S3ss1aR0dcx8v6R+qaByrMsdsuYoYYOTmkx3j3NzyIyLTjKQj5QYmEySNkNsuX4o3tI2X1FPSqnIjkFFxLAfHtk0k3Ss30HiIGlQ04hw+F+/rs5LayJvmpsVxtJS0QNJusf4IVa9+8VPguwLTlvfM7Prc/kZKGhd/O8fy7jH243HeBkgq9ts6Amin0uYj3WP8R4DXYr1r4nxOlHR6GZ+XSp/VYue/unOaSCQqWKZVLFSh73hSGaufA+wu6VVgdzyDtKBwJTO72cy6mFmXVq2S7mMisZxwL9ArAr2OeGNYxiXAq2bWEfg9Xoq1EL/NfiiAXKXhPTP7qMjYDc2sK+4a+IdYtsh8A29I65xbf2dc0/cdvClsfzN7HVhZLocGXko2WF72cD1whJl1xvso/pQba+X4vvoLnu3d0cy2i+P9bazzB+A5M2uP34lrE8e0VexnFzPrhH8fZooSVeYYyw+lwgDj2FivNlwE/MzMtgUOijrni/Cmuk5mNhgvM3guzmkP3FlvVdwYZJ6ZbRXH1Ln4LhZxPZ7t7QjcA/QPXeI3Yv674uYh3eT9Lq3NLCvN2ymC+H+rQi2ifaxfio+Bvcxse/y89s+91hU4Pfa7KRXJmjwH4CUqJxDmI8AOwIm5z8X2wG/MbHNcn7gt0Ck7xjI+L5U+qyXO/yKUSxh9+0Vt+jYTieWf+iyx+ABonXu+IVVve2brzJDXDbbAm/VK6juWwtxy87DYthlweEgUJRKJ5RwzmyhvgOpN1VvJuxLyXmb2nKQ1Ja0GDMaDh9tx+bLBFKe25hu98QCW+PdYXHkhc4G7Iv7tiQej1RlE5Oe0IR5Ur4c3MGc1tLsSgb6ZPSnp81i+Bx5kjo6xm+BBXnVzXBwDDHBJuYFyx7sHS6yzN3CQIkuPS9e1iX33j+OYqNKGJhk7URGI3gVcFY9Hxlgb470oJ+LqG5nKxThgIzObK9czfhg3/6iEpBvxc/tdBLON8DLATvjFxua51UflygkHxXZD4rVhcke7icAFwK0UNx/5LsbJ3tc9gQFZqYWZfSbvyamToUgx8jrIq2+6RdJBTiRy1GeAPBrYLK6MP8B/gH5RsM4jwC9xiZwj8KyCqYS+Y3XIbyl+Fpmh3+FX1olEYsXhEbxZtztVS7WK8RJ+y7sVLt11WYn1yjbfkJcwHA4cLOl8vCluTblO72BcxuxBXOHtLUnbUL1BxFe5x9fjygyPyBvNLq7+8BCeYf1dLeZYLvlgKm++0Tey8fsDY+V20MXmdbiZvVEwr1rsvlpG4Nno9fELoHPxz8TImOMiG2gze0LSTfH7MYWcTrKZnRrLM2mHs4CPgG3xu695i/Vi5h8ZPfLNhfIDLWY+0p3K73cx6mQokkgkak+9lVjEVe9puALFVOA+M5si6VJJWdPD/+FfzG/jDXb9Ynle33F8/K0NIOkqSTOAppJmyJ2kwL8A35D0JrAOlW87JRKJ5Z/bgEvMbFLB8pFEaUEEIbPM7AszM/wu1V+BqWb2aS32Vcp8Yw9gopm1Nje22AjPzB4ad8IW4CUZWWa4NgYRLai4C/fLEnPZG1g9lj8LHJH77lxD3nRWco6UMMAowkeStopa20OzhXLzjVfM7CJcM7g1xc03To9AEUnbxfIRRBIlMqUdS+w74z9UGJccRQTAwCi8NGShmX0DjMfL9EbE2Ovm9t0V/x38FDfyaCwpb4jTNPe4BfC/SMIcg2dvM7pK2jjOR09KKGjkjr+Y+UghTwMnxd1VJK1BHQxFKG3OkkgkqqFerzBDVuaJgmUX5R5/gzeKFG53GSWyOWb2Wypq7/LLh1BxSyuRSKxgmOue9y/y0sXAbXHLfh6Vg8vB+N2uPrXcXSnzjVMpbmxxMq75Phi4Gr/9j9XOIOJiPAP9OR7MZXWrlwCDJB2DZ8U/BL4M5YQLgKcicJsf8+tdzRz3o7QBBlRkRvvh1smf4BnWTJP+ankjnPAAfUKM00/SeLzk4Y9xjBNjXtPw+ty/A7dLmoonVcYW7Hui3HgDvFzl9Fj/3JjHcXFOv5X0PvByrDsyjjm7cDoCD1C/B74GesXFEpIOAa6V9NsY8ysq3AFvAh6QO+M9SeVs72hcfrQdrqJUnSzcrRQ3Hym23uZx3POBW8zshlp8XjKGkTv/hXXIGZuu3jxJqyUSOerVKGRZJwmjJ1ZElIxCFhstpvnGEp7LKsACM/s+Mot/j6a8Jb2fSXjj3bQaV16BiLsS5xTKxv3YWH3T9rbHVf9c2tNYxJDDt13aU0isIJT6TVymVSwSiURiGaUp8ILckvghwnyjLgPFLf97Jb0jl+56Qq4u8FiZQ7TBG/Em4Bn0E2ux7yeUk7qrZr2ngUn54FguSzYnSuBel3RNGeMcEiUp2fNLJe1ZxnZrSZovN3EptU5enq+scYuM0VZSYa9MOWwbmd2s7OEKuWzgOEkvSdo3Xpsedc1LBEmDc2WI0yNLnB3H17nXloS2dyKxQpGK+BOJRKKWWGnzjVoRt9gfwpvpesWybamFOUVIl21X44rFt92vzPX2KvHSSDM7QFIT4FVJD9XQWH0IXprxWox7UTXr5jkSL5noDdQY7NVi3ELa4nXQZadSzWy4pGdzi/4IrAd0iHKPdXDp0SWOmS3SNZb0F7zMJ+Od+riTkEisKKQMciKRSCw9egDzrbI5xQS8braZpCGRnb0n11h2kdxkYrKkm3PL62JqMj2ys23lBh23yA1HnoqgF0k7yI0qxssNLiYXHoS5g+F4wgxK0okxxwmSHog57IwH/lfHWJtKGpjLvO4hNw6ZJDcSWSW3i97A/wM2kEuAEtucH8f6Ai6Zly3Pj7soayupi9zCGkm75zKsr8pVPK7AdZPHSzpLpU09pCKGKpKa4hn80y3MrczsIzO7r/CcSTo73sPJks6MZavKDUcmxPKesbyoOUhuLOGNmoMK95NIJOpGCpATiURi6dGBqs1oGdvhhg9bA5sAu8TyG8xsB3PL4iZ4g1tGbU1N8mwG3BiGI7OpkDy7HTgpZzZSBUmrx/YjYtGDMcdt8Ya7E8zsP7gU37lhWvFObvvGwECgp5ltg9/dPDleaw2sZ2ajqNCSRi4h1wu3Ut4PN92oDecAp8ZxdcMb9vrhWfFOZnYtpU09ShmqtAP+m5eSK3G+OuNNhT8BdoxxtwP2AWaa2bbx/j6pms1BiPl/ZBVGKAAbR+D/fHaxVGQeOaOQz4utkkissKQAOZFIJJZNRpnZjJAVG0+F8UOPyAJPwhUn8jJfpUxN7gU3NcENK4oxzczG57eX1yc3N7NMzaKw9KCbvPb5A2ComX0YyzvIbZMn4RJsNUmRbRH7fzOe34GbfYAHxFkG9l48mwweFD5kZvMiIH2khn0U8iLwV0lnAC0zQ44C9gaOldf2voLra29GzlDF3KSqtoYqu8bcvzKzufj71g1X2tgr7gR0M7M5VDaTGY+bjWxYMF4le3XcPKSNuevi2cA/5eY4lbCcs+wqq61e+HIisUKTapATiURi6TEFlx0rxre5xwuAhpFpvQnoYmbvy3XgGxfZpi5GEYX7a1LGNlkN8sbAy5LuiyB7IHCImU2Q1AfXqa8rvYF1JWU22evLpeTK5XsqkkF5U5MrJD2OZ59flPSzItuWMvUoVbv9NtBG0mo1ZZGLYWZvSto+5nSZvLb5IaoxB5HrJB9G7s5AlHdkJR5jJb2DS8Yl2aZEokxSgJxIJBJLj+eAP0v6tbntL5I64tnEYmQB3ixJzfDguib998xIZJgqm5rUiJnNlvSlpJ+Y2StUGHMUrjdN0hW4ZnBv3Jjif1EecBQVBielTCvewDPW7czsbdyI43lJmwPNzGyDbEVJl8Q+HsNtrS/Hf8sOBP5RZOzpePD4b3JOeXJTk0nAJEk7AFsC71PV1ORkSc+Z2fyYzwd4KclJku7A6497AP80s3mS/g/4m6STQue6FdDdzO7PjTsy5n4FHoQfChwjaX3cEfZuSbOBX+F10a0k7WRmL8U53dzMMu3jPYHXQwc8O7ZWMc4CSZvgWe93i5ybRWy6epMkrZZI5EglFolEIrGUCIOKQ4E95TJvU3AzjQ9LrD8buAWYjAdvo8vYzU14gPUabsCUmZqUywnALXF7f9Vqth0A7CapLV7r/AoenL+eW+de4Nyojd00WximUcfhRiiTgIUxXilTk95mNg43XpmAB7+F5yIT+b8ED1jHULmG+sxohJuIm6j8Gy8/WRBNcmfhZh2v4aYek/EAvGHM6a147U4qG6pcgJt/vBbbPAZUyibH3Afirn+vALea2av4xcuoONd/AC4L+cAjgCujnGU8FTXP4Bcthc15u+EGI+PxC6i+ZvYZiUSibJJRSDIKSaxgKBmFLFdImmtmzXLP++AlGKfJdYO/BgYXMzWRm1x8Fw10pcZvFnWySOqHS5g9C2xtZlfUYb7TcYm8+4Er8uULoeawBXAl8JiZdZB0GN5Mt0essyvuWtclqxuW9DCwrpntGM8fBf5qZsPiedvceF2AY83sjDrM/UzgZjObV4ttupMzEpG79V0KNMLLPy40s4drO5cy9jscf6++jkV7m9nHpdZfp11H63n140t6GrWm/6Gtl/YUEisYpX4TU4lFIpFILKeY2QC5fNkLcWteVDY16Q7MBUoGyMD+kn6H/168hytSfEjtm+IKGYRnP/P1vb2A3xYcw4OSfiU38Lgfz4j3zQXHLfESirlRTnABYeRSbKdmNoa61+KeCdyNW5bXGrnG9TXAXlGWsjHefPeumZVqnlwcjorjTSQStSSVWCQSicRySjTxnRTZkf/Dg9wr5c59bYG+wFly3d9ucj3k5+Sav89KamNmg/Hb+i8AawG/ldRH0g2xj3Xk+soT4m/nWP6wXLd3iqRfF5neEDz4XjnWbwusj9fnFnIaXh5yMTC6ION9GPAoXr7Ry8yOj2xzx2xOwKm5c9Jd4VKonPtePJ8c56CKHrFc7WJ9vJY7y0zvLXfKGyfp/qgLR9I+cv3qcTG/jHOAP1s4Esa/lwPnxnbDJf0t3o/JkrrG8lXl2tCjojzl4FjeR9KDkp6UO/ddVeTcJRKJOpAC5EQikfhx00QVhhfj8dv3xegHbGdmHfEM7HS8zvfa0P0dievt3hHr3INbV2dsCOxsZmcXjNsfeD40j7fHa5wBjg/d3i7AGZLWzG8UNbGjgH1jUS/gPitS92dm7+L1xqfhjYB5MomzQVRIwIHrN58e86otVfSIzaw/MBPoYWY95OYjFwB7mtn2eFb6bLnSyC1402BnYN3cuO2pqns9hsoyeE1Dm/kUXPMY4HzgOXON6x642cqq8VonXApvG6CnXDd60TmIz8WFkhvKJBKJ8kgBciKRSPy4+ToC3E4RWJWyWZ4I3CPpaLz2tRg7UaF1fBeu15txv5kVMwr5KfB3gNAFzpr4zojs7ctAa1xJoZCszAKKN5sBIKkBsBdeDrJRbvk6Me4LoaE8X1KHKLtoaWaZccldJY63FMX0iAvZETcKeTEuTH4Zc9sS13R+K4L9u2u570EAMffV4lj2BvrFfobjaiZtYv1nzWxONDq+RsX5OcrcdKVb/B1TuCPljEK+/iL18CUSeVKAnEgkEisG+wM34lne0XL93NrwVbkrRmPansBOkcF9lcp6zRn/AvaQa/82NbNSroKn4EHrCcCNuWzoz4HVgWnR/NeWylnkmshrJJPNMYLt7WOfl0kqdtEh4OncxcnWZnZCDft7japOhp2pyLpDhfpG/rmAw3P7amNmU+P1KnrZcQwfxL9f4hc9XQsnYzmjkCarrVHD1BOJFYsUICcSicRyjqSVgNah6nAe0AJoRlVd4v9QkdE9iuL1wIU8S4UtdANJLWL8z0MXeEs821qFUMcYhpcSlMoer4u7wf3WzJ7EdYh/FS/3BvYxs7Zm1hYPNnuFHN7sULzIjqUY0/FAmAjSN47H6wPzzOxu4OpsHSqfr5eBXSS1i21Wleskv45rOmcydvmA/Rrgd1FvndVd/x74S26dzEp7V9zmeg7eyHh6dmEgt6UuiaSGUQKCvDnzAFwaMJFIlElSsUgkEonlnwbA3RG8CugfJiCPAkOi6ev0+Ltd0rm4lu9xZYz9G+BmSSfgGcyTgSeBvpKm4iYgL1ez/SBcV7ioCQnwV+AqM/sknp8JjJQ0Fi8nWDR2KEPMkfSTmPttkgx4qmDMLEv7AG4lPQXXI86srrfB63wX4hrJJ8fym4EnJc2MOuQ+wCBJq8TrF5i74f0aeFzSPPwio3nMb7yk84BHI3Cdjwf+43Nz+0bSq7gM3PGx7I/Adbi28UrANDzoLcUqwNDYRwNc2u+WatandcuVk8RaIpEj6SAnHeTECoaSDnJiBUbS4cBBZvbLpT2XQuTaxecsDWm29HuYWFEp9ZuYMsiJRKJeiQzePWZ2dDxvCPwPeCUzT6jleH3x2993LsacOuF1sfvGbftljnLmKGkgboAxRNKtuDnGa3XYz/pm9kQttxuOy5adCrxsZv/IvXYILi+3b3Xb1mcgKGlR5ha3gx6Fl3JcC6wh1yQGeNDMLo1t1onXdwQ+B77Ds9eFbn7lzmE6XpZhuDvisaEh/YNR7vv7yez5DHjwox9mUkXoe9g6S23fiUQxUg1yIpGob74COkhqEs/3wutI64SZDVic4Djojev61qahqyR1aHgrh1rN0cx+VdvgOOgE7FeH7TLyShQZJRUpfijMrFtO2eMlPBB+BDgWGJ5reMuCYwEPAyPMbJOQqOuFy9stDj1CNm8MXm9c3Zy7m9mYJfx56sTivb+JxApJCpATicQPwRO4igJU6NYCIGkNuanEREkvS+ooaSVJ00PiKlvvLbkpxSJzB7mxwpVhoPCmpG6xvKmk+yS9JjexeEVuMZwFQkcCfXApr8aStpQ0KrevtpImxePOkp6Xm14MlbRebt/XSRoD/EbSgbGfVyU9E9lIJLWS9LTcMONWSe/lGqiOjrmPl/QPuZxZ0TlmyyXdIOkNSc/gmVFy88mOcW5u+RGRaUbSkXIDigmSRshNOi7F9XPHyw0xSplSNJEbjEyV9BCQXfA8C2yZOy+r4goWD0vaI8aYFGNmtbrk5ldqrgMl/T0+E+/KDT5ui/0PzG1T1Kwj9/pquBTdw4X7LuCnuO32gGyBmb1nZtfHOG0ljYz9jFOFIUr3OJePx/syQF4nXMgIoJ28kfFqSaPjM39SbpyRkh4BXov1ron3a6Kk02O96j6Plf4vFHt/azgHiUQiSAFyNYz77+d8v2Dh0p5GIrE8cC/QKwK9jnhDVMYlwKuRZfs9cKeZLcQlwA4FkDddvWdmxe4BNwwDhTOBP8SyU3AVha2BC6ksrbUzrlP7Dq4pu7+ZvQ6sLLf+BVcSGCxvcroeOCIyircBf8qNtXLIZP0Fz/buaGbbxfFmlsl/wE0e2uPucW3imLaK/ewSWc4FVKgtVJljLD8U2ALX3z021qsNFwE/C+m1g8wtpy8CBkc2dTClTSlOxktbtopj6gyufYw3u/089nFgzPk7YCDQM/R4G1LR7FYuq+PazGfh1tbX4qYa20jqpBJmHQVjHIJrBX+RW7ZTXCT8W1Jm0tEeGFfNXD7GLaK3x9+3vIlKV7zBcWtgUyq752UcQIVU3Rwz2wHYATgx97nbHviNmW0O/BqXresU/zfuKePzWOn/Qon3dxHK6SDPnZN0kBOJPClALsHM2V/T6+aXOXzAS7zzydyaN0gkEiUxs4lUaNQW1kLuShg5mNlzwJqR9RtMSF7ht7oHU5wH49+xsY9szHtjzMm4SUZG7+y1+DcrYbgvt7+esb8tgA7A03KThguofMs9P6cNceWASbh1cBZ45efyJF7bCrAHHmSOjrH3ADapYY67AYPCkGMm8FzRM1KaF4GBkk7E1Q2KUcqUYjfC9CLez/w5LWb4sQUe5GfKEHfEGLXh0TDbmAR8ZGaT4uJpCv5elzLryFPpjgUeBG8UFwnXUyKzLOnGCKJHx6JGwC3x/t4f+80YZWbvxsXCICobrAyLua2G20rvjStnjMcvFNekwkRllIUNNZ6F/4eZfQ+LnAdr+jwW+79QkrwOcrMWSQc5kciTmvRKsH7LJvzlyG254OHJ7N9/JL/bdyuO2XEjVlopuXUmEnXkEVwHtjseFNTES/gt6VZ4FvCyEutlRgmLTBJKESUMhwMHSzoflzxbU1JzPNi9X9KDgJnZW5K2AaaY2U4lhsybZ1yPN8k9IjfKuLj6w0O4rfPvajHHcsnLEy0y6DCzvpGN3x8YK6nQtCKb1+Fm9kbBvKrb33+A9eSNbzvjQfIWizPXIHtvF1LZEGMh/l4vwM06itZpR4a5K3EnAiCfSTazJyTdFOtNwc979tqpsTxrJDwL+AjYFk8ufVPiGAqf9zCzWbk5CbfAHlow1+7UbMYiqv88lv1/IZFIVE/KIFfDgduuz1Nn7caOm6zJHx6ZwjG3vcL7n81b2tNKJH6s3AZcYmaTCpaPJEoLIkiYZWZfRObwIVwHd6qZfVqLfb1I3PKXtDWuawuepZ1oZq3NzSU2wssDDo1yhgV4SUaWGX4DaCVppxirUe6WfCEtqGg+zEuI5eeyN142AF67e4SkteO1NSRtVN0c8TrWnlGfuh5eAlGMjyRtFbWwi4JDSZua2StmdhGuc9yaqmYhpUwpRgC/iGUd8FIZwK8m4pzdAfzb3Pb4Ddwwo12sdgzwfLlzLZNSZh0ZR+AqH4uCWUnr5o6tK/47+CmejW8sKV8G0jT3uAXwv8hgH0PlDHxXSRvHMfTEy21KMRQ4OcolkLR5lLAU8jRwkqJhT9Ia1O7zmFH4/iYSiTJIV5g1sM5qjbm9zw4MGvU+f35iKj+7bgT99t2SY3bcqKaMSiKRyGFmM6hct5lxMW7oMBGYR+XgcjAwGm9Wqw03AXdIeg13NpsCzMElyQolux7Aa2PvjP1dTTiqmdl3ko4A+stNNhrihg1TqMrFeAb6czzYyupKL8HNJI7Bs+IfAl+a2SxJFwBPRWA1P+bXu5o57oc3k70G/DfGy5NlLvsBj+FB8BjcNQ+8nngzPBP5LDAhxslKKi6ntCnF33ETkanAVPw2fp5BeN11vzh330g6Ls5JQ/x9HEBVSs21RszsExUx66DC8KMXcEXBZkfgAer3wNe4857BInm6ayX9//bOO8yK6vzjny8dBJbemxQbSBMLioqxR2NJNICoMTG2WKKJGo2JUWNijb1EJYoaC0ZFsetPQRARUKqIFCkCIoIKgoogvL8/3jPs7OXeLbALu3A+z7PP7p07c+bMzN173nnnPd/vpaE/3+LOg+CfqWcknYoboaSzveOBu4COuDNgYbJwg/DyhwkhUF+KPyHJtt5O+HVYCzxgZneV4POYMJzU9c2sQ05oXK9qlFqLRFJEo5ASCKMvWv49lz87lZEzl3J01+b865fdqF4lVxlfJFI+0XZgFBLKFKqGIK0D7iS2c5i0tKX7Uh1YZ2Y/hszfvWFSXmnvZyo+8W5ukStHSo3w1ONi2wRN7/JENAqJbK/kGhPLNIMs6QjgdvxR1CAzuz7j/ep41mYP/BFXPzObJ+lQ/K6/Gj4T+pIweQdJ/8Bnb9c3s9qpttrgj/fqhf1dZiUUvi+KlvVq8vCv9+Tetz/hxldn8NW3a7jll91plpdZNheJRLYytfDJUVXxbOnvtkZwHGgDPBWysWuAMza3QUmrMr7/PsQVNeaqCCOVENCtMbN3S7jPY4DdMr/Hi7ntPKAXPrnt+nT9raQL8XrlG/ByiC6Sfg6ca2YHh3X64BnaXsmkNUnPAc3MbJ8c+2yXaq8XbtJxwSb0/ULgfjMrdn1dOmgOGe5eZnZe6v0R4f33Jb0MnGRmywtpb8P6GcsH4hNCE7oCPc0trUcAzfEsOcBhZvZFrn0s//pHhv1vWa63y5RjTmy0VfYbiRRGmQXIIYNzN24KsBCfqT3MCgrZn45LMXWU1B//guwHLAN+ZmafhVq314CWYZsX8C/KWRm7/AvwlJndG2oOX6YYs3g34bj4Xd+ONKlTgyuGTuXgf43gtP3accb+7alXq1pp7y4SiWwCZrYSD8i2OmY2C+hR5Iqbx82E47WUjm8O+gKr8Il1xUJSFXOTjWGb2sFAonaRnqDWn3xJPADM7FlJv5V0Eh5U3wOcnQqO6+GJlVWS2pvZnMJ2GgLLTU2PXoird2QNkM1sBK72sUmY2SabeJjZY8BjAPIJpc+Z2aTUKgMzg+pIJFI8ynKS3l7A7CB9swaXKjo2Y51j8awvuD7owZJkZhODhBF4bVXNpL7MzN4zs8VZ9me4jA74ZIrPsqxTapywRyteu/AADtqlCfeM+IQ+NwznX6/P4JvVa8tyt5FIJFIoKmikcoHcLGWK3OSjHXA2cJHcOGJ/uQHGW2GdN8PTuMSo49+SxgI3SjpN0l3hvaZyA5bJ4ScxzXhObmAxTdKZWbr3NHCU3MAiyfK2wCdqZnIerlxyFTA+I+P9czxZ8iQpFz+5icZkSZPxeu5keV9JL2aen/D6w3AOdpCbfUwOy/pJuiD0b7ik4WH9rMYkko6Q9LGkCWTXQc6K3BAnMY75q9xs5B1JT6T7CZyoDEOcDNLSgJFIZDMpywC5JbAg9Xoh+VngjdYJmYEVbCz/9Atggpn9QOFcBZwsaSGePT4/20pKCaMvXbq0OMeRk3aNduCuk3ry6u8P4MCdGnPnW7M54MbhPDByDqvXrtustiORSKQQaoYAd1KYfHVNjvUuA3qYG02cbWbz8Ilyt5obR4zC5ekeDus8RsGJlK2Afc0s03zjDuDtoCXck/xJYr8xN7DoBVwgqcD3edDyHQccGRb1x5/8bTQZJmSFh+CB8p8y3k60jZ+goBX3Q7iEWrcc56MwjgA+M7NuZtYFeNXM7sCTLQeZ2UHKYUwiN8B5ADdJ2QNoltF2v4zrtdHTDUl74uNdN/z8ZK6TzRCnwD7Y2N77obDPv0obzypPj4fffFMSkZhIZNunXMu8yeVrbgDOKsbqA4DBZtYKn+n9qLLYfVpKGL1x48al0s+dm9Xh7oE9efH8PnRtVY9/vDydQ255m5enLmZ7ngQZiUTKjO9DgNs9TPi7Msd6U3AHtpOBH3Os0xt4PPz9KAVNLv5nbn6RyU9wVQvMTUtWhOUXhOzte7iEXKcs22YzFdmIUKZ3KF4O0ja1vGlo9x1zE5K1krqEsot6ZjYydSwlYSpu632DpP1Tx5QmlzHJLrgpyqwQ7P83Y7shGdcrW9nDfsDzZrY6lAi9kPF+ThMQubb1d+amOAkDzR0M9w8/p2TuMD0e1q1bHGnySGT7oSwD5EX4F2RCK/I1QjdaRy4DlIdP1kNSK1wq51RzfdKiOB13wsLMxuCC81u08r9Lyzwe+c1ePP7bvdmhWhV+99gETvj3GGZ/EZ34IpHIVuEofC5IT3weSEnnnRRlXLGBMDHtEKB3yOBOZGPjD3AL8YMl9QRqmVmmXFzC78i3Zr47lQH9Ja4lPVc++a8dBbPIRfEjBce+GgAh2O4Z9nmtpGw3HcKNSZJgdzczO70E+94cCjMB2ehGw8wWhd8r8Rugvcq6g5HItkRZBsjjgU5y8fRq+D9w5gSPYeRrnp4AvGVmFjIBL+FKFKOLub9PcYF9JO2Kf+ltXg3FJrJvx0a8/Pv9ufEXXflk6SoOv20k5/z3A979ZFnMKEcikS1CeILW2syG4yUKebjGcKZxxLvkZ3QHkr0eOJM3cV1m5KYleaH9r83sO0m74NnWjTCzVbg274Pkzh43A/4AXGpuz70I+G14ewBwhLmJSju8pKF/UIFYLle8SI4lG/PwQJgQpO8Y/m6BZ2H/i2th9wzrp89XLmOSj3FTlA6pPpaU0cDPJNUIdc3Fko0L1/mXpOqPJVVJ1TVXDW19mL2FSCSSjTJTsTDX/DwPn61cGXjQzKZJugZ4P8yI/g9eCjEb+Ir8L+nzcMH1K1N38YeZ2ReSbsTdnGqFeuNBZnYV8EfgAUkX4RP2TstW17alqFxJ/HLP1hy0SxMGjZrDkPcX8MqHn9OpSW1O6d2W43u0pE6Nqlure5FIZNunMvDfELwKuMPMlkt6AXha0rH4XI3z8VrVS/Ckwq+L0fbvgfslnY5nNM/BzTPOlhuJzMCDyVw8gT8h7J/j/VuAG80sSXJcCIyS9AFe0rChbXNpuxWhzODXuOmMAa9ntJmMB88Ap0qaBowl31Rkd9xIZT1u2pI46t0PvCrps1CHfBoZxiRmNlM+KfElSd/hNxklcq8zs/GShuFlMUvwTHa2Mo9MDgAWZCh5VAdeC8FxZVwH/IHCGqlXv0qUW4tEUkSjkC0kjL567TqGTf6MR8fMZ+qiFexQrTI/79mK/nu1pnOLvC3Sh0gEtg+jkEgkjaRf4CYqvypy5a2IpNpmtkpSLdza+0wzm7Al9r3Ljt3tP1e/sSV2tYH9Ti2deUCRyOaQa0ws15P0tiVqVK3ML3u1Zth5+zH0d/tyeOdmDBm/gKPueIej7xzFo2PmseL7KBEXiUSyI6mZXKrtE7mU2stBheDFLbDvl0Pp26Zs2zdkeCcFGbSbi7HNcXI9++T1NZIOKcZ2jSStlZulJMuOAf4B3Bdep2XwitVulv20k2s0l3S7wXKraCSNkBuYbGgTWBgm/30E/FBYcBz6kLVsIhzjopRyxiZrLUci2ytl6qQX2RhJ9GhTnx5t6vPXo3fj+UmLGPL+Qv76/DSufWk6R3Zpxom9WrNP+4ZUrrSRKk8kEtkOCRPUhuJybP3Dsm7AMVti/5tjZhEYZe4qVxOYKGloEfNLjgNexANFzCyXSkcmJ+LlFwNwOTsKMzgpQbuZtMNL/R4vYr2SstBKz4b8VjMr8mYkEolkJ2aQtyL1d6jGafvtyMsX9OGF8/rwy16tefPjLxg4aCz7Xv8mg0bNYd367bcEJhKJbOAgYG3aJc/MJuO1rrUlPR2ys48lag+SrpQ0Xm56cX9q+Qi5lFkB0wlJtSQ9JTcWGSppbJLhVDCzCFnL6ZIekJuBvB6CXiTtKTcbmSTppmzZTTP7HphE0MSXdEbo42RJz4Q+7IsH/jeFtjpkZF4PljRR0lRJD6ZqgcED4z8CLeVKSIRtrgjH+g5ua50sT7ebNuzoJbdqRtKBqUzsREl1gOuB/cOyi+QTFW8KxzJF0llhW0m6S27+8X9Ak+JcbBU0Nmks6Y1wvgdJmp/0E6ic7VpEIpHNJwbI5QBJ7N4qj78f14XxVxzCPQN70qlJHa59aTpH3TGKe0bMZv6XxVZbikQi2x5dcP3bbPTAJ7HtBrTH9XQB7jKzPYPpRU0KqiJkM534Ha5CsRvwV1wdIhudgLvNrDOwHDe3ADfpOCtkQLM6JUmqH7ZPtIqfDX3sBkwHTg+OecOAS4KU2iep7WsAg4F+QeO3CvlqGq2B5mY2Dpf87BeW74FPBuyOa+TvmeO4cnExcG44rv2B73EDllGhf7fiUnQrzGzP0P4ZknYEjscD8t2AU4F9M9p+TPnmIS/n2P/fcIWnzrgTYZvUe7muBcB5IVh/MJz3jVDKKGT5ymgUEomkiQFyOaNG1cr8dPfmPHr6Xtzevzs1qlbmxldncOBNIzYEywu++m5rdzMSiZQfxpnZQjNbj2dn24XlB4Us8FTc2KNzaptsphN9CFJhwXBiSo79zTWzSent5fXJdYIGPWxcerC/3EBkEfCamX0elneRNCr0cWBGH7Oxc9h/ojzxMK7iAB4QPxX+fpJ8qbX9gaFm9p2ZfUOOcotCGA3cIredrmfu+prJYbgyxiRcGaMhHrweADwRzFQ+A97K2G5gyjwkVxlL+rq8Cnydem+jaxH+vhfogN8ULAb+la3htFFIvTrRKCQSSRNrkMspkji2e0uO7d6ShV9/xytTP+elqYu58dUZ3PjqDLq1rsfPujbnp7s3p0W9+FQtEtnGmYZrxWfjh9Tf64AqIdN6D9DLzBZIuoqCph2FmU4UReb+ivMFlNQg7wi8J+mpENgNBo4zs8ly+bS+JexLmgFAM0mJ/nELSdmc/HKRNhDZcK7M7HpJL+EB7GhJh2fZVrjF9WsFFpb95Lis18LMlqT68ABezx2JREpADJArAK3q1+KMA9pzxgHtWfDVd7w0dTEvTvmMa1+azrUvTadX2/oc3bU5R+7enKZ1sxlXRSKRCs5bwD8lnWlm9wNI6opnR7ORfBEsk5tOnIA/ni+M0bjhxHC5gsTuxe1c0FdeKWlvMxtLDn3joFl8PW5cMgDXCl4s1+sdSL7baqaZScIMPGPd0cxm4/bJb8vNOmqbWctkRUlXh328CAyWdB0+5v2MoGiRwTy8rOQVUqUKkjqY2VRgqqQ9cVvpBRn9ew04R9JbZrY29GcRXkpylqSH8frjgyj5xL7kutwg6TDcRbBQJDU3s8Xh5fEUwySkdsMqUXYtEkkRA+QKRusGtTj7wA6cfWAH5i77lpemfMaLUxZz1QsfcdULH9G9dT0O69yUw3ZrRscmtbd2dyORSCkQHEaPB26T9CdgNR7QPZdj/eUhc/gh8DnubFoU9wAPS/oId4abRvGMKhJOx82a1gNvF7Ltv4GL5bJmf8VLEpaG30nQ+WRo6wJSmXMzWy3p18D/5LbZ40N7l+EqH2meAYaY2TWShgCTgS/Y+FwkM6GvBv4j6e/AiNT7F0o6CFiPn5NXwt/rQtnIYOB2vLxhgiSF4zku9OknuBrHp8AYSs7VuDHJKWH7z/EbiMK+4G+U1D0c2zzgrE3YbySyXRONQraQUUhZM/uLlbw2bQmvT/ucyQt9XOrUpDZHdmnGkbs3Z5dmdfDv7cj2jrawUYjc1ewxMzs5vK6C10WONbNi2elmtHc2bgn8yGb0qTswETgy1HWWO4rTR0mDgRfN7GlJg4BbzOyjTdhPCzwLWjUEoR1w97WdzWxNju1GECaw4dJqjwUbaSQ9AhwQrKBzbmtmZfYFLOkxoBfuijcOn0C4VlJf4HlgLm4z/ayZ/Tps0xS4FbfJ/hpYgzv6ZQbfxe3DPDyYNTywPTVVf13cNqoD64I7bW/g3pJIwSXX18xyTQIEoEvbbvbUZZnmg6XHbuc0LbO2I5HNIdeYGDPI2wgdm9ShY5M6nHtQRxav+J7Xpy3hlQ8Xc9fw2dzx1mzaNazFT3dvzq/2bRfLMCJbmm/xyVg1g8zXoeQ/Si8xaamzzWAA8E74vdkBsqQqOSZvbQ4l6qOZ/XYT99MdDyRH4eUVVfGa2t/lCo4zeAK4HFgu6XJ8XGmAm3NsTR4DTg5/Pw78Fp+8Bn6sXwBfAmfCBq3p53Ct6ZPCsrZsvtb0QWa2TNI/gT8DFxS1QcbnqQ3wlKRKeMB+Rgn33x2/voUGyJFIpCBRxWIbpHleTX61bzuePLM34644hH8evzutG9TivpFzOODG4Vz+7FTenL6Eb38o7fE8EsnJy8BR4e8BeFAFgKQGkp4LklTvSeoqqZJcl7Zear1ZkpqqoBPapmj6CjeUOA04VFINSbtIGpfaV7ugrICkPSS9LXeve01S89S+b5P0PvB7ST8L+5ko6f9CNrJQHVtJJ4e+T5J0n6TKufqYLFcOXV2lnNkkrUotPyFkmpF0olwXebKkkZKqAdfgChCjgJtwKbL3gavDsRwbtq0pd/KbLmko+ZPz3sTrckeGzObeQDXgURWuWZz0L1dfB0u6N3wm5si1gR8M+x+c2uYwSWMkTZD0P3nNNWb2sgXwDHKr9H7N7DdmdrCZJRamPwHWZGhNzzezO1OfiVFhPxPkes2JZvFISS+F6/LvEMxmMhLoqNyayX1D+8OAj8J6N+NlGpWBQUFGbn0hn8cC/wvp6xs+Y/2y9CsSiWQhBsjbOI1qV+ekvdvw6Ol7M/yPfTm2ewuem7iI0x9+n+7XvE7/+8dwz4jZfLhoBeujKUmk7HgS6B8Cva54vWnC1cBEM+uKZ9geCZJlz+MTjJC0NzA/PTs/RUk1fffF5bE+wWtNjzKzj4FqcpUF8IBxiDybeidwgpntATxIwcxotSCT9S8827uPmfUIx3tpWCerjq2kXcN+9ktpBycKDBv1MSwvSle3KK4EDg+6w8eEDPGVeK1udzMbAlwR+rsXPqnsJkk74HrD35nZruGY9gAws3V4ve8vwz5+Fvq8hhyaxSWgPtAbuAiXZ7sVl4LbXVL3cKPxF+AQM+uJB/Z/SDcQruEpFMzC9w43Ca9ISqTlOgM5rZ3xjPOhYT/9gDtS7+0FnI9flw7Az7NsfzQwldyayQA9gd+b2U54Zrsd0D38bzxWjM9jgf+FHNc3EokUg1hisR3RpmEtbjyhG38/rgvvz/uakbOWMnLmsg3ScY1qV6NPx0bs36kxfTo1iqUYkVLDzKbIJ2UNYONHvX0IqgFm9pakhpLqAkPwwf0hXBUh1+CeS9P39tDmh5LSmr4DCLqy4fepeICXmEtcH373w4PRLsAbntSlMl4/nZDuUys8qG6OZ1DnpvpyfOjLq5ISHduD8SBzfGi7Jh6EFdbHDbq6wGeSMnV1i2I0rujwFPnnLZPDgGMUsvS4IkabsO87wnFMyTinTwA34+e8P/Ao2TWLzwVuK0F/XwgTFKcCS4KaBJKm4de6FR6Ujg7nsBobT4S7B89ujwqvJwBtzWyVXIbtOVyzuACS7sav3ZoQzFYF7pLX9K4DdkqtPs7M5oTtngjbJaohwyWtw3Wl/wIMAroqOPgBeWH/a0I7yefmEODfSamFmX0lqQuFfx6z/S/kRNKZhBKT5g1aFbF2JLJ9EQPk7ZDqVSqzX8dG7NexEZcfCV+sXM07s5YxcuZSRs1axnOTPgNgp6a16dOxMQfs1Ig+HRtRpXJ84BDZLIbhQVRf3EihKMbgj6Qb44oA1+ZYr9iavqGE4RfAsZKuwGttG8rtg4fg6gjP4sIRsyTtDkwzs945mkxbXN6JT5IbJp8IdlXhh4fwetfLS9DH4pJ+HJTW9D07ZOOPAj6Qu8xl69cvzGxGRr8K29+7QHNJ3fCsdn9Sls6b0tdAcm3XU1Dzdz1+rdcBb5jZALIg6W9AY1IqDuZmIcnfL0u6J2Sip5GSdzOzc8PyZCLhRcASoBv+9HV1jmPIfH2QmS1L9SmXZnJfCn6esh4ShX8eS6RvbS4ZeD/4JL2i1o9EtidixBOhSZ0a/LxnK27r34PxVxzCSxf04fIjd6Fp3Ro8NnY+pz00nn2ue5PfPzmRp8YvYOHX0ckvskk8CFydZAFTjCKUFoQgYZmZfRNqR4cCtwDTzawkXriJdiwqqOl7MDDFzFqbWTsza4tnZo8P5Qzr8JKMJDM8A2gsVw9AUtXUI/lM8siffPirHH1J69i+CZwgqUl4r4F8UljOPuJ1rP1CfWpzvAQiG0sk7RpqYY9PFso1fcea2ZW4FFlrNtYcfg04PwRySOoRlo8EkslrXfBSGcDvJsI5exh4xcxWk9IsDqudgsu/FauvxeQ9YL9kH5J2kGsQI+m3wOHAgFCyk5yDZqlj2wsfB7/EtaZrSEqXgdRK/Z0HLA5tnYJnbxP2krRjOIZ+eLlNLhLN5KqhDzuFEpZM3sA1lKuE9RpQss9jQi5N6UgkUggxgxwpQKVKonOLPDq3yOOsAzuweu06Rs5cyktTFzN69pc8H7LLbRvWYr+OjThwp8b8ZJcmVI3Z5UgRmNlCCtZtJlwFPBge2X9HweByCK5be1oJd5dL0/dcsuvlngM8EvZ3Ey7/hZmtCY/C75CUh39n3hbay3Yc/wslFG8lbZBDxzYoG/wFeD0EVmtD/wYU0sefUriubpIFvAw3yFiKZ0ATzdyb5O5ywgP0yaGdy+Q2ydcBfw/HOCX0ay5eP3sv8JCk6cB0/DF+mifwuuvLwrnLpVmcSa6+FomZLZU78D2h/AmAfwFmhn3NB8aEePhZM7sG11U+R9KPwPdA/xDgI+k44FZJl4b+fIubmoB/pp6RdCpez5zO9o4H7gI6AsPZ+PqlGUR2zeRs6+2EX4e1wANmdlcJPo8Jw0ld31x1yDUaV41SbJFIiqiDvI3oIG8JzIxZX6xi9OxljJ69jPfmfMWqH36kWd0aHLxrE/ru3IR9OzRkh+rxvqs8oy2sg7w1CGUKxdb0LeO+bJaObQn2MxWfeDe3yJUjpUZ46nGxbYKmd3kijoeR7ZVcY2KMZCLFRhI7Na3DTk3r8Ov9dmTtuvWMmLGUp95fwNCJi3hs7KdUrSx6tqnP/p28xnn3lnmxdjlSqqh4xiO1KKamr8reeGRzdWyLs/83gKmFBcdF9DFZZzClZDxiRRhTZNluBME8RG6w0Sup3U0HoZKOAXYzs+sLaWvD+lneGwwcSL7T32lmNim8dwQui1YXrzGeAVxiZp+W5FhSfUgMSaoDT5rZ1SVtZ3MJGfbXzeyzwtZb+/kaFt+4sFT33fzSOPEvUnGJAXJkk6lauRKH7taUQ3dryg8/rtugjDFq5jJufn0mN78+kzo1qrBvh4bs36kxB3RqTJuGtYpuOBIpnCKNR8xsJW6OUCRWxsYjZjYL6JFto1yohMYjZnbo5vQxR5ubazxSJsYUZjYMn/C5OVxiZk+nF4S66jvxLPz0sOwYvBwiZ4BsZiMoaE2dZlQI6ncAJkl6wcwKk5JL+lKaxjOn4ZbjhQbIkUikIDFAjpQKmcoYX676gTFzvmTUzGWMmrWU16a5fG3bhrXo3b4he7dvwJ7tGtCyXs1ogR3ZFBLjkafJNx5JTEIa4BMC2+M1zWfiAcIcXFN2eVhvFi7HdQ6wysxuDlnMsfjkt3rA6WY2SlItXNO3C55VbAGcG7KdianHocAoudZzO1zPea+wr3a4ZNnuQTniFrzWdhmewVwc9j0p9OkJSTPxetpq+CSygWa2RK7q8Xjow5iw3z1CTfPJuFNbtXAcvzOzddn6GMpPhAeFhwIL8Aw3oc8jyM/orjKz2mH5CcDRZnaapBNxTeR1eEb2EDwDW1NSH7ym+cWwjy64VNpVZva8pJq4hF83vE48MR4plJAR7WVm54XymceAHfBs7YVJP4Hakp4O+/0AODmpNc7Bn4B/JsExbAjGk/2egX+WqgGzgVPM7LuQkV6N3xTUBf5gZi+mGzazbyV9gKuyrADuxtU1vgPOMLOPU+30wGXr7sHrqBvj5/dEM/tE0iX4pM/qwFAz+1v4fL2C3wDti98wHov/j/TCNZS/B3qHm8pIJFIEMUCOlAkNa1fn6K4tOLprC8yMOcu+ZdTMpbwzexkvTV3Mk+MXANA8rwb7tG9I7/YN6dOpES3qFWuMjESeBK6U9CKupvAgIUAm33jkOEk/wQPV7pIS45GHlDIeyXKDVsXM9pJr5P4ND/o2GI+ETOOk1PobTD1CUHmUmT0jqZqkHUPZQ6bxyLFhglk/3OjhN6GtakktnKT6uPGIyRUZLgX+SL7xyHWhJOD0sH7aeGRtCLAG4pMPN+oj+coYifFIU3zy34MluA6J8cgiSfXCpMYrCQFs6Nc/Q39/I3dGHCd3ATyLYDwiqSsbm3Qk+sHgNxMfZ9n/7cDtZvZEKJVJ0wM3//gMVxLZj3x1iX+Efr4JXGZmP4R1by7kWJ81swfCMV2Ln/c7w3vtcLOQDqHfHdMbSmoI7INPgLwfONtcRnBvfPLfT8KqrYB9w03NWOB6MxsabroqyVVQOoV9CRgm6QA8w90JV+w4Q65z/Qsz+6+k8wg3OpkHpJQOcst6LQs59Ehk+yMGyJEyRxIdGtemQ+PanLbfjqxbb0xf/A0fzP+acfO+YuTMpQyd6E/Iu7bK44guzTh016Z0bFI7ZpcjWbFoPLKtG49ASj84qSnO0nZv8hUgHqdggDsuKKcQFBza4QHy5biSSDU8WP0TnvXeQAho38Rr2e83s5vxsp5r8ScLtXG5toSngvzbLElzcOttgP0lTcR1m6/HVTX2xZU9km3T9tv/C8FxHaClmQ0N52d16Ndh+PmcGNavjQfGn+I3QJPC8mIZhVhKB7lbq67b74z9SCQLMUCObHEqVxJdWubRpWUev9q3HWbGzCWreOvjL3j1w8UbnP3aNazF4Z2b0btDQ/ZoW586Napu7a5HyhfReCSjO2w7xiOlQdpYZMO1NLPkhuQHSQ+RH3hPw62eJ5trbncPQX1SsjEYOM7MJocyj76p9nMZhYxKTxQMN2rLLbeKSXGMQq4zs/sKLPSbxczjjY/jIpHNIMoLRLY6kti5WR3O6duB58/rw5jLf8K1x3WhdYNa/OeduZz20Hi6Xf06x971Dte9Mp3hM75g5eq1W7vbka1PNB7ZRo1HSsB75Lvf9S/OBuE4E0e74/D6dIAbgStCqUpCelZxHWBxKJMZmNHsiZIqhZro9vh13ghzF7+5oXYbOd2yrLcSWCjXZUZSdXkd/GvAbyQl9eAtk+tdCNEoJBLZBGIGOVLuaJ5Xk5P3acvJ+7Tl2x9+ZOKnyxk790vem/MlD74zl/venkMlQecWeezTvgH7tG/Injs2oG7MMG9XWDQe2daNR4rDhcB/Q2b8VfKl2wrjsfAUQXgt+dkAZjZV0u+BR0Kmd1k4lr+F7f6KT3xcGn6ng85PgXH4JL2zwwTIXPsfCNwbrlVVvORlcpb1TgHuk3QNfi1PNLPXQwCfmJ+sAk7Gb8RyMRj4t4qYpFe1WbUoyxaJpIhGIVEYvULx3ZokYP6KsXO+ZOKC5az5cX0MmEuAtgOjkNJG0XikXBKyqt+HiYz98Ulqx27hPgwmaEdvyf2WNnE8jGyv5BoTyzSDLJ9hfTs+EWWQZQi7hy/6R/CJJV8C/cxsnqRD8QkN1XDZoUvM7K2wzT/wCSb1U3I+SLqV/MeDtYAmZlavDA8vshWoVa3KBjk5gNVr1zHx0+W8N8czzA+Pmc8Do+YiwU5N6tCzbT32bOeScq3qR0m5yCZTbOOR0kRSMzz7uiewHFgCvAtcIjfTKEvjkQbA10Wtm2P7vuSbZNTAA8hsk+zS2xwHzLRgTBIypyPN7P8K2WwPPBvbGZdeOzJH21eRL+VXnHaztdEOV5h4vITbDSbffGUEORQlSkoR4+QIoDlupQ1wmJl9ka2dhLVLvmfJrZnzJEtO04s2pVImEil/lFmAHDIud+P6mgvxmdXDrKAr0+m4dFLHcPd/Az7TexnwMzP7LNSmvQYkGjQv4J73s9L7M7OLUvs+nxIK80cqJjWqVqZ3h4b07uBztFavXcekBcsZO+crJi74mpemLOaJcS4p1yKvBnvu2IC9dmzA3js2oEPjqJIRKR5WAuOR0iLUyA7FJ971D8u6AceQMfmrtLHiGY8URWKSUROYKGmomY0uZP3j8DKOj0IfrixGP0dJuhuvZV5vZrOLsU2R7eagXdhPgQDZzE7bxPY2l8LGSXDd7JgSjkQ2kbLMIO8FzDazOQCSnsSFy9MB8rHkz8x+GrhLksxsYmqdabjofHUz+8HM3gvtFbbvAeTXjUW2I2pUrcw+7RuyT3sPmNevN2YsWcm4uV8xbt5XvPvJlzw/yQ2lWjeoyWG7NaNX2/r0aFOfZnk1Cms6EtnSHASstZTTX1BQqA8crCwmGHJt35/hCgbvAmeF5SMouQHKPPymoDZZTCjM7HtJewL/wWXM3sBtrLukDyKsN4kQvCmL4QbuvncMcGCozf0FXvObZF4PxhVLquA15OcE7WLw7/s/Ao9LapWSdrsCrz//AjdB+SAsH5xqdx7B0lpSL+BmM+sr6UCCrB9eh30Anq3dNRzLw3j9+/W4mkV14G4zuy/c2GQ1X8mGshjbBNm7qbi29wo8GL7IzB6R9AjwqJm9kWqmwDhZ2P4ikUjxKMsAuSX+5ZCwENg71zqhnm4FLte0LLXOL4AJxf2nD7O2d8QntUS2cypVErs2r8uuzetukJSb9+V3jPnkS16d9jmPjpnPf97xEssWeTXo0aY+PdrUo0ebenRukUeNqpW38hFEtmOS4DcbuUww7jKzawAkPYpPhnshbFNSA5Q0G5lQAP/FNaXPMLMxkq7PtmEI6DvhqhWQxXDDzO6UNIxULW+SBJGbZAwGDjazmSFAPAe4TVJroLmZjQv96gf8Sy431x8PvKvgJiQlmQR4MX6jMDooRqzGJypenGTu5SYbK8xsz1AuOFrS6/i1KYn5ykbGNqHfyXWdj7tA7h/e6x2OP022cfIhudHKM8C1lmXCkVJGIa3qNy/WiYlEthfKtYpFqCu7ARdGLy79gafNhe+ztbnhC6FNmzab3cdIxUISOzbagR0b7cBJe7fhhx/X8dFn3zDx0+VMXLCciZ9+zUtTXSa1amWxW/O69Gxbn+6t69GjdX1aN4h1zJFyQS4TjIMkXYrXTDfAM4tJgFxSA5Q0cy3DhELuilfHzBLli8fxgDxhf0mT8eD4NjP7PCwvzHAjGzuH/c8Mrx/G1TluwwPip8LyJ/FA9F94MDnUzL4DCMF3SRgN3CLpMTygX5jl//4woKtclQRclq8TJTdfyWVsMyq0NR9X/DhTUkv8hmaDXnKOcXKgubthHTxAPgUPrgtgaaOQ1p233xn7kUgWyjJAXoRrYia0Il/TM3OdhZKq4F8wXwJIaoXX351qridaXPrjX55ZSX8h9OrVK34hbOdUr1I5ZI3rb1j2xcrVHjB/upwJ87/miXGf8tDoeYBnmfdu35DurevRvXU9dm1el2pVopx4pEyYBpyQ472NTDBCpvUevGRgQZiYViPLNkUaoBRjf8UxoUhqkHcE3pP0VAiyB5PbcKOkDACaSUp0iVvIZeeKy4/k+wGkDVCul/QSLoM3WtLhWbYVcL6ZFQjwQ4a+NBiJj2VtgCtw/ekT8MA52VfWcdLMFoXfKyU9jpc8bhQgRyKR3JRlgDwe6BS+HBfhgetJGesMw2vExuD/+G+Ferl6wEvAZUVM6iiApF1w0fxMLc9IpNg0qVODwzs34/DOzQBYu249M5esZML8rxk9+0tGzVq2wRq7WpVKdGlRl+6t69O9TT26tcqjTYNaMcscKQ3eAv4p6cxwY4+krnh2NBtJgLcslAWcgM/tKIzEdGS4ChqgFImZLZe0UtLeZjaWHEYdZjY3lF/8CQ9oMw03ksRJLkOLGXjGumOYhHcK8LaknYDaZrZhYpqkq8M+XsQtsK/Dx7mfAfdt3DTzcCWMV8g3HEkMUKYCU0Od9S54OWCmAco5kt4ys7WhP4vwwPYsSQ8DTfC678KULxJjm78rZWwDfCOpEVDNzOZIegcv/Tgv9LEeWcbJkGyqF+qqq+JZ/SIVO6o2rRkVKCKRFGUWIIea4vPwL5HKwINmNk0usfO+mQ3DJ3c8Kmk28BX5X7DnAR2BK8OkEwgyNZJuxAPtWpIW4vJxV4V1+gNPZqu1ikQ2laqVK9G5RR6dW+RxSm+vY/5sxWomfbqcSQu+ZtKC5Tw2dj4PjvZa5ryaVdm9ZR492tRjj7b16dm2ftRkjpSYkCw4Hq+1/RNeBzsPeC7H+sslPYA7w32OJymKIpcBSnE5HXhA0nrg7UK2/TdwsVwqLZfhxpOhrQtIZc7Ntad/jZumJJP0/o3XBGczQBliZtdIGoIbcHzBxuciGSOuBv4j6e/AiNT7F0o6CJ98OA0PoNcD60LZyGC8NKUdMCFMzFuKK3EMpXDzlZckJVagY4CzyG1sMxYfP8ED6evwUhrIMU7idtWvheC4Mh4cP0AkEikR0SgkCqNHSoG169Yz4/OVTF20gikLVzBl4XI+/nwl69YbEuzctA59OjZiv06N2LVZXZrWrb7VssyKRiGRgDbTAEVSbTNbFf6+DJ8w9/uy6/HmI+kF4BYzG761+1Ke6NZmF3v94k2Lo5tekOuhRiRS/sk1JpbrSXqRSEWhauVKdGmZR5eWeQzYy5d9+8OPTFqwnPHzvmL8vK94ZMx8Br2Tn2Xu0rIuXVrmsXv42d5LMyQZ8JiZnRxeVwEWA2M3RfNX0tnAd2a2ybWXkroDE3H5slc3tZ2ypDh9VEFps0F4gPgRJTBACftpYWYvpxYfJelyfCyZTxYLb6XMMULpx79wBY3leFnFn8xsrKRVljJ/2lzCBLteuE3zODxTex8uZfecpMQh8NmU8kdT4FZgH9wkZQ1wo5llZqqL24d5+DEantU/NTVZcYuQ47pFIpEiiAFyJFJG7FC9oOvfqh9+ZNqiFcxcspKPFq/kw0UrePCduaxd509x6taosiFg7tqqHj3b1qN5XnHmQm0zfIsrHNQ0s+9xHdnMib3FJq0fvBkMwB9pDwA2O0CWVMXMftzsXhWkRH00s9+m/i6JAUr3sO6GQMvMhgBDStDXQbi7XiczWx/mqOxWgu1LwmPAyeHvx4HfmtlvQp3vxZk3XaFM4jncmOWksKwtrs+8ORwU6oH/CfwZuKCoDUr5c9KdjOsWiUSKJgbIkcgWonb1KuzdviF7BxMTgDU/+gTAqYtWMHXRCj5ctIKHRs9jzbr1QNBmblufLi3y2LlZbTo1qUPLejWpVGmbzTS/DByFTy4bADxBmJSmLIYKeL3tHKC7mS0P683CpbPOId9eeAQlN8oQcCIeqI8KKhHtgEfMbK+wr3bAC2a2u1x79xZcumwZcJqZLQ77nhT69ISkmcBfcKOML3FJriWSGuOBXAu8NvVQYI8QXJ2MB1bVwnH8zszWZetjKJfIaVaRkdHdkLWVy5UdbWanSToR10peh9cVHwJcg5tR9MFrYV8M++gCVAWuMrPn5c55DwHd8LrmmqH9DrgW/kAzWw8+gQ8PmDcQ+n4jbhttuIbvEEnN8WC8Lj52nROu4WF4LXF14BPg12a2Kp0xlTQOV1IqjJ8Aa6ygMcv8cIzJtX4U2CG8fZ6ZvRsC7mvwTHFHYHi4Pusz2h8JXBDKWrIZjPQF/o5nrneRtCsu33YEXv/8gLledGGfswKf8fC6wHULNzWRSKQIYoAciWxFqlVJlWaEZWt+XM/Hn3/DB/O/ZkKQmntpyuIN29SqVplOTeuwU5Pa7NysDrsFI5T6O1TbOgdRujyJTzp6EeiKB8RJgeNGhgpm1l3S87gE1kOS9gbmh4Azs+2SGmXsi+vvfhKCj6PM7BlJ1STtGIK7fsCQUKJwJ+4wt1RSP+AfwG9CW9WSGje5ccY+YRLeb4FLcSe4v+FKPtdJOgIPcAiBUj9gv6CWcA+uevBItj7iE9WOp2RmFZlcCRwetHTrmdmaMBGsl5klKgr/DP39TVBUGCfp//BShu/MbFe56saE0GZnYJLl0KhP8XM869kNaASMlzQSn5z9mpn9IwSZteQqD38BDjGzb8Nkxj/gQSGhn1Vx5Yt0bXTvMNnuM/xmYVro3wRy8wVwaLgB6YTfvCXZ973wcz0fz+L/nI0VRI4GpuLXNZvBCEBPoEtQ/jgHvyHrHia9NyjG56zAZ9zMDsm8bmlUwCikaSGHHolsf8QAORIpZ1SrUomurerRtVU9fr2fL1vx3VpmfbGSmUtWMXPJSmYuWcnwGUv53wcLN2zXPK8GuzWvy8m923LQzk22Uu83D3OL3XZ49jjzkXAuQ4UheED3EK5kkytDVlKjjAF4wE74fSoefCaObdeH3/3wYLQL8EYIzCvj9dMJ6T61woPq5nhGOMmg9sEDW8zsVUlfh+UH41Jk40PbNfFgrbA+ltSsIpPRuEzaU+Sft0wOA46RdHF4XQPX7D0At2FOrmcu85Fc9En1fYmkt4E9cSWKB0OQ+JyZTZJbQu+GB5ng5zNTNeIeYKSZJfrBE4C2ZrYqBJLP4QYfBZB0d+jLGjPbE8+S3xVqetcBO6VWH2dmc8J2T4TtkgB5uNzRbgoezA8iu8HImtBO8nk4BPh3UmphZl+Fm7jCPmfZPuM5sbRRSJtdtt8Z+5FIFmKAHIlUAPJqVaVXuwb0ategwPJlq35g+uJv+Oizb/z34m9Y8d3aHK1UGIYBN+OPoBsWvirgAVHHUKJwHHBtjvWKbZQRMpS/AI6VdAU+ga2h3JlsCC459iyuxjZL0u7ANDPrnaPJb1N/34lPkhsWHqtfVfjhIbwu9vIS9LG4pIOitFHG2SEbfxTwQXisn61fvzCzGRn9yrWvaUA3SZWLkUXeuKNmIyUdEPo0WNIteDnCG2Y2INs2kv4GNMaz2kk736T+flnSPSETPY2UFrKZnRuWJ1JHFwFL8Mx2JVx2b8Pqmd1N/X2QmS1L9SmXwUhfCn5Osh4ShX/ONscMJhKJpIj/QJFIBaZR7ers36kx+3dqvLW7Upo8CCw3s6khaEjIZaiApKF4XeZ0M/uyBPvKZZRxMDDFzDY4qMmNH443s0dCRvCv5GeGZwCNJfU2szEhy7lTeHSfSR75kw/TmrdJX24IdbWJveObwPOSbjXXgm+AawfvnKuPFN+sYkko4ZgRtlsZ2ulgbv4xVtKRuONpppHHa8D5ks4P5SI9zGxi2PdJwFsh49kVIJSBvA9cLemvYZt2QGczeynV7qhU3xvgGelL5BPmFprZA6E0oSdeXnC3gomIpB2AlmY2M5SvHA4cnK4HltQMWBL2vxce7H5JvjHLOWZ2b1i9VqpfeWH/6yX9inx9YoC95BMO5+NPFO7Pcq7T5y2bwUgmb4TzMDwpsaBkn7OEXAYsBajapHaUa4tEUkSP3EgkUq4ws4VmdkeWt64C9giP7K+nYHA5BFcsKOkEpHvwgOMjPPOcGGUMILsJRZKpTPb3VOjzGtzc4oZQ2zoJrw/OxlV4BvoDfJJVwtXAYZI+xCfefQ6sNJdj+wvwejj2N4DmRfRxKDALrz1+hI3LDpIM52X4ZLt3Kfio/iZJU0Nf3sUNN4YDu0maFGpf/46XHUyRNC28BrgXqC1pOl4L/EGq3d/iNdGzQ9uDyS8XSRiKlyNMxoPWS82l0foCkyVNxIPQ281sKS4t90Q4N2Nw1ztwM5GmwJjQ58RM4wTgw3Cd7gD6WwB/AnGgpLnyiX0P4w6A4J+VX4XtdqFgtnc8cBcwHS+ZKUwWbhB+XSaEc3Af2ZNVg3CjkSlhnyeV8HOWkHndIpFIMYhGIdEoJLKdoQpoFKIy0kjGpcA2yShDpayRHLKi60K2sDdwr5l138w2N+qjpKnAMUmtq3JrJJd0PyXW2lVBRY15+GSyZYVvVax2B+KBrfAM6jlmNjm8Ny8sWwf8mP5fkPQHfNLaWlw54k1cpzln3ZJyy8ZdBZyBO+xVAf5s7iC7RZH0ZzP7Z1HrdW/TyV6/9LYStd3kvKM2tVuRSLkh15gYSywikUhFoEw0kkO9brGMMrJQqhrJwI54JrQSPmHrjFJos0AfJb0BTE1NBCuApTSSS0h3ypfW7lzgQDP7OpSI3I9LzCUclBmIh5umw3CFkeWSquGKGDXxgHlTuNVcZnBXXIaviW0s/7YRm1qnnYM/A0UGyJFIpCCxxCISiVQUEo1kyNdIBlwjWdJzkqZIek9SV0mVJM2TS5Al682S1FTSVZIuNjfKWIUHuKuB2yUlusu1JD0l6SNJQyWNlZRItSX6w6cBh0qqIWmX8Fg+2Ve7kK1F0h6S3pb0gaTX5AoWSBoh6bZQm3sUrsaxGk9eXCd3dkNSY0lvSJomaZCk+fIJZEg6WdK48Aj9Pvnkvax9NLNDgYGS7pI0Qy7L1iTV5xGpY1yVWn5CyDQj6URJH0qaLGlkCCSvAfolj/El7SDpwdCviZKODdvWlPSkpOnyuvFCnXDCOXwrXNc3JbWRVDmUQEhSPUnr5JP3CP3pZGbvmlmiAvIeRWsgA1yBZ5qXg5fNmNn1qTr3eyW9H67B1antBgMfyUtSxknqmNmwmU0HfgQaSTpM0hhJEyT9T+4uSPis3iBpAnCipCPCOpMlvRnWyXVeT5P0rKRXw2f8xrD8elwDeZLcWTASiRSTGCBHIpGKwpNAf7lhR1fcBCEh0UjuimfMHgmZukQjGaU0krO0XcXc/ONCXI8YUhrJ+IS8tJLDBv1hYASukfwxUE0+WQs21kg+wcz2wCch/iPVVjUz62Vm/8KzvfuYWY9wvJeGdRKN5M64fFibcExpjeTueNnAwFx9DMvTGsmnUnQNayaJRnI3vFRjTVg2xMy6mxtRXBH6uxc+QfAm+QS6cwgayeGYsqljpLkTV/DoipfD3BEyqzNC//vgsm37y0tUWpvZrIw2TgdeSb02vJ77A7kOMHK5wNq5MuuBK8Jj2K54nXLX1HsrzGx3vA75tswNw2dvfdh3otvcE1fI+ENq1S/D8jeBB3CVkG74jQ7kPq/gWfx++ETTfpJam9llwPfhugwkA0lnhqD//S9XrSjk0COR7Y8YIEcikQqBmU3BtV1zaSQ/GtZ7C5c7SzSSk4lJm6KR/GRo80N84lhCpv5wMnkv0Ugm/B5CQY3kSXiAlM5oZmokvxYyz5fg5hWZfXkVlzeDghrJk8Lr9kX0cYNGspl9hk+EKwmJRvIZFFRySHMYcFno0wgKaiT/NxzHFAqe02z0Jl9941H8PIArXRwQfq4LyxOt5A1IOggPkP+UWtwnBKFHAucm2eeM7Q4PWdd5kpIbiF+G7O5E/LqkLbKfSP1OS7BdFM7BzfjnYW/ydZsn4RNN26bWTz4L++DazXPBNZDD8lznFeBNM1thZqvxSYDpdrNiZveHm7NeDWvnFbV6JLJdEWuQI5FIRSJqJGd0h21DI7mkjMSz0S3w7PUl+GciMQMhZHgH4RMUN0j/mdmi8PuLUOaxl7nG8ioFh0RzjeLX5I6OyVOBi4E9Q13zYFLnhILnKv33rWZ2c6pPP6MQ3WaKp4Oc7bzuTf5nGKIOciSy2cQMciQSqUg8CFxtZlMzlicayYmqwDIz+yZId22uRjLKrpHc2szamVlbgr1zKGfIqZEc2qoqqTPZKUojGW2skXyCpCbhvQZyveCcfcSDy36hlrc5/qg+G0sk7SqfNHh8slBBI9nMrsQVGgrTSFbYpkdYnmgko5RGciG8i2f+wa9vEgCPw0tD1oeM6STcDGRkaLsN/lTgFDObmer7DslNQihNOAz4MLx9HXCvQs166HsSBNfFg9cV8rrwIzP6mX5qkCmpl+Y9YL+kTjn0Z6cc6x2QlOvINZAh93ktjLWhzCcSiZSAeIcZiUQqDGa2kGBjnMFVuA3xFFy+LVMjeTw+Wa0k3AM8LNdI/ph8jeRzya4/fA6uOTwEuAlXpcDM1shthe+QlId/794W2st2HP+T20y/lbSB11g/IekUPABLNJKXSUo0kivhagvnklsj+Rzgp8BP8Mfwn1K0RvJSvFa2dlh+k6ROeDbzTVyv+FPyH/1fh2si34Zr+FbCVSWOxjWSH5JrJE+noEYyYf1E5eEp4Pyw/iWhH78O5/QHSQvwQBI8cB4AJDdOV+JPGO4JsWQi59YUGBqWVQEet3yJvnuBHXBzlB/wyZuj8dr2FXL95Y+BBWF5mvrhs/cD+aUsG2FmSyWdhl/L6mHxX4CZWdY7E3g2nL8vcOWWXOe1MO4P60/IVoecUKVJXpRti0RSbNc6yJKW4s5HhdGIgmL+FZV4HOWLrXkcbc1sm7LeKwtCmcImaSSXQV9KXSM5x34KaCRHikalqN+8NZG0En/aUVGoaGNB7G/Zsjn9zTombtcZ5OIECZLetwpmqpCNeBzli23lOLZxarHpGsmlTRvgKZWuRnIBVIRGcmSbZ0ZF+k6qaN+hsb9lS1n0d7sOkCORSCQX5hrJ5WKACNJlxak33Zx9HFqW7W+rmFm7rd2HSCRS+sRJepFIJBKJRCKRSIoYIBfN/Vu7A6VEPI7yxbZyHJFIZNugon0nxf6WLdt9f7frSXqRSCQSiUQikUgmMYMciUQikUgkEomkiAFyJBKJRCKRSCSSIgbIOZB0hKQZkmZLumxr96cwJLWWNFzSR5KmSfp9WN5A0huSZoXf9cNySbojHNsUST237hEUJDh8TQw2r0jaUdLY0N8hkqqF5dXD69nh/XZbteMZSKon6WlJH0uaLql3Rb0mkUhk26U8jncVcVyrSGNXRRufJF0UPgcfSnpCUo2yPr8xQM6C3CDgbtxOdDdggNxqtrzyI/BHM9sN2Ac4N/T3MuBNM+uEO14lX3xHAp3Cz5m4g1R54ve4y1bCDcCtZtYR+Bo4PSw/Hfg6LL81rFeeuB141cx2Abrhx1RRr0kkEtkGKcfjXUUc1yrS2FVhxidJLYELcEOeLkBl3IK+bM+vmcWfjB+gN/Ba6vXlwOVbu18l6P/zuC3pDKB5WNYcF4IHuA8YkFp/w3pb+wdohf9j/gS3uRXujlMl89oArwG9w99Vwnra2scQ+pOH28AqY3mFuybxJ/7En233p6KMd+V9XKtIY1dFG5+AlrjFe4Nwvl4EDi/r8xszyNlJLkbCwrCs3BMeJfQAxgJNzWxxeOtzoGn4uzwf323ApcD68LohsNzMfgyv033dcBzh/RVh/fLAjsBS4KHwyG2QpB2omNckEolsu5T7754KMq7dRsUZuyrU+GRmi4CbgU+Bxfj5+oAyPr8xQN6GkFQbeAa40My+Sb9nfitVrjX9JB0NfGFmH2ztvpQCVYCewL1m1gP4lvzHVUDFuCaRSCSyNakI41oFHLsq1PgUaqGPxQP7FsAOwBFlvd8YIGdnEdA69bpVWFZukVQV/xJ5zMyeDYuXSGoe3m8OfBGWl9fj2w84RtI84En8UdXtQD1JiS16uq8bjiO8nwd8uSU7XAgLgYVmNja8fhr/Qqpo1yQSiWzblNvvngo0rlW0sauijU+HAHPNbKmZrQWexc95mZ7fGCBnZzzQKcyQrIYXgw/byn3KiSQB/wGmm9ktqbeGAb8Kf/8Kr+FKlp8aZqbuA6xIPVbZapjZ5WbWysza4ef8LTMbCAwHTgirZR5HcnwnhPXLxR2vmX0OLJC0c1h0MPARFeyaRCKRbZ5yOd5VpHGtoo1dFXB8+hTYR1Kt8LlI+lu253dLFVlXtB/gp8BM4BPgiq3dnyL62gd/FDIFmBR+forX3LwJzAL+D2gQ1hc+a/kTYCo+M3SrH0fGMfUFXgx/twfGAbOB/wHVw/Ia4fXs8H77rd3vjGPoDrwfrstzQP2KfE3iT/yJP9vmT3kc7yrquFZRxq6KNj4BVwMfAx8CjwLVy/r8RqvpSCQSiUQikUgkRSyxiEQikUgkEolEUsQAORKJRCKRSCQSSRED5EgkEolEIpFIJEUMkCORSCQSiUQikRQxQI5EIpFIJBKJRFLEADlSLCStCr/bSTqplNv+c8brd0uz/UgkEolESsKWHofKYmyNbB4xQI6UlHZAif6JU043uSgQIJvZviXsUyQSiUQipcaWHIfCGNmOEo6tkbIlBsiRknI9sL+kSZIuklRZ0k2SxkuaIuksAEl9JY2SNAx3vEHSc5I+kDRN0plh2fVAzdDeY2FZkq1WaPtDSVMl9Uu1PULS05I+lvRYcNeJRCKRSGSzSY1DfSW9Lel5SXMkXS9poKRxYVzqENYbLOnfkt6XNFPS0WF5DUkPhXUnSjooLD9N0jBJb+HmHJlja7swhk4IP/um+pN1/JO0p6R3JU0O/auTa4yOFE1Rmb1IJJPLgIvNLPnnPxO3ndxTUnVgtKTXw7o9gS5mNje8/o2ZfSWpJjBe0jNmdpmk88yse5Z9/Rx3++kGNArbjAzv9QA6A58Bo3Ff9ndK+2AjkUgkst3TDdgV+AqYAwwys70k/R44H7gwrNcO2AvoAAyX1BE4FzAz213SLsDrknYK6/cEuoZxsS8Fx9ZawKFmtlpSJ+AJoFfYbqPxT9I4YAjQz8zGS6oLfA+cTpYxOjUuR3IQA+TI5nIY0FVS4oeeB3QC1gDjMv4JL5B0fPi7dVjvy0La7gM8YWbrgCWS3gb2BL4JbS8EkDQJ/2KKAXIkEolESpvxZrYYQNInQJIEmgoclFrvKTNbD8ySNAfYBR/H7gQws48lzQeSAPkNM/sqxz6rAndJ6g6sS20D2ce/FcBiMxsf9vVNeD/XGB0D5CKIAXJkcxFwvpm9VmCh3w1/m/H6EKC3mX0naQTul76p/JD6ex3xsxyJRCKRsiE93qxPvV5PwbHHMrbLfJ3Jt4W8dxGwBM9eVwJW5+hPUeNf1jE6UjSxBjlSUlYCdVKvXwPOkVQVQNJOknbIsl0e8HUIjncB9km9tzbZPoNRQL9QQ9UYOAAYVypHEYlEIpFI6XKipEqhLrk9MAMfxwaCj49Am7A8k8yxNQ/PCK8HTgEqF7HvGUBzSXuGfdWRT/4r7hgdySBm3SIlZQqwTtJkYDBwO/54Z0KYKLAUOC7Ldq8CZ0uajv8jv5d6735giqQJZjYwtXwo0BuYjN+JX2pmn4cAOxKJRCKR8sSneBKnLnB2qB++B7hX0lTgR+A0M/shy7zyzLH1HuAZSafi42dh2WbMbE2YyH5nmOfzPf7UdhDFG6MjGcisqCcAkUgkEolEIpFcSBoMvGhmT2/tvkRKh1hiEYlEIpFIJBKJpIgZ5EgkEolEIpFIJEXMIEcikUgkEolEIiligByJRCKRSCQSiaSIAXIkEolEIpFIJJIiBsiRSCQSiUQikUiKGCBHIpFIJBKJRCIp/h+24xcKL84VowAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"sharpe_ratio: 0.5320470026104983\nscore 1: 0.5320470026104983\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-04-22 10:46:29,801]\u001b[0m A new study created in memory with name: no-name-5300ad9a-f5c6-49ba-969f-c8a342e30d2d\u001b[0m\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076083 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021517\tValid's rmse: 0.0250913\n[200]\tTrain's rmse: 0.0214905\tValid's rmse: 0.0250716\n[300]\tTrain's rmse: 0.0214698\tValid's rmse: 0.0250642\n[400]\tTrain's rmse: 0.0214527\tValid's rmse: 0.0250606\n[500]\tTrain's rmse: 0.0214384\tValid's rmse: 0.0250513\n[600]\tTrain's rmse: 0.021424\tValid's rmse: 0.0250457\n[700]\tTrain's rmse: 0.0214114\tValid's rmse: 0.0250415\n[800]\tTrain's rmse: 0.0213997\tValid's rmse: 0.0250383\n[900]\tTrain's rmse: 0.0213886\tValid's rmse: 0.0250294\n[1000]\tTrain's rmse: 0.0213774\tValid's rmse: 0.025022\n[1100]\tTrain's rmse: 0.0213664\tValid's rmse: 0.0250224\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025021:  14%|#4        | 1/7 [00:24<02:28, 24.82s/it]\u001b[32m[I 2022-04-22 10:46:54,629]\u001b[0m Trial 0 finished with value: 0.025020526329578924 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.025020526329578924.\u001b[0m\nfeature_fraction, val_score: 0.025021:  14%|#4        | 1/7 [00:24<02:28, 24.82s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1030]\tTrain's rmse: 0.0213739\tValid's rmse: 0.0250205\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062522 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215202\tValid's rmse: 0.0251051\n[200]\tTrain's rmse: 0.0214947\tValid's rmse: 0.0250906\n[300]\tTrain's rmse: 0.0214754\tValid's rmse: 0.0250798\n[400]\tTrain's rmse: 0.0214593\tValid's rmse: 0.0250706\n[500]\tTrain's rmse: 0.0214457\tValid's rmse: 0.0250643\n[600]\tTrain's rmse: 0.0214327\tValid's rmse: 0.0250579\n[700]\tTrain's rmse: 0.0214208\tValid's rmse: 0.0250554\n[800]\tTrain's rmse: 0.0214106\tValid's rmse: 0.0250509\n[900]\tTrain's rmse: 0.0214005\tValid's rmse: 0.0250448\n[1000]\tTrain's rmse: 0.0213901\tValid's rmse: 0.0250387\n[1100]\tTrain's rmse: 0.0213803\tValid's rmse: 0.0250409\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025021:  29%|##8       | 2/7 [00:47<01:56, 23.31s/it]\u001b[32m[I 2022-04-22 10:47:16,884]\u001b[0m Trial 1 finished with value: 0.025037787064584614 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.025020526329578924.\u001b[0m\nfeature_fraction, val_score: 0.025021:  29%|##8       | 2/7 [00:47<01:56, 23.31s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1030]\tTrain's rmse: 0.021387\tValid's rmse: 0.0250378\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215221\tValid's rmse: 0.0251129\n[200]\tTrain's rmse: 0.0214968\tValid's rmse: 0.0250965\n[300]\tTrain's rmse: 0.021478\tValid's rmse: 0.0250877\n[400]\tTrain's rmse: 0.0214626\tValid's rmse: 0.0250763\n[500]\tTrain's rmse: 0.0214493\tValid's rmse: 0.025068\n[600]\tTrain's rmse: 0.0214369\tValid's rmse: 0.0250615\n[700]\tTrain's rmse: 0.0214256\tValid's rmse: 0.0250562\n[800]\tTrain's rmse: 0.0214154\tValid's rmse: 0.025051\n[900]\tTrain's rmse: 0.0214056\tValid's rmse: 0.0250461\n[1000]\tTrain's rmse: 0.0213957\tValid's rmse: 0.02504\n[1100]\tTrain's rmse: 0.0213865\tValid's rmse: 0.0250396\n[1200]\tTrain's rmse: 0.0213781\tValid's rmse: 0.0250366\n[1300]\tTrain's rmse: 0.0213696\tValid's rmse: 0.0250365\n[1400]\tTrain's rmse: 0.0213612\tValid's rmse: 0.0250333\n[1500]\tTrain's rmse: 0.0213533\tValid's rmse: 0.0250327\n[1600]\tTrain's rmse: 0.0213453\tValid's rmse: 0.0250264\n[1700]\tTrain's rmse: 0.0213372\tValid's rmse: 0.0250252\n[1800]\tTrain's rmse: 0.02133\tValid's rmse: 0.0250213\n[1900]\tTrain's rmse: 0.0213228\tValid's rmse: 0.0250193\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018:  43%|####2     | 3/7 [01:20<01:51, 27.94s/it]\u001b[32m[I 2022-04-22 10:47:50,333]\u001b[0m Trial 2 finished with value: 0.025017629064798954 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018:  43%|####2     | 3/7 [01:20<01:51, 27.94s/it]","output_type":"stream"},{"name":"stdout","text":"[2000]\tTrain's rmse: 0.0213158\tValid's rmse: 0.0250176\nDid not meet early stopping. Best iteration is:\n[2000]\tTrain's rmse: 0.0213158\tValid's rmse: 0.0250176\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061852 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215188\tValid's rmse: 0.0251026\n[200]\tTrain's rmse: 0.0214928\tValid's rmse: 0.0250879\n[300]\tTrain's rmse: 0.0214737\tValid's rmse: 0.0250759\n[400]\tTrain's rmse: 0.0214574\tValid's rmse: 0.0250645\n[500]\tTrain's rmse: 0.0214438\tValid's rmse: 0.0250582\n[600]\tTrain's rmse: 0.0214306\tValid's rmse: 0.0250525\n[700]\tTrain's rmse: 0.0214186\tValid's rmse: 0.0250507\n[800]\tTrain's rmse: 0.0214081\tValid's rmse: 0.0250472\n[900]\tTrain's rmse: 0.0213973\tValid's rmse: 0.0250412\n[1000]\tTrain's rmse: 0.0213866\tValid's rmse: 0.0250335\n[1100]\tTrain's rmse: 0.0213769\tValid's rmse: 0.0250357\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018:  57%|#####7    | 4/7 [01:42<01:16, 25.43s/it]\u001b[32m[I 2022-04-22 10:48:11,909]\u001b[0m Trial 3 finished with value: 0.02503209746824251 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018:  57%|#####7    | 4/7 [01:42<01:16, 25.43s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1029]\tTrain's rmse: 0.0213837\tValid's rmse: 0.0250321\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177071 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215169\tValid's rmse: 0.0250939\n[200]\tTrain's rmse: 0.0214904\tValid's rmse: 0.0250745\n[300]\tTrain's rmse: 0.0214699\tValid's rmse: 0.0250659\n[400]\tTrain's rmse: 0.021453\tValid's rmse: 0.0250598\n[500]\tTrain's rmse: 0.0214386\tValid's rmse: 0.0250514\n[600]\tTrain's rmse: 0.0214245\tValid's rmse: 0.0250477\n[700]\tTrain's rmse: 0.0214117\tValid's rmse: 0.0250431\n[800]\tTrain's rmse: 0.0214002\tValid's rmse: 0.0250386\n[900]\tTrain's rmse: 0.021389\tValid's rmse: 0.0250283\n[1000]\tTrain's rmse: 0.0213777\tValid's rmse: 0.0250207\n[1100]\tTrain's rmse: 0.021367\tValid's rmse: 0.0250216\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018:  71%|#######1  | 5/7 [02:06<00:49, 24.98s/it]\u001b[32m[I 2022-04-22 10:48:36,086]\u001b[0m Trial 4 finished with value: 0.025019429185763376 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018:  71%|#######1  | 5/7 [02:06<00:49, 24.98s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1052]\tTrain's rmse: 0.0213719\tValid's rmse: 0.0250194\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065999 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215167\tValid's rmse: 0.0250944\n[200]\tTrain's rmse: 0.0214907\tValid's rmse: 0.0250773\n[300]\tTrain's rmse: 0.0214704\tValid's rmse: 0.0250682\n[400]\tTrain's rmse: 0.0214534\tValid's rmse: 0.0250621\n[500]\tTrain's rmse: 0.0214393\tValid's rmse: 0.0250535\n[600]\tTrain's rmse: 0.0214252\tValid's rmse: 0.0250483\n[700]\tTrain's rmse: 0.0214126\tValid's rmse: 0.0250426\n[800]\tTrain's rmse: 0.0214013\tValid's rmse: 0.0250373\n[900]\tTrain's rmse: 0.02139\tValid's rmse: 0.0250285\n[1000]\tTrain's rmse: 0.021379\tValid's rmse: 0.0250226\n[1100]\tTrain's rmse: 0.0213684\tValid's rmse: 0.0250243\n[1200]\tTrain's rmse: 0.0213587\tValid's rmse: 0.0250227\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018:  86%|########5 | 6/7 [02:32<00:25, 25.35s/it]\u001b[32m[I 2022-04-22 10:49:02,149]\u001b[0m Trial 5 finished with value: 0.025021501616482204 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018:  86%|########5 | 6/7 [02:32<00:25, 25.35s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1147]\tTrain's rmse: 0.0213639\tValid's rmse: 0.0250215\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215176\tValid's rmse: 0.0250973\n[200]\tTrain's rmse: 0.0214916\tValid's rmse: 0.0250819\n[300]\tTrain's rmse: 0.0214722\tValid's rmse: 0.0250747\n[400]\tTrain's rmse: 0.0214549\tValid's rmse: 0.0250641\n[500]\tTrain's rmse: 0.021441\tValid's rmse: 0.0250581\n[600]\tTrain's rmse: 0.0214272\tValid's rmse: 0.0250552\n[700]\tTrain's rmse: 0.0214148\tValid's rmse: 0.0250499\n[800]\tTrain's rmse: 0.0214037\tValid's rmse: 0.0250452\n[900]\tTrain's rmse: 0.0213929\tValid's rmse: 0.0250372\n[1000]\tTrain's rmse: 0.0213821\tValid's rmse: 0.0250308\n[1100]\tTrain's rmse: 0.0213717\tValid's rmse: 0.0250331\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction, val_score: 0.025018: 100%|##########| 7/7 [02:55<00:00, 24.65s/it]\u001b[32m[I 2022-04-22 10:49:25,376]\u001b[0m Trial 6 finished with value: 0.02502967451856664 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.025017629064798954.\u001b[0m\nfeature_fraction, val_score: 0.025018: 100%|##########| 7/7 [02:55<00:00, 25.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1027]\tTrain's rmse: 0.0213792\tValid's rmse: 0.0250297\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.025018:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057860 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214481\tValid's rmse: 0.0250826\n[200]\tTrain's rmse: 0.0213639\tValid's rmse: 0.0250521\n[300]\tTrain's rmse: 0.0212933\tValid's rmse: 0.0250375\n[400]\tTrain's rmse: 0.0212294\tValid's rmse: 0.0250204\n[500]\tTrain's rmse: 0.0211716\tValid's rmse: 0.0250065\n[600]\tTrain's rmse: 0.0211166\tValid's rmse: 0.0249976\n[700]\tTrain's rmse: 0.0210638\tValid's rmse: 0.0249935\n[800]\tTrain's rmse: 0.0210134\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209664\tValid's rmse: 0.0249851\n[1000]\tTrain's rmse: 0.0209187\tValid's rmse: 0.0249797\n[1100]\tTrain's rmse: 0.0208734\tValid's rmse: 0.024982\nEarly stopping, best iteration is:\n[1013]\tTrain's rmse: 0.0209125\tValid's rmse: 0.0249784\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024978:   5%|5         | 1/20 [00:46<14:44, 46.55s/it]\u001b[32m[I 2022-04-22 10:50:11,936]\u001b[0m Trial 7 finished with value: 0.024978388258463286 and parameters: {'num_leaves': 87}. Best is trial 7 with value: 0.024978388258463286.\u001b[0m\nnum_leaves, val_score: 0.024978:   5%|5         | 1/20 [00:46<14:44, 46.55s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057926 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214468\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213611\tValid's rmse: 0.0250513\n[300]\tTrain's rmse: 0.0212895\tValid's rmse: 0.0250372\n[400]\tTrain's rmse: 0.0212254\tValid's rmse: 0.0250197\n[500]\tTrain's rmse: 0.0211662\tValid's rmse: 0.0250057\n[600]\tTrain's rmse: 0.0211103\tValid's rmse: 0.0249963\n[700]\tTrain's rmse: 0.0210564\tValid's rmse: 0.0249932\n[800]\tTrain's rmse: 0.0210052\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209573\tValid's rmse: 0.0249835\n[1000]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249779\n[1100]\tTrain's rmse: 0.0208629\tValid's rmse: 0.0249771\n[1200]\tTrain's rmse: 0.0208185\tValid's rmse: 0.0249764\nEarly stopping, best iteration is:\n[1146]\tTrain's rmse: 0.0208421\tValid's rmse: 0.0249747\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  10%|#         | 2/20 [01:39<15:00, 50.04s/it]\u001b[32m[I 2022-04-22 10:51:04,412]\u001b[0m Trial 8 finished with value: 0.024974720462748096 and parameters: {'num_leaves': 89}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  10%|#         | 2/20 [01:39<15:00, 50.04s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058014 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215015\tValid's rmse: 0.0251005\n[200]\tTrain's rmse: 0.0214612\tValid's rmse: 0.0250761\n[300]\tTrain's rmse: 0.0214304\tValid's rmse: 0.025063\n[400]\tTrain's rmse: 0.021404\tValid's rmse: 0.0250488\n[500]\tTrain's rmse: 0.0213812\tValid's rmse: 0.0250389\n[600]\tTrain's rmse: 0.0213591\tValid's rmse: 0.0250314\n[700]\tTrain's rmse: 0.0213383\tValid's rmse: 0.0250275\n[800]\tTrain's rmse: 0.0213187\tValid's rmse: 0.0250213\n[900]\tTrain's rmse: 0.021301\tValid's rmse: 0.0250155\n[1000]\tTrain's rmse: 0.0212832\tValid's rmse: 0.0250082\n[1100]\tTrain's rmse: 0.0212656\tValid's rmse: 0.0250084\n[1200]\tTrain's rmse: 0.0212489\tValid's rmse: 0.0250037\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  15%|#5        | 3/20 [02:10<11:47, 41.63s/it]\u001b[32m[I 2022-04-22 10:51:36,044]\u001b[0m Trial 9 finished with value: 0.02500364577649468 and parameters: {'num_leaves': 23}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  15%|#5        | 3/20 [02:10<11:47, 41.63s/it]","output_type":"stream"},{"name":"stdout","text":"[1300]\tTrain's rmse: 0.0212327\tValid's rmse: 0.025006\nEarly stopping, best iteration is:\n[1203]\tTrain's rmse: 0.0212484\tValid's rmse: 0.0250036\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058645 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214782\tValid's rmse: 0.0250923\n[200]\tTrain's rmse: 0.0214187\tValid's rmse: 0.0250652\n[300]\tTrain's rmse: 0.0213718\tValid's rmse: 0.0250499\n[400]\tTrain's rmse: 0.0213295\tValid's rmse: 0.0250344\n[500]\tTrain's rmse: 0.021292\tValid's rmse: 0.0250241\n[600]\tTrain's rmse: 0.0212563\tValid's rmse: 0.025013\n[700]\tTrain's rmse: 0.0212222\tValid's rmse: 0.0250085\n[800]\tTrain's rmse: 0.0211901\tValid's rmse: 0.0250019\n[900]\tTrain's rmse: 0.0211602\tValid's rmse: 0.0249951\n[1000]\tTrain's rmse: 0.02113\tValid's rmse: 0.0249901\n[1100]\tTrain's rmse: 0.0211015\tValid's rmse: 0.0249893\n[1200]\tTrain's rmse: 0.021074\tValid's rmse: 0.0249859\nEarly stopping, best iteration is:\n[1195]\tTrain's rmse: 0.0210754\tValid's rmse: 0.0249856\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  20%|##        | 4/20 [02:51<11:02, 41.41s/it]\u001b[32m[I 2022-04-22 10:52:17,108]\u001b[0m Trial 10 finished with value: 0.024985607391169524 and parameters: {'num_leaves': 46}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  20%|##        | 4/20 [02:51<11:02, 41.41s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057838 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214915\tValid's rmse: 0.0250954\n[200]\tTrain's rmse: 0.0214435\tValid's rmse: 0.02507\n[300]\tTrain's rmse: 0.0214058\tValid's rmse: 0.0250546\n[400]\tTrain's rmse: 0.0213723\tValid's rmse: 0.0250397\n[500]\tTrain's rmse: 0.021343\tValid's rmse: 0.0250325\n[600]\tTrain's rmse: 0.0213152\tValid's rmse: 0.0250239\n[700]\tTrain's rmse: 0.0212889\tValid's rmse: 0.02502\n[800]\tTrain's rmse: 0.0212641\tValid's rmse: 0.025014\n[900]\tTrain's rmse: 0.0212411\tValid's rmse: 0.0250075\n[1000]\tTrain's rmse: 0.0212179\tValid's rmse: 0.0250011\n[1100]\tTrain's rmse: 0.0211961\tValid's rmse: 0.0250006\n[1200]\tTrain's rmse: 0.0211751\tValid's rmse: 0.024999\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  25%|##5       | 5/20 [03:27<09:52, 39.52s/it]\u001b[32m[I 2022-04-22 10:52:53,272]\u001b[0m Trial 11 finished with value: 0.02499842843361689 and parameters: {'num_leaves': 32}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  25%|##5       | 5/20 [03:27<09:52, 39.52s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1144]\tTrain's rmse: 0.0211867\tValid's rmse: 0.0249984\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074791 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213827\tValid's rmse: 0.0250764\n[200]\tTrain's rmse: 0.0212407\tValid's rmse: 0.0250452\n[300]\tTrain's rmse: 0.0211172\tValid's rmse: 0.0250318\n[400]\tTrain's rmse: 0.021002\tValid's rmse: 0.0250165\n[500]\tTrain's rmse: 0.0208956\tValid's rmse: 0.0250069\n[600]\tTrain's rmse: 0.0207945\tValid's rmse: 0.0250005\n[700]\tTrain's rmse: 0.0206966\tValid's rmse: 0.0249989\n[800]\tTrain's rmse: 0.0206029\tValid's rmse: 0.0249956\n[900]\tTrain's rmse: 0.0205143\tValid's rmse: 0.0249946\n[1000]\tTrain's rmse: 0.0204263\tValid's rmse: 0.024995\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0204446\tValid's rmse: 0.0249929\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  30%|###       | 6/20 [04:39<11:48, 50.59s/it]\u001b[32m[I 2022-04-22 10:54:05,365]\u001b[0m Trial 12 finished with value: 0.024992895979893008 and parameters: {'num_leaves': 224}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  30%|###       | 6/20 [04:39<11:48, 50.59s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058866 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214958\tValid's rmse: 0.0250975\n[200]\tTrain's rmse: 0.0214509\tValid's rmse: 0.0250733\n[300]\tTrain's rmse: 0.0214162\tValid's rmse: 0.0250582\n[400]\tTrain's rmse: 0.0213854\tValid's rmse: 0.025044\n[500]\tTrain's rmse: 0.0213588\tValid's rmse: 0.0250365\n[600]\tTrain's rmse: 0.0213336\tValid's rmse: 0.0250274\n[700]\tTrain's rmse: 0.0213098\tValid's rmse: 0.0250226\n[800]\tTrain's rmse: 0.0212874\tValid's rmse: 0.0250157\n[900]\tTrain's rmse: 0.0212666\tValid's rmse: 0.0250098\n[1000]\tTrain's rmse: 0.021246\tValid's rmse: 0.0250033\n[1100]\tTrain's rmse: 0.021226\tValid's rmse: 0.0250036\n[1200]\tTrain's rmse: 0.021207\tValid's rmse: 0.0249996\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  35%|###5      | 7/20 [05:14<09:51, 45.46s/it]\u001b[32m[I 2022-04-22 10:54:40,263]\u001b[0m Trial 13 finished with value: 0.02499934517728724 and parameters: {'num_leaves': 28}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  35%|###5      | 7/20 [05:14<09:51, 45.46s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[1195]\tTrain's rmse: 0.0212081\tValid's rmse: 0.0249993\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021387\tValid's rmse: 0.0250757\n[200]\tTrain's rmse: 0.0212482\tValid's rmse: 0.0250442\n[300]\tTrain's rmse: 0.0211282\tValid's rmse: 0.0250317\n[400]\tTrain's rmse: 0.0210171\tValid's rmse: 0.0250171\n[500]\tTrain's rmse: 0.0209131\tValid's rmse: 0.0250075\n[600]\tTrain's rmse: 0.0208154\tValid's rmse: 0.0250011\n[700]\tTrain's rmse: 0.0207205\tValid's rmse: 0.0249992\n[800]\tTrain's rmse: 0.0206301\tValid's rmse: 0.0249964\n[900]\tTrain's rmse: 0.0205444\tValid's rmse: 0.0249943\n[1000]\tTrain's rmse: 0.0204593\tValid's rmse: 0.024992\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0204769\tValid's rmse: 0.0249909\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  40%|####      | 8/20 [06:23<10:32, 52.74s/it]\u001b[32m[I 2022-04-22 10:55:48,599]\u001b[0m Trial 14 finished with value: 0.02499091841736845 and parameters: {'num_leaves': 213}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  40%|####      | 8/20 [06:23<10:32, 52.74s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057948 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0213762\tValid's rmse: 0.0250771\n[200]\tTrain's rmse: 0.0212281\tValid's rmse: 0.0250473\n[300]\tTrain's rmse: 0.0210992\tValid's rmse: 0.025031\n[400]\tTrain's rmse: 0.0209793\tValid's rmse: 0.025016\n[500]\tTrain's rmse: 0.0208673\tValid's rmse: 0.0250093\n[600]\tTrain's rmse: 0.0207613\tValid's rmse: 0.0250031\n[700]\tTrain's rmse: 0.0206589\tValid's rmse: 0.0250032\nEarly stopping, best iteration is:\n[607]\tTrain's rmse: 0.0207541\tValid's rmse: 0.0250027\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  45%|####5     | 9/20 [07:12<09:27, 51.57s/it]\u001b[32m[I 2022-04-22 10:56:37,581]\u001b[0m Trial 15 finished with value: 0.025002704915109863 and parameters: {'num_leaves': 242}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  45%|####5     | 9/20 [07:12<09:27, 51.57s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058872 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214322\tValid's rmse: 0.0250819\n[200]\tTrain's rmse: 0.021334\tValid's rmse: 0.0250491\n[300]\tTrain's rmse: 0.0212507\tValid's rmse: 0.0250352\n[400]\tTrain's rmse: 0.0211757\tValid's rmse: 0.0250195\n[500]\tTrain's rmse: 0.0211065\tValid's rmse: 0.0250071\n[600]\tTrain's rmse: 0.0210407\tValid's rmse: 0.0249969\n[700]\tTrain's rmse: 0.0209768\tValid's rmse: 0.0249954\n[800]\tTrain's rmse: 0.0209165\tValid's rmse: 0.0249927\n[900]\tTrain's rmse: 0.0208595\tValid's rmse: 0.0249865\n[1000]\tTrain's rmse: 0.0208024\tValid's rmse: 0.0249803\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0208142\tValid's rmse: 0.0249794\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  50%|#####     | 10/20 [08:02<08:33, 51.31s/it]\u001b[32m[I 2022-04-22 10:57:28,312]\u001b[0m Trial 16 finished with value: 0.0249794366481069 and parameters: {'num_leaves': 114}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  50%|#####     | 10/20 [08:02<08:33, 51.31s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058543 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214178\tValid's rmse: 0.0250805\n[200]\tTrain's rmse: 0.0213062\tValid's rmse: 0.0250484\n[300]\tTrain's rmse: 0.0212117\tValid's rmse: 0.0250341\n[400]\tTrain's rmse: 0.0211246\tValid's rmse: 0.0250169\n[500]\tTrain's rmse: 0.0210447\tValid's rmse: 0.0250065\n[600]\tTrain's rmse: 0.0209685\tValid's rmse: 0.0249975\n[700]\tTrain's rmse: 0.0208959\tValid's rmse: 0.0249981\nEarly stopping, best iteration is:\n[655]\tTrain's rmse: 0.0209283\tValid's rmse: 0.0249966\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  55%|#####5    | 11/20 [08:44<07:14, 48.31s/it]\u001b[32m[I 2022-04-22 10:58:09,804]\u001b[0m Trial 17 finished with value: 0.024996593943804723 and parameters: {'num_leaves': 142}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  55%|#####5    | 11/20 [08:44<07:14, 48.31s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058250 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214397\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213477\tValid's rmse: 0.0250515\n[300]\tTrain's rmse: 0.02127\tValid's rmse: 0.0250356\n[400]\tTrain's rmse: 0.0212001\tValid's rmse: 0.0250191\n[500]\tTrain's rmse: 0.021136\tValid's rmse: 0.0250064\n[600]\tTrain's rmse: 0.021075\tValid's rmse: 0.024996\n[700]\tTrain's rmse: 0.0210164\tValid's rmse: 0.0249938\n[800]\tTrain's rmse: 0.0209605\tValid's rmse: 0.0249917\n[900]\tTrain's rmse: 0.0209082\tValid's rmse: 0.0249863\n[1000]\tTrain's rmse: 0.0208562\tValid's rmse: 0.0249823\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0208669\tValid's rmse: 0.0249802\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  60%|######    | 12/20 [09:32<06:25, 48.24s/it]\u001b[32m[I 2022-04-22 10:58:57,886]\u001b[0m Trial 18 finished with value: 0.024980159724309253 and parameters: {'num_leaves': 101}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  60%|######    | 12/20 [09:32<06:25, 48.24s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058508 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214525\tValid's rmse: 0.0250842\n[200]\tTrain's rmse: 0.0213721\tValid's rmse: 0.0250541\n[300]\tTrain's rmse: 0.0213048\tValid's rmse: 0.0250399\n[400]\tTrain's rmse: 0.0212447\tValid's rmse: 0.0250217\n[500]\tTrain's rmse: 0.0211897\tValid's rmse: 0.0250101\n[600]\tTrain's rmse: 0.0211377\tValid's rmse: 0.0250003\n[700]\tTrain's rmse: 0.0210879\tValid's rmse: 0.0249968\n[800]\tTrain's rmse: 0.0210407\tValid's rmse: 0.0249935\n[900]\tTrain's rmse: 0.0209961\tValid's rmse: 0.0249848\n[1000]\tTrain's rmse: 0.0209517\tValid's rmse: 0.0249795\n[1100]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249802\nEarly stopping, best iteration is:\n[1014]\tTrain's rmse: 0.0209454\tValid's rmse: 0.0249784\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  65%|######5   | 13/20 [10:17<05:30, 47.21s/it]\u001b[32m[I 2022-04-22 10:59:42,718]\u001b[0m Trial 19 finished with value: 0.024978429500118873 and parameters: {'num_leaves': 80}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  65%|######5   | 13/20 [10:17<05:30, 47.21s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059300 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214077\tValid's rmse: 0.0250779\n[200]\tTrain's rmse: 0.0212876\tValid's rmse: 0.0250466\n[300]\tTrain's rmse: 0.021185\tValid's rmse: 0.0250327\n[400]\tTrain's rmse: 0.0210908\tValid's rmse: 0.0250163\n[500]\tTrain's rmse: 0.0210034\tValid's rmse: 0.0250059\n[600]\tTrain's rmse: 0.02092\tValid's rmse: 0.0249994\n[700]\tTrain's rmse: 0.0208404\tValid's rmse: 0.0249991\n[800]\tTrain's rmse: 0.0207645\tValid's rmse: 0.0249962\n[900]\tTrain's rmse: 0.0206922\tValid's rmse: 0.0249933\n[1000]\tTrain's rmse: 0.0206201\tValid's rmse: 0.0249909\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0206349\tValid's rmse: 0.0249891\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  70%|#######   | 14/20 [11:17<05:06, 51.14s/it]\u001b[32m[I 2022-04-22 11:00:42,955]\u001b[0m Trial 20 finished with value: 0.02498910070792199 and parameters: {'num_leaves': 163}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  70%|#######   | 14/20 [11:17<05:06, 51.14s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057840 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214563\tValid's rmse: 0.0250854\n[200]\tTrain's rmse: 0.0213788\tValid's rmse: 0.0250546\n[300]\tTrain's rmse: 0.0213144\tValid's rmse: 0.0250404\n[400]\tTrain's rmse: 0.0212565\tValid's rmse: 0.0250253\n[500]\tTrain's rmse: 0.0212042\tValid's rmse: 0.0250133\n[600]\tTrain's rmse: 0.0211544\tValid's rmse: 0.0250039\n[700]\tTrain's rmse: 0.0211068\tValid's rmse: 0.0249992\n[800]\tTrain's rmse: 0.0210612\tValid's rmse: 0.0249952\n[900]\tTrain's rmse: 0.0210189\tValid's rmse: 0.0249882\n[1000]\tTrain's rmse: 0.0209764\tValid's rmse: 0.0249808\n[1100]\tTrain's rmse: 0.0209355\tValid's rmse: 0.02498\n[1200]\tTrain's rmse: 0.0208959\tValid's rmse: 0.0249792\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209176\tValid's rmse: 0.0249779\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  75%|#######5  | 15/20 [12:06<04:12, 50.48s/it]\u001b[32m[I 2022-04-22 11:01:31,895]\u001b[0m Trial 21 finished with value: 0.02497794169268381 and parameters: {'num_leaves': 75}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  75%|#######5  | 15/20 [12:06<04:12, 50.48s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058821 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214617\tValid's rmse: 0.0250854\n[200]\tTrain's rmse: 0.0213888\tValid's rmse: 0.0250574\n[300]\tTrain's rmse: 0.0213291\tValid's rmse: 0.0250432\n[400]\tTrain's rmse: 0.021275\tValid's rmse: 0.0250273\n[500]\tTrain's rmse: 0.0212266\tValid's rmse: 0.0250179\n[600]\tTrain's rmse: 0.0211802\tValid's rmse: 0.0250101\n[700]\tTrain's rmse: 0.0211361\tValid's rmse: 0.0250046\n[800]\tTrain's rmse: 0.0210941\tValid's rmse: 0.0249989\n[900]\tTrain's rmse: 0.0210549\tValid's rmse: 0.0249918\n[1000]\tTrain's rmse: 0.0210157\tValid's rmse: 0.024985\n[1100]\tTrain's rmse: 0.020978\tValid's rmse: 0.0249835\n[1200]\tTrain's rmse: 0.0209418\tValid's rmse: 0.0249806\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0209615\tValid's rmse: 0.0249797\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  80%|########  | 16/20 [12:52<03:16, 49.12s/it]\u001b[32m[I 2022-04-22 11:02:17,864]\u001b[0m Trial 22 finished with value: 0.024979657607697926 and parameters: {'num_leaves': 67}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  80%|########  | 16/20 [12:52<03:16, 49.12s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060023 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214014\tValid's rmse: 0.0250782\n[200]\tTrain's rmse: 0.0212764\tValid's rmse: 0.0250479\n[300]\tTrain's rmse: 0.021168\tValid's rmse: 0.0250323\n[400]\tTrain's rmse: 0.0210678\tValid's rmse: 0.025016\n[500]\tTrain's rmse: 0.0209749\tValid's rmse: 0.0250049\n[600]\tTrain's rmse: 0.0208873\tValid's rmse: 0.0249978\n[700]\tTrain's rmse: 0.0208025\tValid's rmse: 0.024996\n[800]\tTrain's rmse: 0.0207219\tValid's rmse: 0.0249912\n[900]\tTrain's rmse: 0.020646\tValid's rmse: 0.0249875\n[1000]\tTrain's rmse: 0.0205704\tValid's rmse: 0.0249847\nEarly stopping, best iteration is:\n[979]\tTrain's rmse: 0.0205863\tValid's rmse: 0.0249832\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  85%|########5 | 17/20 [13:55<02:39, 53.20s/it]\u001b[32m[I 2022-04-22 11:03:20,557]\u001b[0m Trial 23 finished with value: 0.024983227489171055 and parameters: {'num_leaves': 177}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  85%|########5 | 17/20 [13:55<02:39, 53.20s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058423 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0215512\tValid's rmse: 0.0251341\n[200]\tTrain's rmse: 0.0215423\tValid's rmse: 0.0251273\n[300]\tTrain's rmse: 0.0215363\tValid's rmse: 0.0251239\n[400]\tTrain's rmse: 0.0215318\tValid's rmse: 0.0251201\n[500]\tTrain's rmse: 0.0215282\tValid's rmse: 0.0251192\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  90%|######### | 18/20 [14:01<01:18, 39.02s/it]\u001b[32m[I 2022-04-22 11:03:26,564]\u001b[0m Trial 24 finished with value: 0.025118321131473914 and parameters: {'num_leaves': 2}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  90%|######### | 18/20 [14:01<01:18, 39.02s/it]","output_type":"stream"},{"name":"stdout","text":"Early stopping, best iteration is:\n[451]\tTrain's rmse: 0.0215298\tValid's rmse: 0.0251183\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021429\tValid's rmse: 0.0250822\n[200]\tTrain's rmse: 0.0213283\tValid's rmse: 0.0250517\n[300]\tTrain's rmse: 0.0212427\tValid's rmse: 0.0250373\n[400]\tTrain's rmse: 0.0211649\tValid's rmse: 0.0250198\n[500]\tTrain's rmse: 0.0210932\tValid's rmse: 0.025007\n[600]\tTrain's rmse: 0.0210247\tValid's rmse: 0.0249976\n[700]\tTrain's rmse: 0.0209591\tValid's rmse: 0.0249954\nEarly stopping, best iteration is:\n[655]\tTrain's rmse: 0.0209885\tValid's rmse: 0.0249943\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975:  95%|#########5| 19/20 [14:38<00:38, 38.55s/it]\u001b[32m[I 2022-04-22 11:04:04,017]\u001b[0m Trial 25 finished with value: 0.02499434417508548 and parameters: {'num_leaves': 120}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975:  95%|#########5| 19/20 [14:38<00:38, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060077 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214638\tValid's rmse: 0.0250874\n[200]\tTrain's rmse: 0.0213927\tValid's rmse: 0.0250583\n[300]\tTrain's rmse: 0.0213348\tValid's rmse: 0.0250427\n[400]\tTrain's rmse: 0.0212826\tValid's rmse: 0.0250276\n[500]\tTrain's rmse: 0.0212355\tValid's rmse: 0.0250183\n[600]\tTrain's rmse: 0.0211904\tValid's rmse: 0.0250093\n[700]\tTrain's rmse: 0.0211479\tValid's rmse: 0.0250054\n[800]\tTrain's rmse: 0.0211073\tValid's rmse: 0.0249999\n[900]\tTrain's rmse: 0.0210695\tValid's rmse: 0.0249931\n[1000]\tTrain's rmse: 0.0210315\tValid's rmse: 0.0249838\n[1100]\tTrain's rmse: 0.0209951\tValid's rmse: 0.0249815\n[1200]\tTrain's rmse: 0.0209598\tValid's rmse: 0.0249772\nEarly stopping, best iteration is:\n[1194]\tTrain's rmse: 0.0209618\tValid's rmse: 0.0249767\n","output_type":"stream"},{"name":"stderr","text":"num_leaves, val_score: 0.024975: 100%|##########| 20/20 [15:25<00:00, 40.98s/it]\u001b[32m[I 2022-04-22 11:04:50,659]\u001b[0m Trial 26 finished with value: 0.024976658674561517 and parameters: {'num_leaves': 64}. Best is trial 8 with value: 0.024974720462748096.\u001b[0m\nnum_leaves, val_score: 0.024975: 100%|##########| 20/20 [15:25<00:00, 46.26s/it]\nbagging, val_score: 0.024975:   0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058483 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214387\tValid's rmse: 0.0250873\n[200]\tTrain's rmse: 0.0213452\tValid's rmse: 0.0250577\n[300]\tTrain's rmse: 0.0212672\tValid's rmse: 0.0250399\n[400]\tTrain's rmse: 0.0211971\tValid's rmse: 0.0250251\n[500]\tTrain's rmse: 0.021133\tValid's rmse: 0.0250155\n[600]\tTrain's rmse: 0.0210722\tValid's rmse: 0.0250098\n[700]\tTrain's rmse: 0.0210145\tValid's rmse: 0.0250044\n[800]\tTrain's rmse: 0.0209604\tValid's rmse: 0.0250012\n[900]\tTrain's rmse: 0.0209095\tValid's rmse: 0.0249994\n[1000]\tTrain's rmse: 0.0208584\tValid's rmse: 0.0249983\n[1100]\tTrain's rmse: 0.0208103\tValid's rmse: 0.0249966\n[1200]\tTrain's rmse: 0.0207642\tValid's rmse: 0.0249973\nEarly stopping, best iteration is:\n[1144]\tTrain's rmse: 0.0207901\tValid's rmse: 0.0249958\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  10%|#         | 1/10 [00:54<08:08, 54.28s/it]\u001b[32m[I 2022-04-22 11:05:44,951]\u001b[0m Trial 27 finished with value: 0.02499580541961115 and parameters: {'bagging_fraction': 0.8202344585880483, 'bagging_freq': 4}. Best is trial 27 with value: 0.02499580541961115.\u001b[0m\nbagging, val_score: 0.024975:  10%|#         | 1/10 [00:54<08:08, 54.28s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057934 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214396\tValid's rmse: 0.0250828\n[200]\tTrain's rmse: 0.0213484\tValid's rmse: 0.0250511\n[300]\tTrain's rmse: 0.0212726\tValid's rmse: 0.0250358\n[400]\tTrain's rmse: 0.0212031\tValid's rmse: 0.02502\n[500]\tTrain's rmse: 0.0211401\tValid's rmse: 0.025009\n[600]\tTrain's rmse: 0.0210797\tValid's rmse: 0.0250031\n[700]\tTrain's rmse: 0.0210228\tValid's rmse: 0.0249976\n[800]\tTrain's rmse: 0.0209689\tValid's rmse: 0.0249941\n[900]\tTrain's rmse: 0.020918\tValid's rmse: 0.0249927\n[1000]\tTrain's rmse: 0.0208684\tValid's rmse: 0.0249905\nEarly stopping, best iteration is:\n[982]\tTrain's rmse: 0.0208773\tValid's rmse: 0.0249898\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  20%|##        | 2/10 [01:42<06:47, 50.94s/it]\u001b[32m[I 2022-04-22 11:06:33,554]\u001b[0m Trial 28 finished with value: 0.024989836055415954 and parameters: {'bagging_fraction': 0.7251885811653775, 'bagging_freq': 5}. Best is trial 28 with value: 0.024989836055415954.\u001b[0m\nbagging, val_score: 0.024975:  20%|##        | 2/10 [01:42<06:47, 50.94s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058904 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214413\tValid's rmse: 0.0250812\n[200]\tTrain's rmse: 0.0213516\tValid's rmse: 0.0250519\n[300]\tTrain's rmse: 0.0212766\tValid's rmse: 0.0250339\n[400]\tTrain's rmse: 0.0212089\tValid's rmse: 0.0250247\n[500]\tTrain's rmse: 0.0211462\tValid's rmse: 0.0250197\n[600]\tTrain's rmse: 0.0210882\tValid's rmse: 0.0250097\n[700]\tTrain's rmse: 0.0210327\tValid's rmse: 0.0250033\n[800]\tTrain's rmse: 0.0209795\tValid's rmse: 0.0249957\n[900]\tTrain's rmse: 0.0209286\tValid's rmse: 0.0249938\n[1000]\tTrain's rmse: 0.0208786\tValid's rmse: 0.0249908\n[1100]\tTrain's rmse: 0.0208315\tValid's rmse: 0.0249928\nEarly stopping, best iteration is:\n[1038]\tTrain's rmse: 0.0208606\tValid's rmse: 0.0249901\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  30%|###       | 3/10 [02:31<05:50, 50.06s/it]\u001b[32m[I 2022-04-22 11:07:22,558]\u001b[0m Trial 29 finished with value: 0.02499007390276077 and parameters: {'bagging_fraction': 0.6479140777610455, 'bagging_freq': 7}. Best is trial 28 with value: 0.024989836055415954.\u001b[0m\nbagging, val_score: 0.024975:  30%|###       | 3/10 [02:31<05:50, 50.06s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057796 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214406\tValid's rmse: 0.0250821\n[200]\tTrain's rmse: 0.0213488\tValid's rmse: 0.0250524\n[300]\tTrain's rmse: 0.021272\tValid's rmse: 0.0250358\n[400]\tTrain's rmse: 0.0212031\tValid's rmse: 0.0250191\n[500]\tTrain's rmse: 0.0211396\tValid's rmse: 0.0250108\n[600]\tTrain's rmse: 0.0210784\tValid's rmse: 0.0250043\n[700]\tTrain's rmse: 0.021022\tValid's rmse: 0.0249972\n[800]\tTrain's rmse: 0.0209675\tValid's rmse: 0.0249948\n[900]\tTrain's rmse: 0.0209163\tValid's rmse: 0.0249924\n[1000]\tTrain's rmse: 0.0208668\tValid's rmse: 0.0249926\nEarly stopping, best iteration is:\n[920]\tTrain's rmse: 0.0209065\tValid's rmse: 0.0249911\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  40%|####      | 4/10 [03:12<04:37, 46.31s/it]\u001b[32m[I 2022-04-22 11:08:03,121]\u001b[0m Trial 30 finished with value: 0.02499112427503526 and parameters: {'bagging_fraction': 0.7245267238675048, 'bagging_freq': 1}. Best is trial 28 with value: 0.024989836055415954.\u001b[0m\nbagging, val_score: 0.024975:  40%|####      | 4/10 [03:12<04:37, 46.31s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058471 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214431\tValid's rmse: 0.0250854\n[200]\tTrain's rmse: 0.0213541\tValid's rmse: 0.0250506\n[300]\tTrain's rmse: 0.0212804\tValid's rmse: 0.0250323\n[400]\tTrain's rmse: 0.0212149\tValid's rmse: 0.0250204\n[500]\tTrain's rmse: 0.021154\tValid's rmse: 0.0250117\n[600]\tTrain's rmse: 0.0210954\tValid's rmse: 0.0249996\n[700]\tTrain's rmse: 0.0210409\tValid's rmse: 0.0249965\n[800]\tTrain's rmse: 0.0209891\tValid's rmse: 0.0249939\n[900]\tTrain's rmse: 0.0209399\tValid's rmse: 0.0249917\n[1000]\tTrain's rmse: 0.0208912\tValid's rmse: 0.0249913\nEarly stopping, best iteration is:\n[986]\tTrain's rmse: 0.0208979\tValid's rmse: 0.02499\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  50%|#####     | 5/10 [03:59<03:52, 46.46s/it]\u001b[32m[I 2022-04-22 11:08:49,858]\u001b[0m Trial 31 finished with value: 0.02498996524234578 and parameters: {'bagging_fraction': 0.5824770578345255, 'bagging_freq': 3}. Best is trial 28 with value: 0.024989836055415954.\u001b[0m\nbagging, val_score: 0.024975:  50%|#####     | 5/10 [03:59<03:52, 46.46s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057908 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214356\tValid's rmse: 0.0250852\n[200]\tTrain's rmse: 0.0213419\tValid's rmse: 0.0250541\n[300]\tTrain's rmse: 0.0212633\tValid's rmse: 0.0250356\n[400]\tTrain's rmse: 0.0211926\tValid's rmse: 0.0250188\n[500]\tTrain's rmse: 0.0211266\tValid's rmse: 0.0250095\n[600]\tTrain's rmse: 0.0210642\tValid's rmse: 0.0250034\n[700]\tTrain's rmse: 0.0210072\tValid's rmse: 0.0249986\n[800]\tTrain's rmse: 0.0209535\tValid's rmse: 0.0249977\n[900]\tTrain's rmse: 0.0209024\tValid's rmse: 0.0249983\nEarly stopping, best iteration is:\n[820]\tTrain's rmse: 0.0209432\tValid's rmse: 0.0249969\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  60%|######    | 6/10 [04:41<03:00, 45.05s/it]\u001b[32m[I 2022-04-22 11:09:32,175]\u001b[0m Trial 32 finished with value: 0.024996854691392394 and parameters: {'bagging_fraction': 0.9007411962444317, 'bagging_freq': 7}. Best is trial 28 with value: 0.024989836055415954.\u001b[0m\nbagging, val_score: 0.024975:  60%|######    | 6/10 [04:41<03:00, 45.05s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060366 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214415\tValid's rmse: 0.0250831\n[200]\tTrain's rmse: 0.0213514\tValid's rmse: 0.0250543\n[300]\tTrain's rmse: 0.021276\tValid's rmse: 0.0250367\n[400]\tTrain's rmse: 0.0212077\tValid's rmse: 0.025025\n[500]\tTrain's rmse: 0.021144\tValid's rmse: 0.0250181\n[600]\tTrain's rmse: 0.0210857\tValid's rmse: 0.0250089\n[700]\tTrain's rmse: 0.0210297\tValid's rmse: 0.0250049\n[800]\tTrain's rmse: 0.020977\tValid's rmse: 0.0250013\n[900]\tTrain's rmse: 0.0209263\tValid's rmse: 0.024999\n[1000]\tTrain's rmse: 0.0208767\tValid's rmse: 0.0249967\n[1100]\tTrain's rmse: 0.0208292\tValid's rmse: 0.024998\n[1200]\tTrain's rmse: 0.020783\tValid's rmse: 0.0249973\nEarly stopping, best iteration is:\n[1142]\tTrain's rmse: 0.0208094\tValid's rmse: 0.0249954\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  70%|#######   | 7/10 [05:34<02:22, 47.66s/it]\u001b[32m[I 2022-04-22 11:10:25,192]\u001b[0m Trial 33 finished with value: 0.02499543648913422 and parameters: {'bagging_fraction': 0.6657106140134859, 'bagging_freq': 7}. Best is trial 28 with value: 0.024989836055415954.\u001b[0m\nbagging, val_score: 0.024975:  70%|#######   | 7/10 [05:34<02:22, 47.66s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061133 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214501\tValid's rmse: 0.0250853\n[200]\tTrain's rmse: 0.0213673\tValid's rmse: 0.0250557\n[300]\tTrain's rmse: 0.0212973\tValid's rmse: 0.0250415\n[400]\tTrain's rmse: 0.0212345\tValid's rmse: 0.0250272\n[500]\tTrain's rmse: 0.0211767\tValid's rmse: 0.0250194\n[600]\tTrain's rmse: 0.0211227\tValid's rmse: 0.0250094\n[700]\tTrain's rmse: 0.0210704\tValid's rmse: 0.0250106\nEarly stopping, best iteration is:\n[601]\tTrain's rmse: 0.0211222\tValid's rmse: 0.0250094\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  80%|########  | 8/10 [06:04<01:24, 42.08s/it]\u001b[32m[I 2022-04-22 11:10:55,334]\u001b[0m Trial 34 finished with value: 0.025009397434912567 and parameters: {'bagging_fraction': 0.42505956506940923, 'bagging_freq': 5}. Best is trial 28 with value: 0.024989836055415954.\u001b[0m\nbagging, val_score: 0.024975:  80%|########  | 8/10 [06:04<01:24, 42.08s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057989 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214394\tValid's rmse: 0.0250841\n[200]\tTrain's rmse: 0.0213475\tValid's rmse: 0.0250537\n[300]\tTrain's rmse: 0.0212702\tValid's rmse: 0.0250351\n[400]\tTrain's rmse: 0.0212013\tValid's rmse: 0.0250201\n[500]\tTrain's rmse: 0.0211371\tValid's rmse: 0.0250089\n[600]\tTrain's rmse: 0.021077\tValid's rmse: 0.0250029\n[700]\tTrain's rmse: 0.02102\tValid's rmse: 0.0249948\n[800]\tTrain's rmse: 0.020966\tValid's rmse: 0.0249921\n[900]\tTrain's rmse: 0.0209145\tValid's rmse: 0.0249909\n[1000]\tTrain's rmse: 0.0208648\tValid's rmse: 0.0249911\nEarly stopping, best iteration is:\n[971]\tTrain's rmse: 0.0208792\tValid's rmse: 0.0249891\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975:  90%|######### | 9/10 [06:51<00:43, 43.61s/it]\u001b[32m[I 2022-04-22 11:11:42,302]\u001b[0m Trial 35 finished with value: 0.024989112667533394 and parameters: {'bagging_fraction': 0.7464887956998969, 'bagging_freq': 6}. Best is trial 35 with value: 0.024989112667533394.\u001b[0m\nbagging, val_score: 0.024975:  90%|######### | 9/10 [06:51<00:43, 43.61s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057430 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214394\tValid's rmse: 0.025084\n[200]\tTrain's rmse: 0.0213475\tValid's rmse: 0.0250557\n[300]\tTrain's rmse: 0.021271\tValid's rmse: 0.0250414\n[400]\tTrain's rmse: 0.0212018\tValid's rmse: 0.0250255\n[500]\tTrain's rmse: 0.0211379\tValid's rmse: 0.0250197\n[600]\tTrain's rmse: 0.021078\tValid's rmse: 0.0250114\n[700]\tTrain's rmse: 0.0210205\tValid's rmse: 0.0250053\n[800]\tTrain's rmse: 0.020967\tValid's rmse: 0.0250019\n[900]\tTrain's rmse: 0.0209153\tValid's rmse: 0.0249993\nEarly stopping, best iteration is:\n[894]\tTrain's rmse: 0.0209184\tValid's rmse: 0.0249985\n","output_type":"stream"},{"name":"stderr","text":"bagging, val_score: 0.024975: 100%|##########| 10/10 [07:36<00:00, 44.03s/it]\u001b[32m[I 2022-04-22 11:12:27,287]\u001b[0m Trial 36 finished with value: 0.02499853052162214 and parameters: {'bagging_fraction': 0.7523534315599849, 'bagging_freq': 7}. Best is trial 35 with value: 0.024989112667533394.\u001b[0m\nbagging, val_score: 0.024975: 100%|##########| 10/10 [07:36<00:00, 45.66s/it]\nfeature_fraction_stage2, val_score: 0.024975:   0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058338 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214468\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213611\tValid's rmse: 0.0250513\n[300]\tTrain's rmse: 0.0212895\tValid's rmse: 0.0250372\n[400]\tTrain's rmse: 0.0212254\tValid's rmse: 0.0250197\n[500]\tTrain's rmse: 0.0211662\tValid's rmse: 0.0250057\n[600]\tTrain's rmse: 0.0211103\tValid's rmse: 0.0249963\n[700]\tTrain's rmse: 0.0210564\tValid's rmse: 0.0249932\n[800]\tTrain's rmse: 0.0210052\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209573\tValid's rmse: 0.0249835\n[1000]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249779\n[1100]\tTrain's rmse: 0.0208629\tValid's rmse: 0.0249771\n[1200]\tTrain's rmse: 0.0208185\tValid's rmse: 0.0249764\nEarly stopping, best iteration is:\n[1146]\tTrain's rmse: 0.0208421\tValid's rmse: 0.0249747\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024975:  33%|###3      | 1/3 [00:51<01:42, 51.17s/it]\u001b[32m[I 2022-04-22 11:13:18,465]\u001b[0m Trial 37 finished with value: 0.024974720462748096 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.024974720462748096.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024975:  33%|###3      | 1/3 [00:51<01:42, 51.17s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060032 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214427\tValid's rmse: 0.0250774\n[200]\tTrain's rmse: 0.0213548\tValid's rmse: 0.0250486\n[300]\tTrain's rmse: 0.021281\tValid's rmse: 0.0250362\n[400]\tTrain's rmse: 0.021216\tValid's rmse: 0.0250226\n[500]\tTrain's rmse: 0.0211561\tValid's rmse: 0.0250118\n[600]\tTrain's rmse: 0.021099\tValid's rmse: 0.025001\n[700]\tTrain's rmse: 0.0210441\tValid's rmse: 0.0249995\n[800]\tTrain's rmse: 0.0209914\tValid's rmse: 0.0249944\n[900]\tTrain's rmse: 0.0209423\tValid's rmse: 0.0249892\n[1000]\tTrain's rmse: 0.0208933\tValid's rmse: 0.0249815\n[1100]\tTrain's rmse: 0.0208456\tValid's rmse: 0.0249836\nEarly stopping, best iteration is:\n[1014]\tTrain's rmse: 0.0208864\tValid's rmse: 0.0249808\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024975:  67%|######6   | 2/3 [01:39<00:49, 49.24s/it]\u001b[32m[I 2022-04-22 11:14:06,360]\u001b[0m Trial 38 finished with value: 0.024980822809563912 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.024974720462748096.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024975:  67%|######6   | 2/3 [01:39<00:49, 49.24s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062353 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214399\tValid's rmse: 0.0250755\n[200]\tTrain's rmse: 0.0213503\tValid's rmse: 0.0250424\n[300]\tTrain's rmse: 0.0212757\tValid's rmse: 0.0250297\n[400]\tTrain's rmse: 0.0212086\tValid's rmse: 0.0250151\n[500]\tTrain's rmse: 0.0211471\tValid's rmse: 0.0250062\n[600]\tTrain's rmse: 0.021089\tValid's rmse: 0.0249987\n[700]\tTrain's rmse: 0.0210331\tValid's rmse: 0.0249951\n[800]\tTrain's rmse: 0.0209797\tValid's rmse: 0.0249918\n[900]\tTrain's rmse: 0.0209294\tValid's rmse: 0.0249885\n[1000]\tTrain's rmse: 0.0208792\tValid's rmse: 0.0249838\n[1100]\tTrain's rmse: 0.0208309\tValid's rmse: 0.0249835\nEarly stopping, best iteration is:\n[1013]\tTrain's rmse: 0.0208728\tValid's rmse: 0.0249822\n","output_type":"stream"},{"name":"stderr","text":"feature_fraction_stage2, val_score: 0.024975: 100%|##########| 3/3 [02:27<00:00, 49.06s/it]\u001b[32m[I 2022-04-22 11:14:55,204]\u001b[0m Trial 39 finished with value: 0.024982169597596533 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.024974720462748096.\u001b[0m\nfeature_fraction_stage2, val_score: 0.024975: 100%|##########| 3/3 [02:27<00:00, 49.30s/it]\nregularization_factors, val_score: 0.024975:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058639 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214019\tValid's rmse: 0.0250925\n[200]\tTrain's rmse: 0.0212786\tValid's rmse: 0.0250643\n[300]\tTrain's rmse: 0.0211742\tValid's rmse: 0.0250511\n[400]\tTrain's rmse: 0.0210788\tValid's rmse: 0.0250339\n[500]\tTrain's rmse: 0.0209908\tValid's rmse: 0.0250267\n[600]\tTrain's rmse: 0.0209081\tValid's rmse: 0.0250191\n[700]\tTrain's rmse: 0.0208297\tValid's rmse: 0.0250151\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.0208656\tValid's rmse: 0.0250139\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:   5%|5         | 1/20 [00:24<07:50, 24.76s/it]\u001b[32m[I 2022-04-22 11:15:19,972]\u001b[0m Trial 40 finished with value: 0.025013913656845955 and parameters: {'lambda_l1': 5.195687898648054e-06, 'lambda_l2': 1.995418356453324e-06}. Best is trial 40 with value: 0.025013913656845955.\u001b[0m\nregularization_factors, val_score: 0.024975:   5%|5         | 1/20 [00:24<07:50, 24.76s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058373 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214027\tValid's rmse: 0.0250896\n[200]\tTrain's rmse: 0.0212797\tValid's rmse: 0.0250669\n[300]\tTrain's rmse: 0.0211742\tValid's rmse: 0.0250594\n[400]\tTrain's rmse: 0.0210784\tValid's rmse: 0.025044\n[500]\tTrain's rmse: 0.0209902\tValid's rmse: 0.0250399\n[600]\tTrain's rmse: 0.0209081\tValid's rmse: 0.0250307\n[700]\tTrain's rmse: 0.020831\tValid's rmse: 0.0250271\nEarly stopping, best iteration is:\n[661]\tTrain's rmse: 0.0208612\tValid's rmse: 0.0250251\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  10%|#         | 2/20 [00:49<07:21, 24.50s/it]\u001b[32m[I 2022-04-22 11:15:44,291]\u001b[0m Trial 41 finished with value: 0.025025096223536165 and parameters: {'lambda_l1': 0.012294117225799747, 'lambda_l2': 0.0054678564307486495}. Best is trial 40 with value: 0.025013913656845955.\u001b[0m\nregularization_factors, val_score: 0.024975:  10%|#         | 2/20 [00:49<07:21, 24.50s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058919 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214138\tValid's rmse: 0.0250869\n[200]\tTrain's rmse: 0.0212991\tValid's rmse: 0.025058\n[300]\tTrain's rmse: 0.0212017\tValid's rmse: 0.0250441\n[400]\tTrain's rmse: 0.021114\tValid's rmse: 0.0250334\n[500]\tTrain's rmse: 0.0210323\tValid's rmse: 0.0250229\n[600]\tTrain's rmse: 0.0209539\tValid's rmse: 0.0250158\n[700]\tTrain's rmse: 0.0208813\tValid's rmse: 0.0250128\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.0209145\tValid's rmse: 0.0250118\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  15%|#5        | 3/20 [01:16<07:22, 26.03s/it]\u001b[32m[I 2022-04-22 11:16:12,131]\u001b[0m Trial 42 finished with value: 0.025011840015436968 and parameters: {'lambda_l1': 0.12974800490321228, 'lambda_l2': 1.4095402599706934e-05}. Best is trial 42 with value: 0.025011840015436968.\u001b[0m\nregularization_factors, val_score: 0.024975:  15%|#5        | 3/20 [01:16<07:22, 26.03s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057784 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021404\tValid's rmse: 0.0250898\n[200]\tTrain's rmse: 0.0212814\tValid's rmse: 0.0250636\n[300]\tTrain's rmse: 0.0211781\tValid's rmse: 0.0250531\n[400]\tTrain's rmse: 0.0210826\tValid's rmse: 0.0250376\n[500]\tTrain's rmse: 0.020995\tValid's rmse: 0.0250298\n[600]\tTrain's rmse: 0.0209127\tValid's rmse: 0.0250214\n[700]\tTrain's rmse: 0.0208363\tValid's rmse: 0.0250189\nEarly stopping, best iteration is:\n[657]\tTrain's rmse: 0.0208686\tValid's rmse: 0.0250174\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  20%|##        | 4/20 [01:42<06:55, 25.95s/it]\u001b[32m[I 2022-04-22 11:16:37,955]\u001b[0m Trial 43 finished with value: 0.025017365245893333 and parameters: {'lambda_l1': 0.03107629569798834, 'lambda_l2': 1.1657193290889483e-07}. Best is trial 42 with value: 0.025011840015436968.\u001b[0m\nregularization_factors, val_score: 0.024975:  20%|##        | 4/20 [01:42<06:55, 25.95s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058685 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214018\tValid's rmse: 0.0250893\n[200]\tTrain's rmse: 0.0212783\tValid's rmse: 0.0250612\n[300]\tTrain's rmse: 0.0211734\tValid's rmse: 0.0250475\n[400]\tTrain's rmse: 0.021078\tValid's rmse: 0.0250302\n[500]\tTrain's rmse: 0.0209902\tValid's rmse: 0.0250256\n[600]\tTrain's rmse: 0.0209076\tValid's rmse: 0.0250153\n[700]\tTrain's rmse: 0.0208304\tValid's rmse: 0.0250113\n[800]\tTrain's rmse: 0.0207553\tValid's rmse: 0.0250065\n[900]\tTrain's rmse: 0.0206848\tValid's rmse: 0.0250073\nEarly stopping, best iteration is:\n[803]\tTrain's rmse: 0.0207532\tValid's rmse: 0.0250055\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  25%|##5       | 5/20 [02:11<06:42, 26.85s/it]\u001b[32m[I 2022-04-22 11:17:06,416]\u001b[0m Trial 44 finished with value: 0.025005496896819312 and parameters: {'lambda_l1': 5.889398095173312e-07, 'lambda_l2': 0.05773882902134925}. Best is trial 44 with value: 0.025005496896819312.\u001b[0m\nregularization_factors, val_score: 0.024975:  25%|##5       | 5/20 [02:11<06:42, 26.85s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059363 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214019\tValid's rmse: 0.0250925\n[200]\tTrain's rmse: 0.0212786\tValid's rmse: 0.0250646\n[300]\tTrain's rmse: 0.0211738\tValid's rmse: 0.025051\n[400]\tTrain's rmse: 0.0210781\tValid's rmse: 0.0250331\n[500]\tTrain's rmse: 0.0209899\tValid's rmse: 0.025026\n[600]\tTrain's rmse: 0.0209072\tValid's rmse: 0.0250186\n[700]\tTrain's rmse: 0.0208293\tValid's rmse: 0.0250167\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.020865\tValid's rmse: 0.0250148\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  30%|###       | 6/20 [02:34<06:01, 25.80s/it]\u001b[32m[I 2022-04-22 11:17:30,166]\u001b[0m Trial 45 finished with value: 0.025014766942445154 and parameters: {'lambda_l1': 1.8606043412841866e-07, 'lambda_l2': 4.6024220928067526e-06}. Best is trial 44 with value: 0.025005496896819312.\u001b[0m\nregularization_factors, val_score: 0.024975:  30%|###       | 6/20 [02:34<06:01, 25.80s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011008 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214015\tValid's rmse: 0.0250914\n[200]\tTrain's rmse: 0.0212775\tValid's rmse: 0.0250614\n[300]\tTrain's rmse: 0.0211734\tValid's rmse: 0.0250507\n[400]\tTrain's rmse: 0.0210783\tValid's rmse: 0.0250315\n[500]\tTrain's rmse: 0.0209904\tValid's rmse: 0.0250259\n[600]\tTrain's rmse: 0.0209079\tValid's rmse: 0.0250138\n[700]\tTrain's rmse: 0.0208303\tValid's rmse: 0.0250122\nEarly stopping, best iteration is:\n[660]\tTrain's rmse: 0.0208613\tValid's rmse: 0.0250097\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  35%|###5      | 7/20 [03:01<05:38, 26.04s/it]\u001b[32m[I 2022-04-22 11:17:56,703]\u001b[0m Trial 46 finished with value: 0.02500966452023042 and parameters: {'lambda_l1': 0.00010064818625005978, 'lambda_l2': 0.01661833171276009}. Best is trial 44 with value: 0.025005496896819312.\u001b[0m\nregularization_factors, val_score: 0.024975:  35%|###5      | 7/20 [03:01<05:38, 26.04s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058270 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214019\tValid's rmse: 0.0250925\n[200]\tTrain's rmse: 0.0212786\tValid's rmse: 0.0250646\n[300]\tTrain's rmse: 0.0211738\tValid's rmse: 0.025051\n[400]\tTrain's rmse: 0.0210781\tValid's rmse: 0.0250342\n[500]\tTrain's rmse: 0.0209902\tValid's rmse: 0.0250258\n[600]\tTrain's rmse: 0.0209072\tValid's rmse: 0.0250155\n[700]\tTrain's rmse: 0.0208296\tValid's rmse: 0.0250128\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.020865\tValid's rmse: 0.0250116\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  40%|####      | 8/20 [03:26<05:09, 25.77s/it]\u001b[32m[I 2022-04-22 11:18:21,890]\u001b[0m Trial 47 finished with value: 0.02501163225433855 and parameters: {'lambda_l1': 8.611993071934857e-06, 'lambda_l2': 3.088249048216418e-05}. Best is trial 44 with value: 0.025005496896819312.\u001b[0m\nregularization_factors, val_score: 0.024975:  40%|####      | 8/20 [03:26<05:09, 25.77s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214387\tValid's rmse: 0.0250812\n[200]\tTrain's rmse: 0.0213458\tValid's rmse: 0.0250503\n[300]\tTrain's rmse: 0.0212677\tValid's rmse: 0.0250364\n[400]\tTrain's rmse: 0.0211968\tValid's rmse: 0.0250217\n[500]\tTrain's rmse: 0.0211316\tValid's rmse: 0.0250103\n[600]\tTrain's rmse: 0.0210698\tValid's rmse: 0.025003\n[700]\tTrain's rmse: 0.0210108\tValid's rmse: 0.0250001\n[800]\tTrain's rmse: 0.0209548\tValid's rmse: 0.0249937\n[900]\tTrain's rmse: 0.020902\tValid's rmse: 0.0249878\n[1000]\tTrain's rmse: 0.0208501\tValid's rmse: 0.0249827\n[1100]\tTrain's rmse: 0.0207999\tValid's rmse: 0.0249836\nEarly stopping, best iteration is:\n[1013]\tTrain's rmse: 0.0208432\tValid's rmse: 0.0249817\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  45%|####5     | 9/20 [04:11<05:49, 31.78s/it]\u001b[32m[I 2022-04-22 11:19:06,884]\u001b[0m Trial 48 finished with value: 0.02498173565327452 and parameters: {'lambda_l1': 0.3839564481594833, 'lambda_l2': 0.00046063688623230293}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  45%|####5     | 9/20 [04:11<05:49, 31.78s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057904 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214014\tValid's rmse: 0.0250912\n[200]\tTrain's rmse: 0.0212779\tValid's rmse: 0.0250616\n[300]\tTrain's rmse: 0.0211742\tValid's rmse: 0.0250488\n[400]\tTrain's rmse: 0.0210786\tValid's rmse: 0.0250299\n[500]\tTrain's rmse: 0.0209907\tValid's rmse: 0.0250235\n[600]\tTrain's rmse: 0.0209075\tValid's rmse: 0.0250153\n[700]\tTrain's rmse: 0.0208299\tValid's rmse: 0.0250124\n[800]\tTrain's rmse: 0.0207547\tValid's rmse: 0.0250111\nEarly stopping, best iteration is:\n[780]\tTrain's rmse: 0.0207687\tValid's rmse: 0.0250093\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  50%|#####     | 10/20 [04:39<05:05, 30.57s/it]\u001b[32m[I 2022-04-22 11:19:34,736]\u001b[0m Trial 49 finished with value: 0.025009256273095984 and parameters: {'lambda_l1': 0.00024764425215968315, 'lambda_l2': 2.0723788964256044e-06}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  50%|#####     | 10/20 [04:39<05:05, 30.57s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061441 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tTrain's rmse: 0.0215064\tValid's rmse: 0.02511\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[200]\tTrain's rmse: 0.021471\tValid's rmse: 0.0250944\n[300]\tTrain's rmse: 0.0214447\tValid's rmse: 0.0250858\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[400]\tTrain's rmse: 0.0214231\tValid's rmse: 0.0250771\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[500]\tTrain's rmse: 0.0214044\tValid's rmse: 0.0250685\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[600]\tTrain's rmse: 0.021388\tValid's rmse: 0.0250627\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[700]\tTrain's rmse: 0.0213724\tValid's rmse: 0.0250562\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[800]\tTrain's rmse: 0.0213575\tValid's rmse: 0.0250505\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[900]\tTrain's rmse: 0.0213442\tValid's rmse: 0.0250445\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1000]\tTrain's rmse: 0.0213312\tValid's rmse: 0.025036\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1100]\tTrain's rmse: 0.0213187\tValid's rmse: 0.0250335\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1200]\tTrain's rmse: 0.0213075\tValid's rmse: 0.0250313\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0213136\tValid's rmse: 0.0250304\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  55%|#####5    | 11/20 [05:41<06:00, 40.04s/it]\u001b[32m[I 2022-04-22 11:20:36,249]\u001b[0m Trial 50 finished with value: 0.025030361432065756 and parameters: {'lambda_l1': 3.535217513297179, 'lambda_l2': 3.9021223923593578}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  55%|#####5    | 11/20 [05:41<06:00, 40.04s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059329 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214034\tValid's rmse: 0.0250906\n[200]\tTrain's rmse: 0.0212812\tValid's rmse: 0.0250645\n[300]\tTrain's rmse: 0.0211768\tValid's rmse: 0.0250524\n[400]\tTrain's rmse: 0.0210819\tValid's rmse: 0.0250339\n[500]\tTrain's rmse: 0.0209941\tValid's rmse: 0.025026\n[600]\tTrain's rmse: 0.0209119\tValid's rmse: 0.0250182\n[700]\tTrain's rmse: 0.0208349\tValid's rmse: 0.0250137\n[800]\tTrain's rmse: 0.020761\tValid's rmse: 0.0250129\n[900]\tTrain's rmse: 0.0206914\tValid's rmse: 0.0250119\n[1000]\tTrain's rmse: 0.0206225\tValid's rmse: 0.0250088\n[1100]\tTrain's rmse: 0.0205567\tValid's rmse: 0.0250079\n[1200]\tTrain's rmse: 0.0204941\tValid's rmse: 0.0250062\nEarly stopping, best iteration is:\n[1122]\tTrain's rmse: 0.0205421\tValid's rmse: 0.0250049\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  60%|######    | 12/20 [06:16<05:10, 38.77s/it]\u001b[32m[I 2022-04-22 11:21:12,134]\u001b[0m Trial 51 finished with value: 0.025004899134482506 and parameters: {'lambda_l1': 1.2443102401327002e-08, 'lambda_l2': 0.3274565568810466}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  60%|######    | 12/20 [06:16<05:10, 38.77s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058268 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214149\tValid's rmse: 0.0250873\n[200]\tTrain's rmse: 0.0213026\tValid's rmse: 0.0250566\n[300]\tTrain's rmse: 0.0212059\tValid's rmse: 0.0250439\n[400]\tTrain's rmse: 0.0211187\tValid's rmse: 0.0250297\n[500]\tTrain's rmse: 0.0210385\tValid's rmse: 0.0250263\n[600]\tTrain's rmse: 0.0209612\tValid's rmse: 0.025019\n[700]\tTrain's rmse: 0.0208897\tValid's rmse: 0.0250165\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.0209226\tValid's rmse: 0.0250155\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  65%|######5   | 13/20 [06:43<04:04, 34.99s/it]\u001b[32m[I 2022-04-22 11:21:38,420]\u001b[0m Trial 52 finished with value: 0.025015489586266735 and parameters: {'lambda_l1': 1.2803656708494696e-08, 'lambda_l2': 4.842988795945635}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  65%|######5   | 13/20 [06:43<04:04, 34.99s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012655 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tTrain's rmse: 0.0215124\tValid's rmse: 0.0251136\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[200]\tTrain's rmse: 0.0214814\tValid's rmse: 0.0250996\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[300]\tTrain's rmse: 0.0214596\tValid's rmse: 0.0250931\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[400]\tTrain's rmse: 0.0214414\tValid's rmse: 0.0250854\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[500]\tTrain's rmse: 0.0214265\tValid's rmse: 0.0250775\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[600]\tTrain's rmse: 0.0214131\tValid's rmse: 0.0250727\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[700]\tTrain's rmse: 0.0214007\tValid's rmse: 0.0250669\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[800]\tTrain's rmse: 0.0213893\tValid's rmse: 0.0250621\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[900]\tTrain's rmse: 0.021379\tValid's rmse: 0.0250562\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1000]\tTrain's rmse: 0.0213692\tValid's rmse: 0.0250481\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1100]\tTrain's rmse: 0.0213598\tValid's rmse: 0.0250459\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1200]\tTrain's rmse: 0.0213517\tValid's rmse: 0.0250435\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0213561\tValid's rmse: 0.0250429\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  70%|#######   | 14/20 [07:49<04:26, 44.34s/it]\u001b[32m[I 2022-04-22 11:22:44,358]\u001b[0m Trial 53 finished with value: 0.02504285995112167 and parameters: {'lambda_l1': 4.435580533838589, 'lambda_l2': 0.0006428559843653865}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  70%|#######   | 14/20 [07:49<04:26, 44.34s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016196 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214053\tValid's rmse: 0.025089\n[200]\tTrain's rmse: 0.0212838\tValid's rmse: 0.0250633\n[300]\tTrain's rmse: 0.0211806\tValid's rmse: 0.0250511\n[400]\tTrain's rmse: 0.0210869\tValid's rmse: 0.0250352\n[500]\tTrain's rmse: 0.0210011\tValid's rmse: 0.0250264\n[600]\tTrain's rmse: 0.0209194\tValid's rmse: 0.0250156\n[700]\tTrain's rmse: 0.0208437\tValid's rmse: 0.0250119\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.0208782\tValid's rmse: 0.0250109\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  75%|#######5  | 15/20 [08:16<03:15, 39.20s/it]\u001b[32m[I 2022-04-22 11:23:11,633]\u001b[0m Trial 54 finished with value: 0.025010929954341822 and parameters: {'lambda_l1': 0.0027017004831212743, 'lambda_l2': 0.8317245246482996}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  75%|#######5  | 15/20 [08:16<03:15, 39.20s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060929 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214019\tValid's rmse: 0.0250925\n[200]\tTrain's rmse: 0.0212786\tValid's rmse: 0.0250646\n[300]\tTrain's rmse: 0.0211738\tValid's rmse: 0.025051\n[400]\tTrain's rmse: 0.0210781\tValid's rmse: 0.0250342\n[500]\tTrain's rmse: 0.0209902\tValid's rmse: 0.0250258\n[600]\tTrain's rmse: 0.0209073\tValid's rmse: 0.0250156\n[700]\tTrain's rmse: 0.0208298\tValid's rmse: 0.0250128\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.0208652\tValid's rmse: 0.0250118\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  80%|########  | 16/20 [08:41<02:19, 34.88s/it]\u001b[32m[I 2022-04-22 11:23:36,505]\u001b[0m Trial 55 finished with value: 0.025011791693198063 and parameters: {'lambda_l1': 1.3219293158238061e-08, 'lambda_l2': 0.00040008710419557055}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  80%|########  | 16/20 [08:41<02:19, 34.88s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.021431\tValid's rmse: 0.0250846\n[200]\tTrain's rmse: 0.0213322\tValid's rmse: 0.0250532\n[300]\tTrain's rmse: 0.0212485\tValid's rmse: 0.0250383\n[400]\tTrain's rmse: 0.0211721\tValid's rmse: 0.0250247\n[500]\tTrain's rmse: 0.0211024\tValid's rmse: 0.0250177\n[600]\tTrain's rmse: 0.0210367\tValid's rmse: 0.0250113\n[700]\tTrain's rmse: 0.0209739\tValid's rmse: 0.025009\n[800]\tTrain's rmse: 0.0209137\tValid's rmse: 0.0250057\n[900]\tTrain's rmse: 0.0208573\tValid's rmse: 0.0249997\n[1000]\tTrain's rmse: 0.0208017\tValid's rmse: 0.0249954\nEarly stopping, best iteration is:\n[980]\tTrain's rmse: 0.0208124\tValid's rmse: 0.0249936\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  85%|########5 | 17/20 [09:23<01:51, 37.02s/it]\u001b[32m[I 2022-04-22 11:24:18,480]\u001b[0m Trial 56 finished with value: 0.024993551677592457 and parameters: {'lambda_l1': 0.2990619581051263, 'lambda_l2': 0.1658448814109723}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  85%|########5 | 17/20 [09:23<01:51, 37.02s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057590 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214312\tValid's rmse: 0.0250844\n[200]\tTrain's rmse: 0.0213325\tValid's rmse: 0.0250524\n[300]\tTrain's rmse: 0.0212487\tValid's rmse: 0.0250363\n[400]\tTrain's rmse: 0.0211726\tValid's rmse: 0.0250212\n[500]\tTrain's rmse: 0.0211032\tValid's rmse: 0.0250142\n[600]\tTrain's rmse: 0.0210377\tValid's rmse: 0.0250065\n[700]\tTrain's rmse: 0.0209752\tValid's rmse: 0.0250049\nEarly stopping, best iteration is:\n[654]\tTrain's rmse: 0.0210035\tValid's rmse: 0.0250035\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  90%|######### | 18/20 [09:54<01:10, 35.26s/it]\u001b[32m[I 2022-04-22 11:24:49,660]\u001b[0m Trial 57 finished with value: 0.025003540046897286 and parameters: {'lambda_l1': 0.3040167282826595, 'lambda_l2': 1.1162211340887953e-08}. Best is trial 48 with value: 0.02498173565327452.\u001b[0m\nregularization_factors, val_score: 0.024975:  90%|######### | 18/20 [09:54<01:10, 35.26s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057928 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214528\tValid's rmse: 0.0250835\n[200]\tTrain's rmse: 0.0213718\tValid's rmse: 0.0250524\n[300]\tTrain's rmse: 0.0213048\tValid's rmse: 0.0250376\n[400]\tTrain's rmse: 0.0212447\tValid's rmse: 0.0250209\n[500]\tTrain's rmse: 0.0211897\tValid's rmse: 0.0250105\n[600]\tTrain's rmse: 0.0211371\tValid's rmse: 0.025\n[700]\tTrain's rmse: 0.0210869\tValid's rmse: 0.0249951\n[800]\tTrain's rmse: 0.021039\tValid's rmse: 0.0249921\n[900]\tTrain's rmse: 0.0209942\tValid's rmse: 0.0249862\n[1000]\tTrain's rmse: 0.0209494\tValid's rmse: 0.0249784\n[1100]\tTrain's rmse: 0.0209065\tValid's rmse: 0.0249772\n[1200]\tTrain's rmse: 0.0208644\tValid's rmse: 0.0249772\nEarly stopping, best iteration is:\n[1145]\tTrain's rmse: 0.0208873\tValid's rmse: 0.0249748\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975:  95%|#########5| 19/20 [10:47<00:40, 40.56s/it]\u001b[32m[I 2022-04-22 11:25:42,553]\u001b[0m Trial 58 finished with value: 0.024974799055530145 and parameters: {'lambda_l1': 0.6042145330867635, 'lambda_l2': 0.004975309860591777}. Best is trial 58 with value: 0.024974799055530145.\u001b[0m\nregularization_factors, val_score: 0.024975:  95%|#########5| 19/20 [10:47<00:40, 40.56s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062053 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nTraining until validation scores don't improve for 100 rounds\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[100]\tTrain's rmse: 0.0215269\tValid's rmse: 0.0251212\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[200]\tTrain's rmse: 0.0215051\tValid's rmse: 0.0251119\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[300]\tTrain's rmse: 0.0214911\tValid's rmse: 0.0251072\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[400]\tTrain's rmse: 0.0214802\tValid's rmse: 0.0251016\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[500]\tTrain's rmse: 0.0214717\tValid's rmse: 0.0250955\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[600]\tTrain's rmse: 0.0214649\tValid's rmse: 0.0250927\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[700]\tTrain's rmse: 0.0214591\tValid's rmse: 0.0250891\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[800]\tTrain's rmse: 0.0214538\tValid's rmse: 0.025087\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[900]\tTrain's rmse: 0.0214493\tValid's rmse: 0.0250828\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1000]\tTrain's rmse: 0.0214451\tValid's rmse: 0.0250775\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1100]\tTrain's rmse: 0.0214414\tValid's rmse: 0.0250774\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[1200]\tTrain's rmse: 0.0214384\tValid's rmse: 0.0250754\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nEarly stopping, best iteration is:\n[1163]\tTrain's rmse: 0.0214395\tValid's rmse: 0.0250748\n","output_type":"stream"},{"name":"stderr","text":"regularization_factors, val_score: 0.024975: 100%|##########| 20/20 [11:35<00:00, 42.71s/it]\u001b[32m[I 2022-04-22 11:26:30,293]\u001b[0m Trial 59 finished with value: 0.02507476158301904 and parameters: {'lambda_l1': 8.266831869859054, 'lambda_l2': 0.003962047147156072}. Best is trial 58 with value: 0.024974799055530145.\u001b[0m\nregularization_factors, val_score: 0.024975: 100%|##########| 20/20 [11:35<00:00, 34.75s/it]\nmin_data_in_leaf, val_score: 0.024975:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060786 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=100 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214468\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213611\tValid's rmse: 0.0250513\n[300]\tTrain's rmse: 0.0212895\tValid's rmse: 0.0250372\n[400]\tTrain's rmse: 0.0212254\tValid's rmse: 0.0250197\n[500]\tTrain's rmse: 0.0211662\tValid's rmse: 0.0250057\n[600]\tTrain's rmse: 0.0211103\tValid's rmse: 0.0249963\n[700]\tTrain's rmse: 0.0210564\tValid's rmse: 0.0249932\n[800]\tTrain's rmse: 0.0210052\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209573\tValid's rmse: 0.0249835\n[1000]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249779\n[1100]\tTrain's rmse: 0.0208629\tValid's rmse: 0.0249771\n[1200]\tTrain's rmse: 0.0208185\tValid's rmse: 0.0249764\nEarly stopping, best iteration is:\n[1146]\tTrain's rmse: 0.0208421\tValid's rmse: 0.0249747\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  20%|##        | 1/5 [00:53<03:35, 53.82s/it]\u001b[32m[I 2022-04-22 11:27:24,119]\u001b[0m Trial 60 finished with value: 0.024974720462748096 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.024974720462748096.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  20%|##        | 1/5 [00:53<03:35, 53.82s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059427 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=50 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214468\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213611\tValid's rmse: 0.0250513\n[300]\tTrain's rmse: 0.0212895\tValid's rmse: 0.0250372\n[400]\tTrain's rmse: 0.0212254\tValid's rmse: 0.0250197\n[500]\tTrain's rmse: 0.0211662\tValid's rmse: 0.0250057\n[600]\tTrain's rmse: 0.0211103\tValid's rmse: 0.0249963\n[700]\tTrain's rmse: 0.0210564\tValid's rmse: 0.0249932\n[800]\tTrain's rmse: 0.0210052\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209573\tValid's rmse: 0.0249835\n[1000]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249779\n[1100]\tTrain's rmse: 0.0208629\tValid's rmse: 0.0249771\n[1200]\tTrain's rmse: 0.0208185\tValid's rmse: 0.0249764\nEarly stopping, best iteration is:\n[1146]\tTrain's rmse: 0.0208421\tValid's rmse: 0.0249747\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  40%|####      | 2/5 [01:46<02:39, 53.17s/it]\u001b[32m[I 2022-04-22 11:28:16,841]\u001b[0m Trial 61 finished with value: 0.024974720462748096 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.024974720462748096.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  40%|####      | 2/5 [01:46<02:39, 53.17s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060228 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=5 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214468\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213611\tValid's rmse: 0.0250513\n[300]\tTrain's rmse: 0.0212895\tValid's rmse: 0.0250372\n[400]\tTrain's rmse: 0.0212254\tValid's rmse: 0.0250197\n[500]\tTrain's rmse: 0.0211662\tValid's rmse: 0.0250057\n[600]\tTrain's rmse: 0.0211103\tValid's rmse: 0.0249963\n[700]\tTrain's rmse: 0.0210564\tValid's rmse: 0.0249932\n[800]\tTrain's rmse: 0.0210052\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209573\tValid's rmse: 0.0249835\n[1000]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249779\n[1100]\tTrain's rmse: 0.0208629\tValid's rmse: 0.0249771\n[1200]\tTrain's rmse: 0.0208185\tValid's rmse: 0.0249764\nEarly stopping, best iteration is:\n[1146]\tTrain's rmse: 0.0208421\tValid's rmse: 0.0249747\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  60%|######    | 3/5 [02:40<01:46, 53.49s/it]\u001b[32m[I 2022-04-22 11:29:10,718]\u001b[0m Trial 62 finished with value: 0.024974720462748096 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.024974720462748096.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  60%|######    | 3/5 [02:40<01:46, 53.49s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059955 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=10 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214468\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213611\tValid's rmse: 0.0250513\n[300]\tTrain's rmse: 0.0212895\tValid's rmse: 0.0250372\n[400]\tTrain's rmse: 0.0212254\tValid's rmse: 0.0250197\n[500]\tTrain's rmse: 0.0211662\tValid's rmse: 0.0250057\n[600]\tTrain's rmse: 0.0211103\tValid's rmse: 0.0249963\n[700]\tTrain's rmse: 0.0210564\tValid's rmse: 0.0249932\n[800]\tTrain's rmse: 0.0210052\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209573\tValid's rmse: 0.0249835\n[1000]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249779\n[1100]\tTrain's rmse: 0.0208629\tValid's rmse: 0.0249771\n[1200]\tTrain's rmse: 0.0208185\tValid's rmse: 0.0249764\nEarly stopping, best iteration is:\n[1146]\tTrain's rmse: 0.0208421\tValid's rmse: 0.0249747\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975:  80%|########  | 4/5 [03:32<00:52, 52.92s/it]\u001b[32m[I 2022-04-22 11:30:02,746]\u001b[0m Trial 63 finished with value: 0.024974720462748096 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.024974720462748096.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975:  80%|########  | 4/5 [03:32<00:52, 52.92s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058564 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6663\n[LightGBM] [Info] Number of data points in the train set: 420699, number of used features: 27\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=25 will be ignored. Current value: min_data_in_leaf=10\n[LightGBM] [Info] Start training from score 0.000288\nTraining until validation scores don't improve for 100 rounds\n[100]\tTrain's rmse: 0.0214468\tValid's rmse: 0.0250825\n[200]\tTrain's rmse: 0.0213611\tValid's rmse: 0.0250513\n[300]\tTrain's rmse: 0.0212895\tValid's rmse: 0.0250372\n[400]\tTrain's rmse: 0.0212254\tValid's rmse: 0.0250197\n[500]\tTrain's rmse: 0.0211662\tValid's rmse: 0.0250057\n[600]\tTrain's rmse: 0.0211103\tValid's rmse: 0.0249963\n[700]\tTrain's rmse: 0.0210564\tValid's rmse: 0.0249932\n[800]\tTrain's rmse: 0.0210052\tValid's rmse: 0.0249916\n[900]\tTrain's rmse: 0.0209573\tValid's rmse: 0.0249835\n[1000]\tTrain's rmse: 0.020909\tValid's rmse: 0.0249779\n[1100]\tTrain's rmse: 0.0208629\tValid's rmse: 0.0249771\n[1200]\tTrain's rmse: 0.0208185\tValid's rmse: 0.0249764\nEarly stopping, best iteration is:\n[1146]\tTrain's rmse: 0.0208421\tValid's rmse: 0.0249747\n","output_type":"stream"},{"name":"stderr","text":"min_data_in_leaf, val_score: 0.024975: 100%|##########| 5/5 [04:26<00:00, 53.21s/it]\u001b[32m[I 2022-04-22 11:30:56,469]\u001b[0m Trial 64 finished with value: 0.024974720462748096 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.024974720462748096.\u001b[0m\nmin_data_in_leaf, val_score: 0.024975: 100%|##########| 5/5 [04:26<00:00, 53.23s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"sharpe_ratio: 0.4468949391315575\nscore 2: 0.4468949391315575\nCV_SCORES: [-0.23873907750834863, 0.5320470026104983, 0.4468949391315575]\nCV_SCORE: 0.24673428807790235\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[<lightgbm.basic.Booster at 0x7f54595399d0>,\n <lightgbm.basic.Booster at 0x7f54259a7fd0>,\n <lightgbm.basic.Booster at 0x7f5458980710>]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def predictor(feature_df, feat_cols, models, is_train=True):\n    X = feature_df[feat_cols]\n    \n    # 推論\n    preds = list(map(lambda model: model.predict(X, num_iteration=model.best_iteration), models))\n    print(f\"preds: {preds}\")\n    \n    # スコアは学習時のみ計算\n    if is_train:\n        scores = list(map(lambda pred: evaluator(feature_df, pred), preds))\n        print(\"SCORES:\", scores)\n\n    # 推論結果をバギング\n    pred = np.array(preds).mean(axis=0)\n\n    # スコアは学習時のみ計算\n    if is_train:\n        score = evaluator(feature_df, pred)\n        print(\"SCORE:\", score)\n    \n    return pred\n\ndef eval_predictor(df, feat_cols, models, target_date=['2022-2-01', '2022-2-27']):\n    # 日次で推論・登録\n    print(f\"target_date: {target_date}\")\n    target_df = df.copy()\n    target_df = target_df[(target_date[0] <= target_df['Date']) & (target_df['Date'] < target_date[1])]\n\n    # 推論20\n    target_df[\"pred\"] = predictor(target_df, feat_cols, models, True)\n\n    # 推論結果からRANKを導出し、提出データに反映\n    result_df = add_rank(target_df)\n    return result_df","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:31:00.469987Z","iopub.execute_input":"2022-04-22T11:31:00.470318Z","iopub.status.idle":"2022-04-22T11:31:00.481113Z","shell.execute_reply.started":"2022-04-22T11:31:00.470270Z","shell.execute_reply":"2022-04-22T11:31:00.480124Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"_df = eval_predictor(feature_df, feat_cols, models)\n#pred_df = _df[0]\n#pred_df = pred_df[[\"SecuritiesCode\", \"pred\", \"Date\", \"Rank\"]]\n#target_df = _df[1]\n#target_df = target_df[[\"SecuritiesCode\", \"Target\"]]\n#result_df = pred_df.merge(target_df, on='SecuritiesCode', how=\"left\")\n#write_df(result_df, \"result_df\")\n_df","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:31:00.482339Z","iopub.execute_input":"2022-04-22T11:31:00.482545Z","iopub.status.idle":"2022-04-22T11:31:05.844885Z","shell.execute_reply.started":"2022-04-22T11:31:00.482515Z","shell.execute_reply":"2022-04-22T11:31:05.844003Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"target_date: ['2022-2-01', '2022-2-27']\npreds: [array([0.00073817, 0.00073817, 0.00073817, ..., 0.00074767, 0.00074767,\n       0.00073817]), array([-2.68019620e-04,  1.61962650e-04, -3.81987668e-05, ...,\n        1.47493391e-03,  9.74953254e-04, -1.22408543e-03]), array([-2.75216639e-04,  2.90376109e-05, -6.48490413e-04, ...,\n        2.57841894e-03,  2.42209494e-03, -2.66956545e-03])]\nsharpe_ratio: -0.3183487920363959\nsharpe_ratio: -0.01671803948413025\nsharpe_ratio: 0.022719276203177714\nSCORES: [-0.3183487920363959, -0.01671803948413025, 0.022719276203177714]\nsharpe_ratio: 0.03824054468849757\nSCORE: 0.03824054468849757\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 RowId       Date  SecuritiesCode  \\\n1239     20220201_1301 2022-02-01            1301   \n1240     20220202_1301 2022-02-02            1301   \n1241     20220203_1301 2022-02-03            1301   \n1242     20220204_1301 2022-02-04            1301   \n1243     20220207_1301 2022-02-07            1301   \n...                ...        ...             ...   \n2436633  20220218_9997 2022-02-18            9997   \n2436634  20220221_9997 2022-02-21            9997   \n2436635  20220222_9997 2022-02-22            9997   \n2436636  20220224_9997 2022-02-24            9997   \n2436637  20220225_9997 2022-02-25            9997   \n\n         ChangingRatioAdjustedClose25  ChangingRatioAdjustedClose5  \\\n1239                         3.770492                     1.118211   \n1240                         6.776860                     3.194888   \n1241                         6.754530                     4.180064   \n1242                         5.008078                     5.008078   \n1243                         2.258065                     0.634921   \n...                               ...                          ...   \n2436633                      0.546448                    -3.285151   \n2436634                      1.820728                    -2.937250   \n2436635                     -1.637108                    -2.699055   \n2436636                     -2.442334                    -2.968961   \n2436637                      3.531073                     1.103448   \n\n         ChangingRatioAdjustedClose75  ChangingRatioAdjustedHigh25  \\\n1239                         5.149502                     3.425775   \n1240                         7.774441                     6.065574   \n1241                         8.252589                     6.732348   \n1242                         6.557377                     5.654281   \n1243                         4.448105                     4.193548   \n...                               ...                          ...   \n2436633                     -8.571429                    -0.405954   \n2436634                     -8.897243                    -0.545703   \n2436635                     -6.967742                    -2.032520   \n2436636                     -5.519054                    -4.100529   \n2436637                     -3.425560                     1.095890   \n\n         ChangingRatioAdjustedHigh5  ChangingRatioAdjustedHigh75  \\\n1239                       1.277955                     3.934426   \n1240                       2.373418                     6.765677   \n1241                       3.174603                     7.973422   \n1242                       4.306220                     7.213115   \n1243                       2.539683                     5.728314   \n...                             ...                          ...   \n2436633                   -4.539559                    -9.247842   \n2436634                   -3.058511                    -9.553350   \n2436635                   -3.728362                    -9.056604   \n2436636                   -4.227213                    -7.407407   \n2436637                   -0.806452                    -4.774194   \n\n         ChangingRatioAdjustedLow25  ...  MovingAverageAdjustedVolume75  \\\n1239                       3.119869  ...                   12514.666667   \n1240                       4.462810  ...                   12720.000000   \n1241                       5.940594  ...                   12801.333333   \n1242                       5.436573  ...                   13270.666667   \n1243                       3.425775  ...                   13313.333333   \n...                             ...  ...                            ...   \n2436633                   -1.104972  ...                  265093.333333   \n2436634                    1.125176  ...                  263338.666667   \n2436635                   -0.974930  ...                  257701.333333   \n2436636                   -2.880658  ...                  255014.666667   \n2436637                    2.404526  ...                  252078.666667   \n\n         MovingAverageAdjustedVolume75GapPercent  diff_rate1  diff_rate2  \\\n1239                                   86.298743    0.003160    0.009479   \n1240                                  184.748428    0.018576    0.023220   \n1241                                  121.862306    0.000000    0.012346   \n1242                                  327.790616    0.000000    0.021538   \n1243                                  102.153230   -0.012618    0.018927   \n...                                          ...         ...         ...   \n2436633                                66.429434    0.019022    0.027174   \n2436634                                44.201636    0.002751    0.013755   \n2436635                                87.504398    0.002774    0.016644   \n2436636                                76.701471    0.013908    0.023644   \n2436637                                67.637616    0.010914    0.019100   \n\n         NewMarketSegment  33SectorCode  17SectorCode    Target      pred  \\\n1239         Prime Market            50             1  0.003096  0.000065   \n1240         Prime Market            50             1  0.003086  0.000310   \n1241         Prime Market            50             1 -0.024615  0.000017   \n1242         Prime Market            50             1  0.023659  0.000237   \n1243         Prime Market            50             1 -0.004622  0.000588   \n...                   ...           ...           ...       ...       ...   \n2436633      Prime Market          6100            14 -0.008253  0.002221   \n2436634      Prime Market          6100            14 -0.002774  0.000485   \n2436635      Prime Market          6100            14  0.019471  0.001600   \n2436636      Prime Market          6100            14  0.001364  0.001382   \n2436637      Prime Market          6100            14 -0.001362 -0.001052   \n\n         Rank  \n1239      814  \n1240     1452  \n1241     1284  \n1242     1494  \n1243     1043  \n...       ...  \n2436633   345  \n2436634  1270  \n2436635   656  \n2436636   915  \n2436637  1916  \n\n[33891 rows x 71 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowId</th>\n      <th>Date</th>\n      <th>SecuritiesCode</th>\n      <th>ChangingRatioAdjustedClose25</th>\n      <th>ChangingRatioAdjustedClose5</th>\n      <th>ChangingRatioAdjustedClose75</th>\n      <th>ChangingRatioAdjustedHigh25</th>\n      <th>ChangingRatioAdjustedHigh5</th>\n      <th>ChangingRatioAdjustedHigh75</th>\n      <th>ChangingRatioAdjustedLow25</th>\n      <th>...</th>\n      <th>MovingAverageAdjustedVolume75</th>\n      <th>MovingAverageAdjustedVolume75GapPercent</th>\n      <th>diff_rate1</th>\n      <th>diff_rate2</th>\n      <th>NewMarketSegment</th>\n      <th>33SectorCode</th>\n      <th>17SectorCode</th>\n      <th>Target</th>\n      <th>pred</th>\n      <th>Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1239</th>\n      <td>20220201_1301</td>\n      <td>2022-02-01</td>\n      <td>1301</td>\n      <td>3.770492</td>\n      <td>1.118211</td>\n      <td>5.149502</td>\n      <td>3.425775</td>\n      <td>1.277955</td>\n      <td>3.934426</td>\n      <td>3.119869</td>\n      <td>...</td>\n      <td>12514.666667</td>\n      <td>86.298743</td>\n      <td>0.003160</td>\n      <td>0.009479</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0.003096</td>\n      <td>0.000065</td>\n      <td>814</td>\n    </tr>\n    <tr>\n      <th>1240</th>\n      <td>20220202_1301</td>\n      <td>2022-02-02</td>\n      <td>1301</td>\n      <td>6.776860</td>\n      <td>3.194888</td>\n      <td>7.774441</td>\n      <td>6.065574</td>\n      <td>2.373418</td>\n      <td>6.765677</td>\n      <td>4.462810</td>\n      <td>...</td>\n      <td>12720.000000</td>\n      <td>184.748428</td>\n      <td>0.018576</td>\n      <td>0.023220</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0.003086</td>\n      <td>0.000310</td>\n      <td>1452</td>\n    </tr>\n    <tr>\n      <th>1241</th>\n      <td>20220203_1301</td>\n      <td>2022-02-03</td>\n      <td>1301</td>\n      <td>6.754530</td>\n      <td>4.180064</td>\n      <td>8.252589</td>\n      <td>6.732348</td>\n      <td>3.174603</td>\n      <td>7.973422</td>\n      <td>5.940594</td>\n      <td>...</td>\n      <td>12801.333333</td>\n      <td>121.862306</td>\n      <td>0.000000</td>\n      <td>0.012346</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>1</td>\n      <td>-0.024615</td>\n      <td>0.000017</td>\n      <td>1284</td>\n    </tr>\n    <tr>\n      <th>1242</th>\n      <td>20220204_1301</td>\n      <td>2022-02-04</td>\n      <td>1301</td>\n      <td>5.008078</td>\n      <td>5.008078</td>\n      <td>6.557377</td>\n      <td>5.654281</td>\n      <td>4.306220</td>\n      <td>7.213115</td>\n      <td>5.436573</td>\n      <td>...</td>\n      <td>13270.666667</td>\n      <td>327.790616</td>\n      <td>0.000000</td>\n      <td>0.021538</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0.023659</td>\n      <td>0.000237</td>\n      <td>1494</td>\n    </tr>\n    <tr>\n      <th>1243</th>\n      <td>20220207_1301</td>\n      <td>2022-02-07</td>\n      <td>1301</td>\n      <td>2.258065</td>\n      <td>0.634921</td>\n      <td>4.448105</td>\n      <td>4.193548</td>\n      <td>2.539683</td>\n      <td>5.728314</td>\n      <td>3.425775</td>\n      <td>...</td>\n      <td>13313.333333</td>\n      <td>102.153230</td>\n      <td>-0.012618</td>\n      <td>0.018927</td>\n      <td>Prime Market</td>\n      <td>50</td>\n      <td>1</td>\n      <td>-0.004622</td>\n      <td>0.000588</td>\n      <td>1043</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2436633</th>\n      <td>20220218_9997</td>\n      <td>2022-02-18</td>\n      <td>9997</td>\n      <td>0.546448</td>\n      <td>-3.285151</td>\n      <td>-8.571429</td>\n      <td>-0.405954</td>\n      <td>-4.539559</td>\n      <td>-9.247842</td>\n      <td>-1.104972</td>\n      <td>...</td>\n      <td>265093.333333</td>\n      <td>66.429434</td>\n      <td>0.019022</td>\n      <td>0.027174</td>\n      <td>Prime Market</td>\n      <td>6100</td>\n      <td>14</td>\n      <td>-0.008253</td>\n      <td>0.002221</td>\n      <td>345</td>\n    </tr>\n    <tr>\n      <th>2436634</th>\n      <td>20220221_9997</td>\n      <td>2022-02-21</td>\n      <td>9997</td>\n      <td>1.820728</td>\n      <td>-2.937250</td>\n      <td>-8.897243</td>\n      <td>-0.545703</td>\n      <td>-3.058511</td>\n      <td>-9.553350</td>\n      <td>1.125176</td>\n      <td>...</td>\n      <td>263338.666667</td>\n      <td>44.201636</td>\n      <td>0.002751</td>\n      <td>0.013755</td>\n      <td>Prime Market</td>\n      <td>6100</td>\n      <td>14</td>\n      <td>-0.002774</td>\n      <td>0.000485</td>\n      <td>1270</td>\n    </tr>\n    <tr>\n      <th>2436635</th>\n      <td>20220222_9997</td>\n      <td>2022-02-22</td>\n      <td>9997</td>\n      <td>-1.637108</td>\n      <td>-2.699055</td>\n      <td>-6.967742</td>\n      <td>-2.032520</td>\n      <td>-3.728362</td>\n      <td>-9.056604</td>\n      <td>-0.974930</td>\n      <td>...</td>\n      <td>257701.333333</td>\n      <td>87.504398</td>\n      <td>0.002774</td>\n      <td>0.016644</td>\n      <td>Prime Market</td>\n      <td>6100</td>\n      <td>14</td>\n      <td>0.019471</td>\n      <td>0.001600</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>2436636</th>\n      <td>20220224_9997</td>\n      <td>2022-02-24</td>\n      <td>9997</td>\n      <td>-2.442334</td>\n      <td>-2.968961</td>\n      <td>-5.519054</td>\n      <td>-4.100529</td>\n      <td>-4.227213</td>\n      <td>-7.407407</td>\n      <td>-2.880658</td>\n      <td>...</td>\n      <td>255014.666667</td>\n      <td>76.701471</td>\n      <td>0.013908</td>\n      <td>0.023644</td>\n      <td>Prime Market</td>\n      <td>6100</td>\n      <td>14</td>\n      <td>0.001364</td>\n      <td>0.001382</td>\n      <td>915</td>\n    </tr>\n    <tr>\n      <th>2436637</th>\n      <td>20220225_9997</td>\n      <td>2022-02-25</td>\n      <td>9997</td>\n      <td>3.531073</td>\n      <td>1.103448</td>\n      <td>-3.425560</td>\n      <td>1.095890</td>\n      <td>-0.806452</td>\n      <td>-4.774194</td>\n      <td>2.404526</td>\n      <td>...</td>\n      <td>252078.666667</td>\n      <td>67.637616</td>\n      <td>0.010914</td>\n      <td>0.019100</td>\n      <td>Prime Market</td>\n      <td>6100</td>\n      <td>14</td>\n      <td>-0.001362</td>\n      <td>-0.001052</td>\n      <td>1916</td>\n    </tr>\n  </tbody>\n</table>\n<p>33891 rows × 71 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"# 時系列APIのロード\nimport jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:31:05.847052Z","iopub.execute_input":"2022-04-22T11:31:05.847348Z","iopub.status.idle":"2022-04-22T11:31:05.882211Z","shell.execute_reply.started":"2022-04-22T11:31:05.847316Z","shell.execute_reply":"2022-04-22T11:31:05.881157Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# supplemental filesを履歴データの初期状態としてセットアップ\npast_df = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:31:05.884644Z","iopub.execute_input":"2022-04-22T11:31:05.885206Z","iopub.status.idle":"2022-04-22T11:31:08.219292Z","shell.execute_reply.started":"2022-04-22T11:31:05.885154Z","shell.execute_reply":"2022-04-22T11:31:08.218382Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# 日次で推論・登録\nfor i, (prices, options, financials, trades, secondary_prices, sample_prediction) in enumerate(iter_test):\n    current_date = prices[\"Date\"].iloc[0]\n    print(f\"count {i}, {current_date}\")\n\n    if i == 0:\n        # リークを防止するため、時系列APIから受け取ったデータより未来のデータを削除\n        past_df = past_df[past_df[\"Date\"] < current_date]\n\n    # リソース確保のため古い履歴を削除\n    threshold = (pd.Timestamp(current_date) - pd.offsets.BDay(80))\n    past_df = past_df[past_df[\"Date\"] >= threshold]\n    \n    # 時系列APIから受け取ったデータを履歴データに統合\n    base_df = collector(prices, options, financials, trades, secondary_prices, stock_list)\n    past_df = pd.concat([past_df, base_df]).reset_index(drop=True)\n\n    # 特徴量エンジニアリング\n    feature_df, feat_cols, label_col = preprocessor(past_df, False)\n\n    # 予測対象レコードだけを抽出\n    feature_df = feature_df[feature_df['Date'] == current_date]\n\n    # 推論\n    feature_df[\"pred\"] = predictor(feature_df, feat_cols, models, False)\n\n    # 推論結果からRANKを導出し、提出データに反映\n    feature_df = add_rank(feature_df)\n    write_df(feature_df, f\"result_{i}\")\n    feature_map = feature_df.set_index('SecuritiesCode')['Rank'].to_dict()\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(feature_map)\n\n    # 結果を登録\n    env.predict(sample_prediction)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T11:31:08.220712Z","iopub.execute_input":"2022-04-22T11:31:08.220948Z","iopub.status.idle":"2022-04-22T11:35:41.755885Z","shell.execute_reply.started":"2022-04-22T11:31:08.220921Z","shell.execute_reply":"2022-04-22T11:35:41.755004Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\ncount 0, 2021-12-06\npreds: [array([0.00073817, 0.00073817, 0.00073817, ..., 0.00074767, 0.00073817,\n       0.00073817]), array([-0.00183815, -0.00078291,  0.0002153 , ...,  0.00095909,\n        0.00013279,  0.00028044]), array([-0.00251258, -0.00290485, -0.00146348, ...,  0.00237238,\n       -0.00044787, -0.00109379])]\ncount 1, 2021-12-07\npreds: [array([0.00073817, 0.00074767, 0.00073817, ..., 0.00074767, 0.00073817,\n       0.00073817]), array([ 6.45879504e-04, -8.29771546e-04,  4.13145893e-04, ...,\n        6.35339836e-04, -6.53932985e-05,  5.86580550e-04]), array([ 0.00108188, -0.00208913, -0.00126981, ...,  0.00055182,\n       -0.00074936, -0.00075155])]\n","output_type":"stream"}]}]}